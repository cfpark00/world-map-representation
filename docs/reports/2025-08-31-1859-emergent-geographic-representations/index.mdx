import Image from 'next/image'
import representationEvolution from './representation_evolution.png'
import finalWorldMap from './final_world_map.png'
import worldMapEvolution from './world_map_evolution.gif'
import trainingDynamics from './training_dynamics.png'
import trainingSummary from './training_summary.png'

**TL;DR:** We trained a 6-layer transformer to predict distances between cities. Without any geographic supervision, the model develops internal representations that encode longitude and latitude coordinates. Linear probes trained on partial prompts achieve R²=0.96 for geographic location prediction, showing how a world model emerges from distance learning alone.

<div className="flex justify-center my-6">
  <figure className="w-full max-w-3xl">
    <Image src={worldMapEvolution} alt="Animation showing the emergence of geographic representations during training" />
    <figcaption className="text-center text-sm text-muted-foreground mt-2">
      <strong>Geographic representations emerging during training:</strong> Starting from random noise (step 3908), the model progressively learns geographic structure, achieving R²=0.96 by the final checkpoint. Lines connect true locations to model predictions.
    </figcaption>
  </figure>
</div>

## The Experiment: Learning Geography from Distance Alone

We investigated whether neural networks can discover spatial structure from distance relationships alone. The task provides no explicit geographic information—only city pairs and their distances.

### The Task: Distance Prediction

```
Input:  <bos>dist(c_1234,c_5678)=
Output: 2451<eos>
```

The model receives two anonymized city IDs and must predict the distance between them in kilometers. No coordinates, no country information, no geographic metadata—just pairs of numbers and their haversine distances.

### Experimental Setup

**Dataset**: We generated 1 million distance prediction samples from 5,075 cities worldwide (population ≥100k). Cities were filtered from GeoNames data and randomly shuffled to eliminate geographic clustering in ID assignments.

**Model Architecture**: A compact Qwen2.5-style transformer:
- **6 layers, 128 hidden dimensions, 4 attention heads**
- **44-token character-level vocabulary**: letters, digits, grammar symbols
- **Custom tokenizer** handling the format: `dist(c_ID,c_ID)=DISTANCE`
- **Total parameters**: ~350k (small enough for detailed analysis)

**Training Configuration**:
- **1M training samples** with train/val/test splits
- **Answer-only loss masking**: trained only on distance outputs, not prompts
- **20 epochs, batch size 512**, learning rate 3e-4 with linear warmup
- **Frequent evaluation**: 40 times per epoch to track representation dynamics

**Loss Masking Strategy**: We used "answer-only" loss masking, computing gradients only on the actual distance values (not the input cities). This focuses learning on the prediction task while preventing overfitting to prompt structure.

### Training Dynamics

<div className="flex justify-center my-6">
  <figure className="w-full max-w-4xl">
    <Image src={trainingSummary} alt="Training and evaluation metrics showing loss curves and distance prediction errors" />
    <figcaption className="text-center text-sm text-muted-foreground mt-2">
      <strong>Primary task performance:</strong> The model learns to predict distances with remarkable accuracy. Left: Training and evaluation loss converge smoothly from ~1.8 to ~1.1. Right: Absolute distance error (log scale) drops from ~5,000 km to ~100 km, achieving better-than-100km accuracy by the final checkpoint.
    </figcaption>
  </figure>
</div>

An interesting observation: the loss curves show a characteristic plateau pattern rather than continuing to decrease exponentially. This raises an intriguing question—are these simple loss plateaus in language modeling well understood? The model seems to reach a natural performance ceiling around loss 1.1, yet continues making subtle improvements in distance accuracy. This suggests the plateau may hide continued learning of internal representations even when the primary loss appears stable.

## The Analysis: Probing for Geographic Knowledge

To test whether the model develops geographic representations, we designed a linear probe analysis:

### Probe Design

We extracted representations from layers 3 and 4 (concatenated, 256 dimensions total) at specific token positions during partial prompt processing:

```
Prompt: <bos>dist(c_1234,c_
Token position: ─────────────^
```

At the final underscore token, we hypothesized the model must "know" the first city's location to prepare for distance calculations with the upcoming second city.

### Training Linear Probes

For each checkpoint during training:
1. **Sample 5,000 random cities** from our dataset
2. **Extract representations** at the critical token position  
3. **Train Ridge regression probes** (3,000 train, 2,000 test) to predict:
   - Longitude coordinate (in degrees)
   - Latitude coordinate (in degrees)
4. **Compute R² scores** and mean distance errors

The probe uses no information about distances or city relationships—only the internal representations at the moment the model processes a city ID.

## Results: The Emergence of a World Model

### Representation Evolution

<div className="flex justify-center my-6">
  <figure className="w-full max-w-3xl">
    <Image src={trainingDynamics} alt="Evolution of representation quality during training" />
    <figcaption className="text-center text-sm text-muted-foreground mt-2">
      <strong>Figure 1:</strong> Training dynamics showing the emergence of geographic representations. Longitude and latitude prediction accuracy (R²) develops in parallel with distance learning, reaching R²≈0.96 by final checkpoint.
    </figcaption>
  </figure>
</div>

The results show a clear pattern:

**Early Training (Steps 0-8000)**:
- Distance loss decreases from 1.85 to 1.78
- Geographic probes achieve negative R² (worse than random)
- Mean location error: ~6,875 km (nearly half Earth's circumference)

**Rapid Emergence (Steps 8000-20000)**:
- Distance task performance improves steadily
- Geographic representations suddenly emerge and improve rapidly
- Location error drops from 6,875 km to 1,185 km

**Convergence (Steps 20000-39000)**:
- **Final longitude R²: 0.956** (explains 95.6% of variance)
- **Final latitude R²: 0.923** (explains 92.3% of variance)  
- **Mean location error: 993 km** (about the distance from New York to Detroit)
- **Median location error: 679 km** (even better for typical predictions)

### What the Model Learned

The world map visualization at the top reveals the model has learned:

1. **Continental Structure**: Clear separation of Europe, Asia, Africa, Americas
2. **Relative Positioning**: Japan appears east of China, UK northwest of continental Europe  
3. **Density Patterns**: Dense city clusters in Europe/East Asia, sparse regions in oceans/deserts
4. **Distance Relationships**: Nearby cities cluster together, distant cities separate appropriately

### Analysis of Learned Representations

Several patterns emerge from the training data:

**Longitude vs Latitude**: Longitude predictions consistently outperform latitude (R²=0.956 vs 0.923). This may reflect the model's implicit understanding that longitude affects distance more dramatically at higher latitudes.

**Convergence Dynamics**: Both coordinates show similar improvement trajectories, suggesting they emerge from a unified spatial representation rather than independent encodings.

**Stability**: Final representations remain stable across the last 10,000 training steps, indicating robust convergence rather than overfitting.

## Key Findings and Implications

### 1. Spatial Organization Without Supervision

Geographic structure emerges without explicit supervision. The model never sees coordinates, country names, or geographic metadata—yet it develops representations that encode spatial relationships with high accuracy.

### 2. Task-Driven Representation Learning  

The model learns geography because it's *necessary* for the distance task. To predict distances accurately, it must implicitly understand that:
- London and Paris are close (≈344 km)
- London and Tokyo are far (≈9,560 km)
- Geographic relationships are consistent and lawful

### 3. Hierarchical Spatial Representations

The linear probe analysis reveals representations at different levels of abstraction:
- **Layer 3**: Emerging spatial structure with moderate accuracy
- **Layer 4**: Refined geographic coordinates with high precision  
- **Combined**: Concatenated representations achieve highest accuracy

### 4. Efficient Learning

With only 350k parameters and 1M training samples, the model learns an accurate world model. This demonstrates that spatial reasoning can emerge from appropriate training objectives without massive scale.

## Technical Insights

### Why This Approach Worked

Several design decisions proved crucial:

**Character-Level Tokenization**: Our 44-token vocabulary handles city IDs, distances, and grammar symbols uniformly, preventing tokenization artifacts that could bias learning.

**Answer-Only Loss Masking**: By computing gradients only on distance predictions, we focus learning pressure on the core spatial reasoning task.

**Frequent Evaluation**: Evaluating 40 times per epoch revealed the precise dynamics of representation emergence, showing it occurs rapidly around step 15,000.

**Large-Scale Data**: 1M samples provided sufficient diversity to learn robust spatial relationships across all continents and distance scales.

### What the Model Must Learn

To succeed at distance prediction, the model must implicitly solve several sub-problems:

1. **City Identification**: Map arbitrary IDs to unique locations
2. **Spatial Embedding**: Organize cities in a metric space
3. **Distance Computation**: Apply approximate haversine formula
4. **Output Generation**: Convert distances to token sequences

Our linear probe analysis reveals the model solves problems 1 and 2 explicitly—internal representations directly encode longitude and latitude coordinates.

### Comparison to Explicit Geographic Training

These results compare favorably to explicit geographic learning:
- **No coordinate supervision**: Model never sees latitude/longitude pairs
- **No distance formula**: Model must discover haversine-like computation
- **No geographic metadata**: No continent, country, or region labels
- **Yet achieves R²=0.96**: Comparable to supervised geographic prediction

## Implications for Representation Learning

### For AI Interpretability Research

This work shows that meaningful representations can be extracted from compact models. The linear probe methodology provides a framework for studying how representations develop during training.

**Methodological Contributions**:
- Probe training at specific token positions during inference
- Tracking representation quality across training checkpoints  
- Validation through explicit world map visualization
- Connection between task performance and representation quality

### For World Model Research

The results suggest that appropriate training objectives can lead to structured world models without explicit supervision, questioning whether complex architectures or multi-modal training are always necessary.

**Key Principles**:
- **Task Necessity**: Representations emerge when required for task success
- **Implicit Structure**: Models can discover latent structure in training data
- **Efficient Discovery**: Small models can learn large-scale spatial relationships

### For Synthetic Data Generation

The city coordinate task provides a template for studying representation formation:
- **Controllable complexity**: Scale from 100 to 10,000+ cities
- **Ground truth validation**: Visualize representations on world maps
- **Natural structure**: Real geographic patterns, not artificial hierarchies
- **Multiple task variants**: Distance, location, path planning, etc.

## Looking Forward: Future Experiments

This flagship experiment opens several research directions:

### Scaling Studies
- **Model size effects**: How do representations change from 100k to 100M parameters?
- **Data efficiency**: What's the minimum data needed for world model emergence?
- **Task complexity**: Can models learn 3D geographic relationships (elevation, depth)?

### Representation Structure  
- **Layer-wise analysis**: How do representations differ across all 6 layers?
- **Attention patterns**: What spatial relationships do attention heads discover?
- **Transfer learning**: Do geographic representations transfer to new spatial tasks?

### Intervention Studies
- **Representation editing**: Can we modify internal coordinates and change predictions?
- **Ablation studies**: What happens when we remove specific continents from training?
- **Architecture variations**: How do different attention mechanisms affect spatial learning?

## Conclusion

We studied representation formation in neural networks using a simple distance prediction task. A 6-layer transformer, trained only on city distances, learned to encode longitude and latitude coordinates with R²=0.96—without any geographic supervision.

This demonstrates that spatial representations can emerge from task requirements alone. The model learned geography because spatial understanding was necessary for accurate distance prediction.

For representation learning research, this provides both a method and a result. The probing methodology reveals internal representation structure, while the results show that appropriate training objectives can lead to world model discovery without explicit supervision.

The city coordinate task offers a useful testbed for studying representation formation: controllable complexity, natural structure, and ground truth validation. This enables systematic investigation of how representations form and what conditions lead to interpretable internal models.

Future work will explore how these geographic representations transfer across tasks and what happens when we intervene in the model's internal coordinate system.

---

*Next: How these geographic representations transfer across different spatial reasoning tasks, and what happens when we intervene directly in the model's internal coordinate system.*

<details className="not-prose my-4 rounded-lg border border-gray-200 dark:border-gray-700 p-3">
  <summary className="cursor-pointer font-semibold text-gray-700 dark:text-gray-300 hover:text-gray-900 dark:hover:text-gray-100">Appendix: Technical Details</summary>
  <div className="mt-3 text-sm text-gray-600 dark:text-gray-400">

**Model Architecture** (Qwen2.5-style transformer):
```yaml
model:
  vocab_size: 44
  hidden_size: 128
  num_hidden_layers: 6
  num_attention_heads: 4
  intermediate_size: 512
  init_scale: 0.1  # GPT-2 style weight initialization std
```

**Custom Character-Level Tokenizer**:
```
Total vocabulary: 44 tokens
- Special tokens (3): <pad>, <bos>, <eos>
- Grammar tokens (5): ( ) , = _
- Alphabet tokens (26): a-z (lowercase only)
- Digit tokens (10): 0-9

Token ID assignments:
- 0: <pad>, 1: <bos>, 2: <eos>
- 3-7: Grammar symbols
- 8-33: Letters a-z
- 34-43: Digits 0-9
```

**Training Configuration**:
```yaml  
training:
  batch_size: 512
  eval_batch_size: 64
  num_epochs: 20
  optimizer: adamw
  learning_rate: 3e-4
  weight_decay: 0.01
  scheduler: linear_with_warmup
  warmup_steps: 50
  loss_mask_type: answer_only  # Only compute gradients on distance values
  seed: 42
```

**Checkpointing &amp; Evaluation**:
```yaml
checkpointing:
  save_strategy: steps
  save_steps: 0.1      # Save 10 times per epoch
  eval_strategy: steps
  eval_steps: 0.025    # Evaluate 40 times per epoch (for fine-grained tracking)
```

**Dataset Generation**:
- **Source**: GeoNames database, filtered for cities with population ≥100,000
- **Total cities**: 5,075 worldwide
- **Training samples**: 1,000,000 random city pairs
- **ID assignment**: Random shuffle to prevent geographic clustering in IDs
- **Distance calculation**: Haversine formula (great circle distance)
- **Distance rounding**: Nearest integer kilometer
- **Format**: `dist(c_ID1,c_ID2)=DISTANCE` (no zero-padding on IDs)
- **Sequence length**: Maximum 32 tokens

**Linear Probe Methodology**:
```python
# Representation extraction
layers_to_probe = [3, 4]  # 0-indexed, so layers 4 and 5
extraction_point = "last_token_of_first_city"  # The "_" in "dist(c_1234,c_"

# Probe configuration
probe_type = Ridge(alpha=10.0)  # L2 regularization
n_probe_samples = 5000  # Random subset of cities
train_test_split = (3000, 2000)

# Evaluation metrics
- R² score (variance explained)
- Mean Absolute Error (MAE) in km
- Median distance error
```

**Representation Analysis Details**:
- **Extraction prompt**: `<bos>dist(c_ID,c_` (partial, stops at underscore)
- **Token position**: Final underscore token before second city
- **Layer selection**: Concatenated representations from layers 3 and 4
- **Dimensionality**: 256 (128 × 2 layers)
- **Probe training**: Separate Ridge regression for longitude and latitude
- **Validation**: Hold-out test set (2,000 cities never seen during probe training)

**Final Performance Metrics**:
```
Distance Prediction (Main Task):
- Train loss: 1.087
- Eval loss: 1.119
- Mean distance error: 98.25 km
- Median distance error: 59.5 km

Geographic Probe Results:
- Longitude R²: 0.956
- Latitude R²: 0.923
- Mean location error: 993 km
- Median location error: 679 km
```

**Haversine Distance Formula** (used for ground truth):
```python
def haversine(lon1, lat1, lon2, lat2):
    """Great circle distance between points (in degrees)"""
    # Convert to radians
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    
    # Haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    # Earth radius in km
    r = 6371
    return c * r
```

**Computational Resources**:

• Training hardware: Single GPU (specific model varies)  
• Training time: ~2-3 hours for 20 epochs  
• Analysis time: ~1 hour for full probe evaluation across all checkpoints  
• Storage: ~500MB for all checkpoints and analysis outputs

  </div>
</details>