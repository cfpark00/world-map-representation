
@article{allen2023physics1,
  title={Physics of language models: Part 1, learning hierarchical language structures},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={ArXiv e-prints, abs/2305.13673, May},
  year={2023}
}

@misc{kumar2025questioningrepresentationaloptimismdeep,
      title={Questioning Representational Optimism in Deep Learning: The Fractured Entangled Representation Hypothesis}, 
      author={Akarsh Kumar and Jeff Clune and Joel Lehman and Kenneth O. Stanley},
      year={2025},
      eprint={2505.11581},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.11581}, 
}

@misc{lee2025geometryselfverificationtaskspecificreasoning,
      title={The Geometry of Self-Verification in a Task-Specific Reasoning Model}, 
      author={Andrew Lee and Lihao Sun and Chris Wendler and Fernanda Viégas and Martin Wattenberg},
      year={2025},
      eprint={2504.14379},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.14379}, 
}

@misc{li2016convergentlearningdifferentneural,
      title={Convergent Learning: Do different neural networks learn the same representations?}, 
      author={Yixuan Li and Jason Yosinski and Jeff Clune and Hod Lipson and John Hopcroft},
      year={2016},
      eprint={1511.07543},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.07543}, 
}

@article{olah2018the,
  author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2018},
  note = {https://distill.pub/2018/building-blocks},
  doi = {10.23915/distill.00010}
}

@article{pearce2025tree,
  author = {Pearce, Michael and Simon, Elana and Byun, Michael and Balsam, Daniel},
  title = {Finding the Tree of Life in Evo 2},
  journal = {Goodfire Research},
  year = {2025},
  month = {August},
  note = {Correspondence to michael@goodfire.ai}
}

@article{templeton2024scaling,
       title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
       author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
       year={2024},
       journal={Transformer Circuits Thread},
       url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
    }

@misc{dziri2023faithfatelimitstransformers,
      title={Faith and Fate: Limits of Transformers on Compositionality}, 
      author={Nouha Dziri and Ximing Lu and Melanie Sclar and Xiang Lorraine Li and Liwei Jiang and Bill Yuchen Lin and Peter West and Chandra Bhagavatula and Ronan Le Bras and Jena D. Hwang and Soumya Sanyal and Sean Welleck and Xiang Ren and Allyson Ettinger and Zaid Harchaoui and Yejin Choi},
      year={2023},
      eprint={2305.18654},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18654}, 
}

@misc{shojaee2025illusionthinkingunderstandingstrengths,
      title={The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity}, 
      author={Parshin Shojaee and Iman Mirzadeh and Keivan Alizadeh and Maxwell Horton and Samy Bengio and Mehrdad Farajtabar},
      year={2025},
      eprint={2506.06941},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.06941}, 
}

@misc{alain2018understandingintermediatelayersusing,
      title={Understanding intermediate layers using linear classifier probes}, 
      author={Guillaume Alain and Yoshua Bengio},
      year={2018},
      eprint={1610.01644},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1610.01644}, 
}


@misc{geonames_all_cities_1000,
  title        = {GeoNames – All Cities with a Population > 1000},
  author       = {{OpenDataSoft / GeoNames}},
  howpublished = {\url{https://public.opendatasoft.com/explore/dataset/geonames-all-cities-with-a-population-1000}},
  note         = {Accessed: 2025},
  year         = {2025}
}

@misc{hoffmann2024eurekamomentstransformersmultisteptasks,
      title={Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced Optimization Problems}, 
      author={David T. Hoffmann and Simon Schrodi and Jelena Bratulić and Nadine Behrmann and Volker Fischer and Thomas Brox},
      year={2024},
      eprint={2310.12956},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.12956}, 
}

@misc{gopalani2025happenslossplateauunderstanding,
      title={What Happens During the Loss Plateau? Understanding Abrupt Learning in Transformers}, 
      author={Pulkit Gopalani and Wei Hu},
      year={2025},
      eprint={2506.13688},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.13688}, 
}


@misc{shah2020pitfallssimplicitybiasneural,
      title={The Pitfalls of Simplicity Bias in Neural Networks}, 
      author={Harshay Shah and Kaustav Tamuly and Aditi Raghunathan and Prateek Jain and Praneeth Netrapalli},
      year={2020},
      eprint={2006.07710},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.07710}, 
}

@misc{bachmann2025pitfallsnexttokenprediction,
      title={The pitfalls of next-token prediction}, 
      author={Gregor Bachmann and Vaishnavh Nagarajan},
      year={2025},
      eprint={2403.06963},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.06963}, 
}

@misc{chan2022datadistributionalpropertiesdrive,
      title={Data Distributional Properties Drive Emergent In-Context Learning in Transformers}, 
      author={Stephanie C. Y. Chan and Adam Santoro and Andrew K. Lampinen and Jane X. Wang and Aaditya Singh and Pierre H. Richemond and Jay McClelland and Felix Hill},
      year={2022},
      eprint={2205.05055},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.05055}, 
}

@misc{menon2025analyzinginabilitiessaesformal,
      title={Analyzing (In)Abilities of SAEs via Formal Languages}, 
      author={Abhinav Menon and Manish Shrivastava and David Krueger and Ekdeep Singh Lubana},
      year={2025},
      eprint={2410.11767},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.11767}, 
}

@misc{hindupur2025projectingassumptionsdualitysparse,
      title={Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry}, 
      author={Sai Sumedh R. Hindupur and Ekdeep Singh Lubana and Thomas Fel and Demba Ba},
      year={2025},
      eprint={2503.01822},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.01822}, 
}

@misc{wurgaft2025incontextlearningstrategiesemerge,
      title={In-Context Learning Strategies Emerge Rationally}, 
      author={Daniel Wurgaft and Ekdeep Singh Lubana and Core Francisco Park and Hidenori Tanaka and Gautam Reddy and Noah D. Goodman},
      year={2025},
      eprint={2506.17859},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.17859}, 
}

@article{allen2023physics,
  title={Physics of language models: Part 3.1, knowledge storage and extraction},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2309.14316},
  year={2023}
}

@article{wen2024transformers,
  title={Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars},
  author={Wen, Kaiyue and Li, Yuchen and Liu, Bingbin and Risteski, Andrej},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2022transformers,
  title={Transformers learn shortcuts to automata},
  author={Liu, Bingbin and Ash, Jordan T and Goel, Surbhi and Krishnamurthy, Akshay and Zhang, Cyril},
  journal={arXiv preprint arXiv:2210.10749},
  year={2022}
}

@article{qin2024sometimes,
  title={Sometimes I am a Tree: Data Drives Unstable Hierarchical Generalization},
  author={Qin, Tian and Saphra, Naomi and Alvarez-Melis, David},
  journal={arXiv preprint arXiv:2412.04619},
  year={2024}
}

@article{brady2009compression,
  title={Compression in visual working memory: using statistical regularities to form more efficient memory representations.},
  author={Brady, Timothy F and Konkle, Talia and Alvarez, George A},
  journal={Journal of Experimental Psychology: General},
  volume={138},
  number={4},
  pages={487},
  year={2009},
  publisher={American Psychological Association}
}

@article{harman1982conceptual,
  title={Conceptual role semantics.},
  author={Harman, Gilbert},
  journal={Notre Dame Journal of Formal Logic},
  volume={23},
  number={2},
  pages={242--256},
  year={1982},
  publisher={Duke University Press}
}

@article{block1998semantics,
  title={Semantics, conceptual role},
  author={Block, Ned},
  journal={Routledge encyclopedia of philosophy},
  volume={8},
  pages={652--657},
  year={1998},
  publisher={Routledge London}
}

@article{nishi2024representation,
  title={Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing},
  author={Nishi, Kento and Okawa, Maya and Ramesh, Rahul and Khona, Mikail and Lubana, Ekdeep Singh and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2410.17194},
  year={2024}
}

@article{khonatowards,
  title={Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model},
  author={Khona, Mikail and Okawa, Maya and Hula, Jan and Ramesh, Rahul and Nishi, Kento and Dick, Robert and Lubana, Ekdeep Singh and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2402.07757},
  year={2024}
}

@article{park2024competition,
  title={Competition Dynamics Shape Algorithmic Phases of In-Context Learning},
  author={Park, Core Francisco and Lubana, Ekdeep Singh and Pres, Itamar and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2412.01003},
  year={2024}
}

@article{von2023uncovering,
  title={Uncovering mesa-optimization algorithms in transformers},
  author={Von Oswald, Johannes and Schlegel, Maximilian and Meulemans, Alexander and Kobayashi, Seijin and Niklasson, Eyvind and Zucchet, Nicolas and Scherrer, Nino and Miller, Nolan and Sandler, Mark and Vladymyrov, Max and others},
  journal={arXiv preprint arXiv:2309.05858},
  year={2023}
}

@inproceedings{von2023transformers,
  title={Transformers learn in-context by gradient descent},
  author={Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  booktitle={International Conference on Machine Learning},
  pages={35151--35174},
  year={2023},
  organization={PMLR}
}

@article{gopalani2024abrupt,
  title={Abrupt Learning in Transformers: A Case Study on Matrix Completion},
  author={Gopalani, Pulkit and Lubana, Ekdeep Singh and Hu, Wei},
  journal={arXiv preprint arXiv:2410.22244},
  year={2024}
}

@article{shai2024transformers,
  title={Transformers represent belief state geometry in their residual stream},
  author={Shai, Adam S and Marzen, Sarah E and Teixeira, Lucas and Oldenziel, Alexander Gietelink and Riechers, Paul M},
  journal={arXiv preprint arXiv:2405.15943},
  year={2024}
}

@article{vafa2024evaluating,
  title={Evaluating the World Model Implicit in a Generative Model},
  author={Vafa, Keyon and Chen, Justin Y and Kleinberg, Jon and Mullainathan, Sendhil and Rambachan, Ashesh},
  journal={arXiv preprint arXiv:2406.03689},
  year={2024}
}

@article{li2021implicit,
  title={Implicit representations of meaning in neural language models},
  author={Li, Belinda Z and Nye, Maxwell and Andreas, Jacob},
  journal={arXiv preprint arXiv:2106.00737},
  year={2021}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{arora2016latent,
  title={A latent variable model approach to pmi-based word embeddings},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={385--399},
  year={2016},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{ethayarajh2018towards,
  title={Towards understanding linear word analogies},
  author={Ethayarajh, Kawin and Duvenaud, David and Hirst, Graeme},
  journal={arXiv preprint arXiv:1810.04882},
  year={2018}
}

@article{gurnee2023language,
  title={Language models represent space and time},
  author={Gurnee, Wes and Tegmark, Max},
  journal={arXiv preprint arXiv:2310.02207},
  year={2023}
}

@article{jenner2024evidence,
  title={Evidence of Learned Look-Ahead in a Chess-Playing Neural Network},
  author={Jenner, Erik and Kapur, Shreyas and Georgiev, Vasil and Allen, Cameron and Emmons, Scott and Russell, Stuart},
  journal={arXiv preprint arXiv:2406.00877},
  year={2024}
}

@article{abdou2021can,
  title={Can language models encode perceptual structure without grounding? a case study in color},
  author={Abdou, Mostafa and Kulmizev, Artur and Hershcovich, Daniel and Frank, Stella and Pavlick, Ellie and S{\o}gaard, Anders},
  journal={arXiv preprint arXiv:2109.06129},
  year={2021}
}

@inproceedings{traylor2022can,
  title={Can Neural Networks Learn Implicit Logic from Physical Reasoning?},
  author={Traylor, Aaron and Feiman, Roman and Pavlick, Ellie},
  booktitle={The eleventh international conference on learning representations},
  year={2022}
}

@inproceedings{patel2022mapping,
  title={Mapping language models to grounded conceptual spaces},
  author={Patel, Roma and Pavlick, Ellie},
  booktitle={International conference on learning representations},
  year={2022}
}

@article{humans4,
  title={Transferring structural knowledge across cognitive maps in humans and models},
  author={Mark, Shirley and Moran, Rani and Parr, Thomas and Kennerley, Steve W and Behrens, Timothy EJ},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={4783},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{humans3,
  title={Flexible neural representations of abstract structural knowledge in the human Entorhinal Cortex},
  author={Mark, Shirley and Schwartenbeck, Phillipp and Hahamy, Avital and Samborska, Veronika and Baram, Alon B and Behrens, Timothy E},
  journal={Elife},
  volume={13},
  year={2024},
  publisher={eLife Sciences Publications Limited}
}

@article{humans2,
  title={The Tolman-Eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation},
  author={Whittington, James CR and Muller, Timothy H and Mark, Shirley and Chen, Guifen and Barry, Caswell and Burgess, Neil and Behrens, Timothy EJ},
  journal={Cell},
  volume={183},
  number={5},
  pages={1249--1263},
  year={2020},
  publisher={Elsevier}
}

@article{humans1,
  title={A map of abstract relational knowledge in the human hippocampal--entorhinal cortex},
  author={Garvert, Mona M and Dolan, Raymond J and Behrens, Timothy EJ},
  journal={elife},
  volume={6},
  pages={e17086},
  year={2017},
  publisher={eLife Sciences Publications, Ltd}
}

@misc{gemmateam2024gemma2improvingopen,
      title={Gemma 2: Improving Open Language Models at a Practical Size}, 
      author={{Gemma Team}},
      year={2024},
      eprint={2408.00118},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.00118}, 
}

@article{dorogovtsevCriticalPhenomenaComplex2008,
  title = {Critical Phenomena in Complex Networks},
  author = {Dorogovtsev, S. N. and Goltsev, A. V. and Mendes, J. F. F.},
  year = {2008},
  month = oct,
  journal = {Reviews of Modern Physics},
  volume = {80},
  number = {4},
  pages = {1275--1335},
  publisher = {{American Physical Society}},
  urldate = {2024-02-04}
}

@article{hooyberghsPercolationBipartiteScalefree2010,
  title = {Percolation on Bipartite Scale-Free Networks},
  author = {Hooyberghs, H. and Van Schaeybroeck, B. and Indekeu, J. O.},
  year = {2010},
  month = aug,
  journal = {Physica A: Statistical Mechanics and its Applications},
  series = {Statistical, {{Fluid}} and {{Biological Physics Problems}}},
  volume = {389},
  number = {15},
  pages = {2920--2929},
  issn = {0378-4371},
  urldate = {2024-02-04},
  keywords = {Bipartite networks,Percolation,Scale-free networks,Sexual-contact network}
}

@article{newmanStructureFunctionComplex2003,
  title = {The {{Structure}} and {{Function}} of {{Complex Networks}}},
  author = {Newman, M. E. J.},
  year = {2003},
  month = jan,
  journal = {SIAM Review},
  volume = {45},
  number = {2},
  pages = {167--256},
  issn = {0036-1445, 1095-7200},
  urldate = {2024-02-04},
  langid = {english}
}

@article{callawayNetworkRobustnessFragility2000,
  title = {Network {{Robustness}} and {{Fragility}}: {{Percolation}} on {{Random Graphs}}},
  shorttitle = {Network {{Robustness}} and {{Fragility}}},
  author = {Callaway, Duncan S. and Newman, M. E. J. and Strogatz, Steven H. and Watts, Duncan J.},
  year = {2000},
  month = dec,
  journal = {Physical Review Letters},
  volume = {85},
  number = {25},
  pages = {5468--5471},
  publisher = {{American Physical Society}},
  urldate = {2024-02-04}
}

@article{chungAverageDistancesRandom2002,
  title = {The Average Distances in Random Graphs with given Expected Degrees},
  author = {Chung, Fan and Lu, Linyuan},
  year = {2002},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {99},
  number = {25},
  pages = {15879--15882},
  publisher = {{Proceedings of the National Academy of Sciences}},
  urldate = {2024-02-04}
}

@article{chungSpectraRandomGraphs2003,
  title = {Spectra of Random Graphs with given Expected Degrees},
  author = {Chung, Fan and Lu, Linyuan and Vu, Van},
  year = {2003},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {100},
  number = {11},
  pages = {6313--6318},
  publisher = {{Proceedings of the National Academy of Sciences}},
  urldate = {2024-02-04}
}

@article{brooks2024large,
  title={Large language models can implement policy iteration},
  author={Brooks, Ethan and Walls, Logan and Lewis, Richard L and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{lee2024supervised,
  title={Supervised pretraining can learn in-context reinforcement learning},
  author={Lee, Jonathan and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{laskin2022context,
  title={In-context reinforcement learning with algorithm distillation},
  author={Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and others},
  journal={arXiv preprint arXiv:2210.14215},
  year={2022}
}

@article{qin2023toolllm,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}

@Misc{towardsmonosemanticity,
  Author = {{Anthropic AI}},
  Title  = "\emph{Towards Monosemanticity: Decomposing Language Models With Dictionary Learning}",
  Note   = "\url{https://transformer-circuits.pub/2023/monosemantic-features}",
  year = 2023,
}


@Misc{scalingmonosemanticity,
  Author = {{Anthropic AI}},
  Title  = "\emph{Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet}",
  Note   = "\url{https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}",
  year = 2024,
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@misc{treutlein2024connectingdotsllmsinfer,
      title={Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data}, 
      author={Johannes Treutlein and Dami Choi and Jan Betley and Samuel Marks and Cem Anil and Roger Grosse and Owain Evans},
      year={2024},
      eprint={2406.14546},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.14546}, 
}

@misc{berglund2024reversalcursellmstrained,
      title={The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"}, 
      author={Lukas Berglund and Meg Tong and Max Kaufmann and Mikita Balesni and Asa Cooper Stickland and Tomasz Korbak and Owain Evans},
      year={2024},
      eprint={2309.12288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.12288}, 
}



@misc{huh2024platonicrepresentationhypothesis,
      title={The Platonic Representation Hypothesis}, 
      author={Minyoung Huh and Brian Cheung and Tongzhou Wang and Phillip Isola},
      year={2024},
      eprint={2405.07987},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.07987}, 
}


@misc{betley2025emergentmisalignmentnarrowfinetuning,
      title={Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs}, 
      author={Jan Betley and Daniel Tan and Niels Warncke and Anna Sztyber-Betley and Xuchan Bao and Martín Soto and Nathan Labenz and Owain Evans},
      year={2025},
      eprint={2502.17424},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.17424}, 
}

@misc{zweiger2025selfadaptinglanguagemodels,
      title={Self-Adapting Language Models}, 
      author={Adam Zweiger and Jyothish Pari and Han Guo and Ekin Akyürek and Yoon Kim and Pulkit Agrawal},
      year={2025},
      eprint={2506.10943},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.10943}, 
}

@misc{qin2025decomposingelementsproblemsolving,
      title={Decomposing Elements of Problem Solving: What "Math" Does RL Teach?}, 
      author={Tian Qin and Core Francisco Park and Mujin Kwun and Aaron Walsman and Eran Malach and Nikhil Anand and Hidenori Tanaka and David Alvarez-Melis},
      year={2025},
      eprint={2505.22756},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.22756}, 
}

@misc{yue2025doesreinforcementlearningreally,
      title={Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?}, 
      author={Yang Yue and Zhiqi Chen and Rui Lu and Andrew Zhao and Zhaokai Wang and Yang Yue and Shiji Song and Gao Huang},
      year={2025},
      eprint={2504.13837},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.13837}, 
}

@misc{zhao2025echochamberrlposttraining,
      title={Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining}, 
      author={Rosie Zhao and Alexandru Meterez and Sham Kakade and Cengiz Pehlevan and Samy Jelassi and Eran Malach},
      year={2025},
      eprint={2504.07912},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.07912}, 
}

@misc{ward2025reasoningfinetuningrepurposeslatentrepresentations,
      title={Reasoning-Finetuning Repurposes Latent Representations in Base Models}, 
      author={Jake Ward and Chuqiao Lin and Constantin Venhoff and Neel Nanda},
      year={2025},
      eprint={2507.12638},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2507.12638}, 
}

@inproceedings{
li2025tracing,
title={Tracing the representation geometry of language models from pretraining to post-training},
author={Melody Zixuan Li and Kumar Krishna Agrawal and Arna Ghosh and Komal Kumar Teru and Guillaume Lajoie and Blake Aaron Richards},
booktitle={High-dimensional Learning Dynamics 2025},
year={2025},
url={https://openreview.net/forum?id=9nKmDLXg9v}
}

@misc{ge2025evolutionconceptslanguagemodel,
      title={Evolution of Concepts in Language Model Pre-Training}, 
      author={Xuyang Ge and Wentao Shu and Jiaxing Wu and Yunhua Zhou and Zhengfu He and Xipeng Qiu},
      year={2025},
      eprint={2509.17196},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.17196}, 
}

@misc{bengio2014representationlearningreviewnew,
      title={Representation Learning: A Review and New Perspectives}, 
      author={Yoshua Bengio and Aaron Courville and Pascal Vincent},
      year={2014},
      eprint={1206.5538},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1206.5538}, 
}

@misc{wu2024reftrepresentationfinetuninglanguage,
      title={ReFT: Representation Finetuning for Language Models}, 
      author={Zhengxuan Wu and Aryaman Arora and Zheng Wang and Atticus Geiger and Dan Jurafsky and Christopher D. Manning and Christopher Potts},
      year={2024},
      eprint={2404.03592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.03592}, 
}

@misc{minder2025overcomingsparsityartifactscrosscoders,
      title={Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning}, 
      author={Julian Minder and Clément Dumas and Caden Juang and Bilal Chugtai and Neel Nanda},
      year={2025},
      eprint={2504.02922},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.02922}, 
}


@misc{park2025textitnewnewssystem2finetuning,
      title={$\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge}, 
      author={Core Francisco Park and Zechen Zhang and Hidenori Tanaka},
      year={2025},
      eprint={2505.01812},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.01812}, 
}

@misc{malladi2024finetuninglanguagemodelsjust,
      title={Fine-Tuning Language Models with Just Forward Passes}, 
      author={Sadhika Malladi and Tianyu Gao and Eshaan Nichani and Alex Damian and Jason D. Lee and Danqi Chen and Sanjeev Arora},
      year={2024},
      eprint={2305.17333},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.17333}, 
}

@misc{ilharco2023editingmodelstaskarithmetic,
      title={Editing Models with Task Arithmetic}, 
      author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Suchin Gururangan and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
      year={2023},
      eprint={2212.04089},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2212.04089}, 
}

@misc{lester2021powerscaleparameterefficientprompt,
      title={The Power of Scale for Parameter-Efficient Prompt Tuning}, 
      author={Brian Lester and Rami Al-Rfou and Noah Constant},
      year={2021},
      eprint={2104.08691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.08691}, 
}

@misc{howard2018universallanguagemodelfinetuning,
      title={Universal Language Model Fine-tuning for Text Classification}, 
      author={Jeremy Howard and Sebastian Ruder},
      year={2018},
      eprint={1801.06146},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1801.06146}, 
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{peters2018deepcontextualizedwordrepresentations,
      title={Deep contextualized word representations}, 
      author={Matthew E. Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer},
      year={2018},
      eprint={1802.05365},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1802.05365}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{simonyan2015deepconvolutionalnetworkslargescale,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@misc{baker2022videopretrainingvptlearning,
      title={Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos}, 
      author={Bowen Baker and Ilge Akkaya and Peter Zhokhov and Joost Huizinga and Jie Tang and Adrien Ecoffet and Brandon Houghton and Raul Sampedro and Jeff Clune},
      year={2022},
      eprint={2206.11795},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.11795}, 
}

@article{chen2021multiple,
  title={Multiple descent: Design your own generalization curve},
  author={Chen, Lin and Min, Yifei and Belkin, Mikhail and Karbasi, Amin},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8898--8912},
  year={2021}
}

@misc{simateam2024scalinginstructableagentssimulated,
      title={Scaling Instructable Agents Across Many Simulated Worlds}, 
      author={SIMA Team and Maria Abi Raad and Arun Ahuja and Catarina Barros and Frederic Besse and Andrew Bolt and Adrian Bolton and Bethanie Brownfield and Gavin Buttimore and Max Cant and Sarah Chakera and Stephanie C. Y. Chan and Jeff Clune and Adrian Collister and Vikki Copeman and Alex Cullum and Ishita Dasgupta and Dario de Cesare and Julia Di Trapani and Yani Donchev and Emma Dunleavy and Martin Engelcke and Ryan Faulkner and Frankie Garcia and Charles Gbadamosi and Zhitao Gong and Lucy Gonzales and Kshitij Gupta and Karol Gregor and Arne Olav Hallingstad and Tim Harley and Sam Haves and Felix Hill and Ed Hirst and Drew A. Hudson and Jony Hudson and Steph Hughes-Fitt and Danilo J. Rezende and Mimi Jasarevic and Laura Kampis and Rosemary Ke and Thomas Keck and Junkyung Kim and Oscar Knagg and Kavya Kopparapu and Rory Lawton and Andrew Lampinen and Shane Legg and Alexander Lerchner and Marjorie Limont and Yulan Liu and Maria Loks-Thompson and Joseph Marino and Kathryn Martin Cussons and Loic Matthey and Siobhan Mcloughlin and Piermaria Mendolicchio and Hamza Merzic and Anna Mitenkova and Alexandre Moufarek and Valeria Oliveira and Yanko Oliveira and Hannah Openshaw and Renke Pan and Aneesh Pappu and Alex Platonov and Ollie Purkiss and David Reichert and John Reid and Pierre Harvey Richemond and Tyson Roberts and Giles Ruscoe and Jaume Sanchez Elias and Tasha Sandars and Daniel P. Sawyer and Tim Scholtes and Guy Simmons and Daniel Slater and Hubert Soyer and Heiko Strathmann and Peter Stys and Allison C. Tam and Denis Teplyashin and Tayfun Terzi and Davide Vercelli and Bojan Vujatovic and Marcus Wainwright and Jane X. Wang and Zhengdong Wang and Daan Wierstra and Duncan Williams and Nathaniel Wong and Sarah York and Nick Young},
      year={2024},
      eprint={2404.10179},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2404.10179}, 
}

@article{wei2022inverse,
  title={Inverse scaling can become u-shaped},
  author={Wei, Jason and Kim, Najoung and Tay, Yi and Le, Quoc V},
  journal={arXiv preprint arXiv:2211.02011},
  year={2022}
}

@article{viering2022shape,
  title={The shape of learning curves: a review},
  author={Viering, Tom and Loog, Marco},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={6},
  pages={7799--7819},
  year={2022},
  publisher={IEEE}
}



@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


% Encoding: UTF-8

@Article{Samuel59,
  author  = {A. L. Samuel},
  title   = {Some Studies in Machine Learning Using the Game of Checkers},
  journal = {IBM Journal of Research and Development},
  year    = {1959},
  volume  = {3},
  number  = {3},
  pages   = {211--229},
}


@article{jasche2019physical,
  title={Physical Bayesian modelling of the non-linear matter distribution: new insights into the Nearby Universe},
  author={Jasche, Jens and Lavaux, Guilhem},
  journal={Astronomy \& Astrophysics},
  volume={625},
  pages={A64},
  year={2019},
  publisher={EDP Sciences}
}

@software{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = mar,
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}




@misc{loshchilov2019decoupled,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2018group,
      title={Group Normalization}, 
      author={Yuxin Wu and Kaiming He},
      year={2018},
      eprint={1803.08494},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{paszke2019pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Tully_2016,
   title={COSMICFLOWS-3},
   volume={152},
   ISSN={1538-3881},
   url={http://dx.doi.org/10.3847/0004-6256/152/2/50},
   DOI={10.3847/0004-6256/152/2/50},
   number={2},
   journal={The Astronomical Journal},
   publisher={American Astronomical Society},
   author={Tully, R. Brent and Courtois, Hélène M. and Sorce, Jenny G.},
   year={2016},
   month=aug, pages={50} }

@article{Ni_2022,
   title={The ASTRID simulation: the evolution of supermassive black holes},
   volume={513},
   ISSN={1365-2966},
   url={http://dx.doi.org/10.1093/mnras/stac351},
   DOI={10.1093/mnras/stac351},
   number={1},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Ni, Yueying and Di Matteo, Tiziana and Bird, Simeon and Croft, Rupert and Feng, Yu and Chen, Nianyi and Tremmel, Michael and DeGraf, Colin and Li, Yin},
   year={2022},
   month=feb, pages={670–692} }


@misc{ramesh2021zeroshot,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{park2023probabilistic,
      title={Probabilistic reconstruction of Dark Matter fields from biased tracers using diffusion models}, 
      author={Core Francisco Park and Victoria Ono and Nayantara Mudur and Yueying Ni and Carolina Cuesta-Lazaro},
      year={2023},
      eprint={2311.08558},
      archivePrefix={arXiv},
      primaryClass={astro-ph.CO}
}

@misc{ono2024debiasing,
      title={Debiasing with Diffusion: Probabilistic reconstruction of Dark Matter fields from galaxies with CAMELS}, 
      author={Victoria Ono and Core Francisco Park and Nayantara Mudur and Yueying Ni and Carolina Cuesta-Lazaro and Francisco Villaescusa-Navarro},
      year={2024},
      eprint={2403.10648},
      archivePrefix={arXiv},
      primaryClass={astro-ph.CO}
}

@article{park2023quantification,
  title={Quantification of High-dimensional Non-Gaussianities and Its Implication to Fisher Analysis in Cosmology},
  author={Park, Core Francisco and Allys, Erwan and Villaescusa-Navarro, Francisco and Finkbeiner, Douglas},
  journal={The Astrophysical Journal},
  volume={946},
  number={2},
  pages={107},
  year={2023},
  publisher={IOP Publishing}
}

@article{Regaldo_Saint_Blancard_2020,
   title={Statistical description of dust polarized emission from the diffuse interstellar medium: A RWST approach},
   volume={642},
   ISSN={1432-0746},
   url={http://dx.doi.org/10.1051/0004-6361/202038044},
   DOI={10.1051/0004-6361/202038044},
   journal={Astronomy \& Astrophysics},
   publisher={EDP Sciences},
   author={Regaldo-Saint Blancard, B. and Levrier, F. and Allys, E. and Bellomi, E. and Boulanger, F.},
   year={2020},
   month=oct, pages={A217} }


@article{legin2024posterior,
  title={Posterior sampling of the initial conditions of the universe from non-linear large scale structures using score-based generative models},
  author={Legin, Ronan and Ho, Matthew and Lemos, Pablo and Perreault-Levasseur, Laurence and Ho, Shirley and Hezaveh, Yashar and Wandelt, Benjamin},
  journal={Monthly Notices of the Royal Astronomical Society: Letters},
  volume={527},
  number={1},
  pages={L173--L178},
  year={2024},
  publisher={Oxford University Press}
}

@misc{rombach2022highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{saharia2022photorealistic,
      title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding}, 
      author={Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily Denton and Seyed Kamyar Seyed Ghasemipour and Burcu Karagol Ayan and S. Sara Mahdavi and Rapha Gontijo Lopes and Tim Salimans and Jonathan Ho and David J Fleet and Mohammad Norouzi},
      year={2022},
      eprint={2205.11487},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{kingma2021variational,
  title={Variational diffusion models},
  author={Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={21696--21707},
  year={2021}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{villaescusa2020quijote,
  title={The quijote simulations},
  author={Villaescusa-Navarro, Francisco and Hahn, ChangHoon and Massara, Elena and Banerjee, Arka and Delgado, Ana Maria and Ramanah, Doogesh Kodi and Charnock, Tom and Giusarma, Elena and Li, Yin and Allys, Erwan and others},
  journal={The Astrophysical Journal Supplement Series},
  volume={250},
  number={1},
  pages={2},
  year={2020},
  publisher={IOP Publishing}
}

@article{garrison2019high,
  title={A high-fidelity realization of the Euclid code comparison N-body simulation with ABACUS},
  author={Garrison, Lehman H and Eisenstein, Daniel J and Pinto, Philip A},
  journal={Monthly Notices of the Royal Astronomical Society},
  volume={485},
  number={3},
  pages={3370--3377},
  year={2019},
  publisher={Oxford University Press}
}

@article{springel2005simulations,
  title={Simulations of the formation, evolution and clustering of galaxies and quasars},
  author={Springel, Volker and White, Simon DM and Jenkins, Adrian and Frenk, Carlos S and Yoshida, Naoki and Gao, Liang and Navarro, Julio and Thacker, Robert and Croton, Darren and Helly, John and others},
  journal={nature},
  volume={435},
  number={7042},
  pages={629--636},
  year={2005},
  publisher={Nature Publishing Group UK London}
}

@article{Nelson_2015,
   title={The illustris simulation: Public data release},
   volume={13},
   ISSN={2213-1337},
   url={http://dx.doi.org/10.1016/j.ascom.2015.09.003},
   DOI={10.1016/j.ascom.2015.09.003},
   journal={Astronomy and Computing},
   publisher={Elsevier BV},
   author={Nelson, D. and Pillepich, A. and Genel, S. and Vogelsberger, M. and Springel, V. and Torrey, P. and Rodriguez-Gomez, V. and Sijacki, D. and Snyder, G.F. and Griffen, B. and Marinacci, F. and Blecha, L. and Sales, L. and Xu, D. and Hernquist, L.},
   year={2015},
   month=nov, pages={12–37} }


@ARTICLE{CMD,
    author = {{Villaescusa-Navarro}, Francisco and {Genel}, Shy and {Angles-Alcazar}, Daniel and {Thiele}, Leander and {Dave}, Romeel and {Narayanan}, Desika and {Nicola}, Andrina and {Li}, Yin and {Villanueva-Domingo}, Pablo and {Wandelt}, Benjamin and {Spergel}, David N. and {Somerville}, Rachel S. and {Zorrilla Matilla}, Jose Manuel and {Mohammad}, Faizan G. and {Hassan}, Sultan and {Shao}, Helen and {Wadekar}, Digvijay and {Eickenberg}, Michael and {Wong}, Kaze W.~K. and {Contardo}, Gabriella and {Jo}, Yongseok and {Moser}, Emily and {Lau}, Erwin T. and {Machado Poletti Valle}, Luis Fernando and {Perez}, Lucia A. and {Nagai}, Daisuke and {Battaglia}, Nicholas and {Vogelsberger}, Mark},
     title = "{The CAMELS Multifield Dataset: Learning the Universe's Fundamental Parameters with Artificial Intelligence}",
   journal = {arXiv e-prints},
  keywords = {Computer Science - Machine Learning, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Astrophysics of Galaxies, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Computer Vision and Pattern Recognition},
      year = 2021,
     month = sep,
     eid = {arXiv:2109.10915},
     pages = {arXiv:2109.10915},
     archivePrefix = {arXiv},
     eprint = {2109.10915},
     primaryClass = {cs.LG},
     adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210910915V},
     adsnote = {Provided by the SAO/NASA Astrophysics Data System}
     }

@ARTICLE{CAMELS,
    author = {{Villaescusa-Navarro}, Francisco and {Angl{\'e}s-Alc{\'a}zar}, Daniel and {Genel}, Shy and {Spergel}, David N. and {Somerville}, Rachel S. and {Dave}, Romeel and {Pillepich}, Annalisa and {Hernquist}, Lars and {Nelson}, Dylan and {Torrey}, Paul and {Narayanan}, Desika and {Li}, Yin and {Philcox}, Oliver and {La Torre}, Valentina and {Maria Delgado}, Ana and {Ho}, Shirley and {Hassan}, Sultan and {Burkhart}, Blakesley and {Wadekar}, Digvijay and {Battaglia}, Nicholas and {Contardo}, Gabriella and {Bryan}, Greg L.},
     title = "{The CAMELS Project: Cosmology and Astrophysics with Machine-learning Simulations}",
   journal = {Apj},
  keywords = {Cosmology, Cosmological parameters from large-scale structure, Galaxy formation, Astrostatistics, 343, 340, 595, 1882, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Astrophysics of Galaxies, Astrophysics - Instrumentation and Methods for Astrophysics},
      year = 2021,
     month = jul,
    volume = {915},
    number = {1},
       eid = {71},
     pages = {71},
       doi = {10.3847/1538-4357/abf7ba},
     archivePrefix = {arXiv},
  eprint = {2010.00619},
  primaryClass = {astro-ph.CO},
    adsurl = {https://ui.adsabs.harvard.edu/abs/2021ApJ...915...71V},
   adsnote = {Provided by the SAO/NASA Astrophysics Data System}
   }

@misc{bruna2012invariant,
      title={Invariant Scattering Convolution Networks}, 
      author={Joan Bruna and Stéphane Mallat},
      year={2012},
      eprint={1203.1513},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{DESI2016arXiv161100036D,
       author = {{DESI Collaboration} and {Aghamousa}, Amir and {Aguilar}, Jessica and {Ahlen}, Steve and {Alam}, Shadab and {Allen}, Lori E. and {Allende Prieto}, Carlos and {Annis}, James and {Bailey}, Stephen and {Balland}, Christophe and {Ballester}, Otger and {Baltay}, Charles and {Beaufore}, Lucas and {Bebek}, Chris and {Beers}, Timothy C. and {Bell}, Eric F. and {Bernal}, Jos{\'e} Luis and {Besuner}, Robert and {Beutler}, Florian and {Blake}, Chris and {Bleuler}, Hannes and {Blomqvist}, Michael and {Blum}, Robert and {Bolton}, Adam S. and {Briceno}, Cesar and {Brooks}, David and {Brownstein}, Joel R. and {Buckley-Geer}, Elizabeth and {Burden}, Angela and {Burtin}, Etienne and {Busca}, Nicolas G. and {Cahn}, Robert N. and {Cai}, Yan-Chuan and {Cardiel-Sas}, Laia and {Carlberg}, Raymond G. and {Carton}, Pierre-Henri and {Casas}, Ricard and {Castander}, Francisco J. and {Cervantes-Cota}, Jorge L. and {Claybaugh}, Todd M. and {Close}, Madeline and {Coker}, Carl T. and {Cole}, Shaun and {Comparat}, Johan and {Cooper}, Andrew P. and {Cousinou}, M. -C. and {Crocce}, Martin and {Cuby}, Jean-Gabriel and {Cunningham}, Daniel P. and {Davis}, Tamara M. and {Dawson}, Kyle S. and {de la Macorra}, Axel and {De Vicente}, Juan and {Delubac}, Timoth{\'e}e and {Derwent}, Mark and {Dey}, Arjun and {Dhungana}, Govinda and {Ding}, Zhejie and {Doel}, Peter and {Duan}, Yutong T. and {Ealet}, Anne and {Edelstein}, Jerry and {Eftekharzadeh}, Sarah and {Eisenstein}, Daniel J. and {Elliott}, Ann and {Escoffier}, St{\'e}phanie and {Evatt}, Matthew and {Fagrelius}, Parker and {Fan}, Xiaohui and {Fanning}, Kevin and {Farahi}, Arya and {Farihi}, Jay and {Favole}, Ginevra and {Feng}, Yu and {Fernandez}, Enrique and {Findlay}, Joseph R. and {Finkbeiner}, Douglas P. and {Fitzpatrick}, Michael J. and {Flaugher}, Brenna and {Flender}, Samuel and {Font-Ribera}, Andreu and {Forero-Romero}, Jaime E. and {Fosalba}, Pablo and {Frenk}, Carlos S. and {Fumagalli}, Michele and {Gaensicke}, Boris T. and {Gallo}, Giuseppe and {Garcia-Bellido}, Juan and {Gaztanaga}, Enrique and {Pietro Gentile Fusillo}, Nicola and {Gerard}, Terry and {Gershkovich}, Irena and {Giannantonio}, Tommaso and {Gillet}, Denis and {Gonzalez-de-Rivera}, Guillermo and {Gonzalez-Perez}, Violeta and {Gott}, Shelby and {Graur}, Or and {Gutierrez}, Gaston and {Guy}, Julien and {Habib}, Salman and {Heetderks}, Henry and {Heetderks}, Ian and {Heitmann}, Katrin and {Hellwing}, Wojciech A. and {Herrera}, David A. and {Ho}, Shirley and {Holland}, Stephen and {Honscheid}, Klaus and {Huff}, Eric and {Hutchinson}, Timothy A. and {Huterer}, Dragan and {Hwang}, Ho Seong and {Illa Laguna}, Joseph Maria and {Ishikawa}, Yuzo and {Jacobs}, Dianna and {Jeffrey}, Niall and {Jelinsky}, Patrick and {Jennings}, Elise and {Jiang}, Linhua and {Jimenez}, Jorge and {Johnson}, Jennifer and {Joyce}, Richard and {Jullo}, Eric and {Juneau}, St{\'e}phanie and {Kama}, Sami and {Karcher}, Armin and {Karkar}, Sonia and {Kehoe}, Robert and {Kennamer}, Noble and {Kent}, Stephen and {Kilbinger}, Martin and {Kim}, Alex G. and {Kirkby}, David and {Kisner}, Theodore and {Kitanidis}, Ellie and {Kneib}, Jean-Paul and {Koposov}, Sergey and {Kovacs}, Eve and {Koyama}, Kazuya and {Kremin}, Anthony and {Kron}, Richard and {Kronig}, Luzius and {Kueter-Young}, Andrea and {Lacey}, Cedric G. and {Lafever}, Robin and {Lahav}, Ofer and {Lambert}, Andrew and {Lampton}, Michael and {Landriau}, Martin and {Lang}, Dustin and {Lauer}, Tod R. and {Le Goff}, Jean-Marc and {Le Guillou}, Laurent and {Le Van Suu}, Auguste and {Lee}, Jae Hyeon and {Lee}, Su-Jeong and {Leitner}, Daniela and {Lesser}, Michael and {Levi}, Michael E. and {L'Huillier}, Benjamin and {Li}, Baojiu and {Liang}, Ming and {Lin}, Huan and {Linder}, Eric and {Loebman}, Sarah R. and {Luki{\'c}}, Zarija and {Ma}, Jun and {MacCrann}, Niall and {Magneville}, Christophe and {Makarem}, Laleh and {Manera}, Marc and {Manser}, Christopher J. and {Marshall}, Robert and {Martini}, Paul and {Massey}, Richard and {Matheson}, Thomas and {McCauley}, Jeremy and {McDonald}, Patrick and {McGreer}, Ian D. and {Meisner}, Aaron and {Metcalfe}, Nigel and {Miller}, Timothy N. and {Miquel}, Ramon and {Moustakas}, John and {Myers}, Adam and {Naik}, Milind and {Newman}, Jeffrey A. and {Nichol}, Robert C. and {Nicola}, Andrina and {Nicolati da Costa}, Luiz and {Nie}, Jundan and {Niz}, Gustavo and {Norberg}, Peder and {Nord}, Brian and {Norman}, Dara and {Nugent}, Peter and {O'Brien}, Thomas and {Oh}, Minji and {Olsen}, Knut A.~G. and {Padilla}, Cristobal and {Padmanabhan}, Hamsa and {Padmanabhan}, Nikhil and {Palanque-Delabrouille}, Nathalie and {Palmese}, Antonella and {Pappalardo}, Daniel and {P{\^a}ris}, Isabelle and {Park}, Changbom and {Patej}, Anna and {Peacock}, John A. and {Peiris}, Hiranya V. and {Peng}, Xiyan and {Percival}, Will J. and {Perruchot}, Sandrine and {Pieri}, Matthew M. and {Pogge}, Richard and {Pollack}, Jennifer E. and {Poppett}, Claire and {Prada}, Francisco and {Prakash}, Abhishek and {Probst}, Ronald G. and {Rabinowitz}, David and {Raichoor}, Anand and {Ree}, Chang Hee and {Refregier}, Alexandre and {Regal}, Xavier and {Reid}, Beth and {Reil}, Kevin and {Rezaie}, Mehdi and {Rockosi}, Constance M. and {Roe}, Natalie and {Ronayette}, Samuel and {Roodman}, Aaron and {Ross}, Ashley J. and {Ross}, Nicholas P. and {Rossi}, Graziano and {Rozo}, Eduardo and {Ruhlmann-Kleider}, Vanina and {Rykoff}, Eli S. and {Sabiu}, Cristiano and {Samushia}, Lado and {Sanchez}, Eusebio and {Sanchez}, Javier and {Schlegel}, David J. and {Schneider}, Michael and {Schubnell}, Michael and {Secroun}, Aur{\'e}lia and {Seljak}, Uros and {Seo}, Hee-Jong and {Serrano}, Santiago and {Shafieloo}, Arman and {Shan}, Huanyuan and {Sharples}, Ray and {Sholl}, Michael J. and {Shourt}, William V. and {Silber}, Joseph H. and {Silva}, David R. and {Sirk}, Martin M. and {Slosar}, Anze and {Smith}, Alex and {Smoot}, George F. and {Som}, Debopam and {Song}, Yong-Seon and {Sprayberry}, David and {Staten}, Ryan and {Stefanik}, Andy and {Tarle}, Gregory and {Sien Tie}, Suk and {Tinker}, Jeremy L. and {Tojeiro}, Rita and {Valdes}, Francisco and {Valenzuela}, Octavio and {Valluri}, Monica and {Vargas-Magana}, Mariana and {Verde}, Licia and {Walker}, Alistair R. and {Wang}, Jiali and {Wang}, Yuting and {Weaver}, Benjamin A. and {Weaverdyck}, Curtis and {Wechsler}, Risa H. and {Weinberg}, David H. and {White}, Martin and {Yang}, Qian and {Yeche}, Christophe and {Zhang}, Tianmeng and {Zhao}, Gong-Bo and {Zheng}, Yi and {Zhou}, Xu and {Zhou}, Zhimin and {Zhu}, Yaling and {Zou}, Hu and {Zu}, Ying},
        title = "{The DESI Experiment Part I: Science,Targeting, and Survey Design}",
      journal = {arXiv e-prints},
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Cosmology and Nongalactic Astrophysics},
         year = 2016,
        month = oct,
          eid = {arXiv:1611.00036},
        pages = {arXiv:1611.00036},
          doi = {10.48550/arXiv.1611.00036},
archivePrefix = {arXiv},
       eprint = {1611.00036},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv161100036D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Spergel2015arXiv150303757S,
       author = {{Spergel}, D. and {Gehrels}, N. and {Baltay}, C. and {Bennett}, D. and {Breckinridge}, J. and {Donahue}, M. and {Dressler}, A. and {Gaudi}, B.~S. and {Greene}, T. and {Guyon}, O. and {Hirata}, C. and {Kalirai}, J. and {Kasdin}, N.~J. and {Macintosh}, B. and {Moos}, W. and {Perlmutter}, S. and {Postman}, M. and {Rauscher}, B. and {Rhodes}, J. and {Wang}, Y. and {Weinberg}, D. and {Benford}, D. and {Hudson}, M. and {Jeong}, W. -S. and {Mellier}, Y. and {Traub}, W. and {Yamada}, T. and {Capak}, P. and {Colbert}, J. and {Masters}, D. and {Penny}, M. and {Savransky}, D. and {Stern}, D. and {Zimmerman}, N. and {Barry}, R. and {Bartusek}, L. and {Carpenter}, K. and {Cheng}, E. and {Content}, D. and {Dekens}, F. and {Demers}, R. and {Grady}, K. and {Jackson}, C. and {Kuan}, G. and {Kruk}, J. and {Melton}, M. and {Nemati}, B. and {Parvin}, B. and {Poberezhskiy}, I. and {Peddie}, C. and {Ruffa}, J. and {Wallace}, J.~K. and {Whipple}, A. and {Wollack}, E. and {Zhao}, F.},
        title = "{Wide-Field InfrarRed Survey Telescope-Astrophysics Focused Telescope Assets WFIRST-AFTA 2015 Report}",
      journal = {arXiv e-prints},
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2015,
        month = mar,
          eid = {arXiv:1503.03757},
        pages = {arXiv:1503.03757},
          doi = {10.48550/arXiv.1503.03757},
archivePrefix = {arXiv},
       eprint = {1503.03757},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150303757S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Laureijs2011arXiv1110.3193L,
       author = {{Laureijs}, R. and {Amiaux}, J. and {Arduini}, S. and {Augu{\`e}res}, J. -L. and {Brinchmann}, J. and {Cole}, R. and {Cropper}, M. and {Dabin}, C. and {Duvet}, L. and {Ealet}, A. and {Garilli}, B. and {Gondoin}, P. and {Guzzo}, L. and {Hoar}, J. and {Hoekstra}, H. and {Holmes}, R. and {Kitching}, T. and {Maciaszek}, T. and {Mellier}, Y. and {Pasian}, F. and {Percival}, W. and {Rhodes}, J. and {Saavedra Criado}, G. and {Sauvage}, M. and {Scaramella}, R. and {Valenziano}, L. and {Warren}, S. and {Bender}, R. and {Castander}, F. and {Cimatti}, A. and {Le F{\`e}vre}, O. and {Kurki-Suonio}, H. and {Levi}, M. and {Lilje}, P. and {Meylan}, G. and {Nichol}, R. and {Pedersen}, K. and {Popa}, V. and {Rebolo Lopez}, R. and {Rix}, H. -W. and {Rottgering}, H. and {Zeilinger}, W. and {Grupp}, F. and {Hudelot}, P. and {Massey}, R. and {Meneghetti}, M. and {Miller}, L. and {Paltani}, S. and {Paulin-Henriksson}, S. and {Pires}, S. and {Saxton}, C. and {Schrabback}, T. and {Seidel}, G. and {Walsh}, J. and {Aghanim}, N. and {Amendola}, L. and {Bartlett}, J. and {Baccigalupi}, C. and {Beaulieu}, J. -P. and {Benabed}, K. and {Cuby}, J. -G. and {Elbaz}, D. and {Fosalba}, P. and {Gavazzi}, G. and {Helmi}, A. and {Hook}, I. and {Irwin}, M. and {Kneib}, J. -P. and {Kunz}, M. and {Mannucci}, F. and {Moscardini}, L. and {Tao}, C. and {Teyssier}, R. and {Weller}, J. and {Zamorani}, G. and {Zapatero Osorio}, M.~R. and {Boulade}, O. and {Foumond}, J.~J. and {Di Giorgio}, A. and {Guttridge}, P. and {James}, A. and {Kemp}, M. and {Martignac}, J. and {Spencer}, A. and {Walton}, D. and {Bl{\"u}mchen}, T. and {Bonoli}, C. and {Bortoletto}, F. and {Cerna}, C. and {Corcione}, L. and {Fabron}, C. and {Jahnke}, K. and {Ligori}, S. and {Madrid}, F. and {Martin}, L. and {Morgante}, G. and {Pamplona}, T. and {Prieto}, E. and {Riva}, M. and {Toledo}, R. and {Trifoglio}, M. and {Zerbi}, F. and {Abdalla}, F. and {Douspis}, M. and {Grenet}, C. and {Borgani}, S. and {Bouwens}, R. and {Courbin}, F. and {Delouis}, J. -M. and {Dubath}, P. and {Fontana}, A. and {Frailis}, M. and {Grazian}, A. and {Koppenh{\"o}fer}, J. and {Mansutti}, O. and {Melchior}, M. and {Mignoli}, M. and {Mohr}, J. and {Neissner}, C. and {Noddle}, K. and {Poncet}, M. and {Scodeggio}, M. and {Serrano}, S. and {Shane}, N. and {Starck}, J. -L. and {Surace}, C. and {Taylor}, A. and {Verdoes-Kleijn}, G. and {Vuerli}, C. and {Williams}, O.~R. and {Zacchei}, A. and {Altieri}, B. and {Escudero Sanz}, I. and {Kohley}, R. and {Oosterbroek}, T. and {Astier}, P. and {Bacon}, D. and {Bardelli}, S. and {Baugh}, C. and {Bellagamba}, F. and {Benoist}, C. and {Bianchi}, D. and {Biviano}, A. and {Branchini}, E. and {Carbone}, C. and {Cardone}, V. and {Clements}, D. and {Colombi}, S. and {Conselice}, C. and {Cresci}, G. and {Deacon}, N. and {Dunlop}, J. and {Fedeli}, C. and {Fontanot}, F. and {Franzetti}, P. and {Giocoli}, C. and {Garcia-Bellido}, J. and {Gow}, J. and {Heavens}, A. and {Hewett}, P. and {Heymans}, C. and {Holland}, A. and {Huang}, Z. and {Ilbert}, O. and {Joachimi}, B. and {Jennins}, E. and {Kerins}, E. and {Kiessling}, A. and {Kirk}, D. and {Kotak}, R. and {Krause}, O. and {Lahav}, O. and {van Leeuwen}, F. and {Lesgourgues}, J. and {Lombardi}, M. and {Magliocchetti}, M. and {Maguire}, K. and {Majerotto}, E. and {Maoli}, R. and {Marulli}, F. and {Maurogordato}, S. and {McCracken}, H. and {McLure}, R. and {Melchiorri}, A. and {Merson}, A. and {Moresco}, M. and {Nonino}, M. and {Norberg}, P. and {Peacock}, J. and {Pello}, R. and {Penny}, M. and {Pettorino}, V. and {Di Porto}, C. and {Pozzetti}, L. and {Quercellini}, C. and {Radovich}, M. and {Rassat}, A. and {Roche}, N. and {Ronayette}, S. and {Rossetti}, E. and {Sartoris}, B. and {Schneider}, P. and {Semboloni}, E. and {Serjeant}, S. and {Simpson}, F. and {Skordis}, C. and {Smadja}, G. and {Smartt}, S. and {Spano}, P. and {Spiro}, S. and {Sullivan}, M. and {Tilquin}, A. and {Trotta}, R. and {Verde}, L. and {Wang}, Y. and {Williger}, G. and {Zhao}, G. and {Zoubian}, J. and {Zucca}, E.},
        title = "{Euclid Definition Study Report}",
      journal = {arXiv e-prints},
     keywords = {Astrophysics - Cosmology and Extragalactic Astrophysics, Astrophysics - Galaxy Astrophysics},
         year = 2011,
        month = oct,
          eid = {arXiv:1110.3193},
        pages = {arXiv:1110.3193},
          doi = {10.48550/arXiv.1110.3193},
archivePrefix = {arXiv},
       eprint = {1110.3193},
 primaryClass = {astro-ph.CO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2011arXiv1110.3193L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{LSST2009arXiv0912.0201L,
       author = {{LSST Science Collaboration} and {Abell}, Paul A. and {Allison}, Julius and {Anderson}, Scott F. and {Andrew}, John R. and {Angel}, J. Roger P. and {Armus}, Lee and {Arnett}, David and {Asztalos}, S.~J. and {Axelrod}, Tim S. and {Bailey}, Stephen and {Ballantyne}, D.~R. and {Bankert}, Justin R. and {Barkhouse}, Wayne A. and {Barr}, Jeffrey D. and {Barrientos}, L. Felipe and {Barth}, Aaron J. and {Bartlett}, James G. and {Becker}, Andrew C. and {Becla}, Jacek and {Beers}, Timothy C. and {Bernstein}, Joseph P. and {Biswas}, Rahul and {Blanton}, Michael R. and {Bloom}, Joshua S. and {Bochanski}, John J. and {Boeshaar}, Pat and {Borne}, Kirk D. and {Bradac}, Marusa and {Brandt}, W.~N. and {Bridge}, Carrie R. and {Brown}, Michael E. and {Brunner}, Robert J. and {Bullock}, James S. and {Burgasser}, Adam J. and {Burge}, James H. and {Burke}, David L. and {Cargile}, Phillip A. and {Chandrasekharan}, Srinivasan and {Chartas}, George and {Chesley}, Steven R. and {Chu}, You-Hua and {Cinabro}, David and {Claire}, Mark W. and {Claver}, Charles F. and {Clowe}, Douglas and {Connolly}, A.~J. and {Cook}, Kem H. and {Cooke}, Jeff and {Cooray}, Asantha and {Covey}, Kevin R. and {Culliton}, Christopher S. and {de Jong}, Roelof and {de Vries}, Willem H. and {Debattista}, Victor P. and {Delgado}, Francisco and {Dell'Antonio}, Ian P. and {Dhital}, Saurav and {Di Stefano}, Rosanne and {Dickinson}, Mark and {Dilday}, Benjamin and {Djorgovski}, S.~G. and {Dobler}, Gregory and {Donalek}, Ciro and {Dubois-Felsmann}, Gregory and {Durech}, Josef and {Eliasdottir}, Ardis and {Eracleous}, Michael and {Eyer}, Laurent and {Falco}, Emilio E. and {Fan}, Xiaohui and {Fassnacht}, Christopher D. and {Ferguson}, Harry C. and {Fernandez}, Yanga R. and {Fields}, Brian D. and {Finkbeiner}, Douglas and {Figueroa}, Eduardo E. and {Fox}, Derek B. and {Francke}, Harold and {Frank}, James S. and {Frieman}, Josh and {Fromenteau}, Sebastien and {Furqan}, Muhammad and {Galaz}, Gaspar and {Gal-Yam}, A. and {Garnavich}, Peter and {Gawiser}, Eric and {Geary}, John and {Gee}, Perry and {Gibson}, Robert R. and {Gilmore}, Kirk and {Grace}, Emily A. and {Green}, Richard F. and {Gressler}, William J. and {Grillmair}, Carl J. and {Habib}, Salman and {Haggerty}, J.~S. and {Hamuy}, Mario and {Harris}, Alan W. and {Hawley}, Suzanne L. and {Heavens}, Alan F. and {Hebb}, Leslie and {Henry}, Todd J. and {Hileman}, Edward and {Hilton}, Eric J. and {Hoadley}, Keri and {Holberg}, J.~B. and {Holman}, Matt J. and {Howell}, Steve B. and {Infante}, Leopoldo and {Ivezic}, Zeljko and {Jacoby}, Suzanne H. and {Jain}, Bhuvnesh and {R} and {Jedicke} and {Jee}, M. James and {Garrett Jernigan}, J. and {Jha}, Saurabh W. and {Johnston}, Kathryn V. and {Jones}, R. Lynne and {Juric}, Mario and {Kaasalainen}, Mikko and {Styliani} and {Kafka} and {Kahn}, Steven M. and {Kaib}, Nathan A. and {Kalirai}, Jason and {Kantor}, Jeff and {Kasliwal}, Mansi M. and {Keeton}, Charles R. and {Kessler}, Richard and {Knezevic}, Zoran and {Kowalski}, Adam and {Krabbendam}, Victor L. and {Krughoff}, K. Simon and {Kulkarni}, Shrinivas and {Kuhlman}, Stephen and {Lacy}, Mark and {Lepine}, Sebastien and {Liang}, Ming and {Lien}, Amy and {Lira}, Paulina and {Long}, Knox S. and {Lorenz}, Suzanne and {Lotz}, Jennifer M. and {Lupton}, R.~H. and {Lutz}, Julie and {Macri}, Lucas M. and {Mahabal}, Ashish A. and {Mandelbaum}, Rachel and {Marshall}, Phil and {May}, Morgan and {McGehee}, Peregrine M. and {Meadows}, Brian T. and {Meert}, Alan and {Milani}, Andrea and {Miller}, Christopher J. and {Miller}, Michelle and {Mills}, David and {Minniti}, Dante and {Monet}, David and {Mukadam}, Anjum S. and {Nakar}, Ehud and {Neill}, Douglas R. and {Newman}, Jeffrey A. and {Nikolaev}, Sergei and {Nordby}, Martin and {O'Connor}, Paul and {Oguri}, Masamune and {Oliver}, John and {Olivier}, Scot S. and {Olsen}, Julia K. and {Olsen}, Knut and {Olszewski}, Edward W. and {Oluseyi}, Hakeem and {Padilla}, Nelson D. and {Parker}, Alex and {Pepper}, Joshua and {Peterson}, John R. and {Petry}, Catherine and {Pinto}, Philip A. and {Pizagno}, James L. and {Popescu}, Bogdan and {Prsa}, Andrej and {Radcka}, Veljko and {Raddick}, M. Jordan and {Rasmussen}, Andrew and {Rau}, Arne and {Rho}, Jeonghee and {Rhoads}, James E. and {Richards}, Gordon T. and {Ridgway}, Stephen T. and {Robertson}, Brant E. and {Roskar}, Rok and {Saha}, Abhijit and {Sarajedini}, Ata and {Scannapieco}, Evan and {Schalk}, Terry and {Schindler}, Rafe and {Schmidt}, Samuel and {Schmidt}, Sarah and {Schneider}, Donald P. and {Schumacher}, German and {Scranton}, Ryan and {Sebag}, Jacques and {Seppala}, Lynn G. and {Shemmer}, Ohad and {Simon}, Joshua D. and {Sivertz}, M. and {Smith}, Howard A. and {Allyn Smith}, J. and {Smith}, Nathan and {Spitz}, Anna H. and {Stanford}, Adam and {Stassun}, Keivan G. and {Strader}, Jay and {Strauss}, Michael A. and {Stubbs}, Christopher W. and {Sweeney}, Donald W. and {Szalay}, Alex and {Szkody}, Paula and {Takada}, Masahiro and {Thorman}, Paul and {Trilling}, David E. and {Trimble}, Virginia and {Tyson}, Anthony and {Van Berg}, Richard and {Vanden Berk}, Daniel and {VanderPlas}, Jake and {Verde}, Licia and {Vrsnak}, Bojan and {Walkowicz}, Lucianne M. and {Wandelt}, Benjamin D. and {Wang}, Sheng and {Wang}, Yun and {Warner}, Michael and {Wechsler}, Risa H. and {West}, Andrew A. and {Wiecha}, Oliver and {Williams}, Benjamin F. and {Willman}, Beth and {Wittman}, David and {Wolff}, Sidney C. and {Wood-Vasey}, W. Michael and {Wozniak}, Przemek and {Young}, Patrick and {Zentner}, Andrew and {Zhan}, Hu},
        title = "{LSST Science Book, Version 2.0}",
      journal = {arXiv e-prints},
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Cosmology and Extragalactic Astrophysics, Astrophysics - Earth and Planetary Astrophysics, Astrophysics - Galaxy Astrophysics, Astrophysics - Solar and Stellar Astrophysics},
         year = 2009,
        month = dec,
          eid = {arXiv:0912.0201},
        pages = {arXiv:0912.0201},
          doi = {10.48550/arXiv.0912.0201},
archivePrefix = {arXiv},
       eprint = {0912.0201},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2009arXiv0912.0201L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Pfeifer_2023,
   title={A local universe model for constrained simulations},
   volume={523},
   ISSN={1365-2966},
   url={http://dx.doi.org/10.1093/mnras/stad1851},
   DOI={10.1093/mnras/stad1851},
   number={4},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Pfeifer, Simon and Valade, Aurélien and Gottlöber, Stefan and Hoffman, Yehuda and Libeskind, Noam I and Hellwing, Wojciech A},
   year={2023},
   month=jun, pages={5985–5994} }

@article{hong2021revealing,
  title={Revealing the local cosmic web from galaxies by deep learning},
  author={Hong, Sungwook E and Jeong, Donghui and Hwang, Ho Seong and Kim, Juhan},
  journal={The Astrophysical Journal},
  volume={913},
  number={1},
  pages={76},
  year={2021},
  publisher={IOP Publishing}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@article{papamakarios2021normalizing,
  title={Normalizing flows for probabilistic modeling and inference},
  author={Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={57},
  pages={1--64},
  year={2021}
}

@inproceedings{
  song2021scorebased,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=PxTIG12RRHS}
}

@article{anderson1982reverse,
  title={Reverse-time diffusion equation models},
  author={Anderson, Brian DO},
  journal={Stochastic Processes and their Applications},
  volume={12},
  number={3},
  pages={313--326},
  year={1982},
  publisher={Elsevier}
}

@misc{kingma2023variational,
      title={Variational Diffusion Models}, 
      author={Diederik P. Kingma and Tim Salimans and Ben Poole and Jonathan Ho},
      year={2023},
      eprint={2107.00630},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{liu2023omnigrok,
      title={Omnigrok: Grokking Beyond Algorithmic Data}, 
      author={Ziming Liu and Eric J. Michaud and Max Tegmark},
      year={2023},
      eprint={2210.01117},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{varma2023explaining,
      title={Explaining grokking through circuit efficiency}, 
      author={Vikrant Varma and Rohin Shah and Zachary Kenton and János Kramár and Ramana Kumar},
      year={2023},
      eprint={2309.02390},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{ba2016layer,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{park2023probabilistic,
      title={Probabilistic reconstruction of Dark Matter fields from biased tracers using diffusion models}, 
      author={Core Francisco Park and Victoria Ono and Nayantara Mudur and Yueying Ni and Carolina Cuesta-Lazaro},
      year={2023},
      eprint={2311.08558},
      archivePrefix={arXiv},
      primaryClass={astro-ph.CO}
}

@inproceedings{liu2022omnigrok,
  title={Omnigrok: Grokking beyond algorithmic data},
  author={Liu, Ziming and Michaud, Eric J and Tegmark, Max},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{kumar2023grokking,
  title={Grokking as the transition from lazy to rich training dynamics},
  author={Kumar, Tanishq and Bordelon, Blake and Gershman, Samuel J and Pehlevan, Cengiz},
  journal={arXiv preprint arXiv:2310.06110},
  year={2023}
}

@misc{nanda2023progress,
      title={Progress measures for grokking via mechanistic interpretability}, 
      author={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
      year={2023},
      eprint={2301.05217},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{liu2022towards,
  title={Towards understanding grokking: An effective theory of representation learning},
  author={Liu, Ziming and Kitouni, Ouail and Nolte, Niklas S and Michaud, Eric and Tegmark, Max and Williams, Mike},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34651--34663},
  year={2022}
}

@inproceedings{locatello2019challenging,
    title        = {{Challenging common assumptions in the unsupervised learning of disentangled representations}},
    author       = {Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Raetsch, Gunnar and Gelly, Sylvain and Sch{\"o}lkopf, Bernhard and Bachem, Olivier},
    year         = {2019},
    booktitle    = {Proc.\ int.\ conf.\ on machine learning  (ICML)},
}

@article{van2019disentangled,
    title        = {{Are disentangled representations helpful for abstract visual reasoning?}},
    author       = {Van Steenkiste, Sjoerd and Locatello, Francesco and Schmidhuber, J{\"u}rgen and Bachem, Olivier},
    year         = {2019},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{eastwood2018framework,
  title={A framework for the quantitative evaluation of disentangled representations},
  author={Eastwood, Cian and Williams, Christopher KI},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{higgins2016beta,
    title        = {{beta-vae: Learning basic visual concepts with a constrained variational framework}},
    author       = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
    year         = {2017},
    journal      = {In Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)}
}


@misc{zhang2024emergence,
      title={The Emergence of Reproducibility and Consistency in Diffusion Models}, 
      author={Huijie Zhang and Jinfan Zhou and Yifu Lu and Minzhe Guo and Peng Wang and Liyue Shen and Qing Qu},
      year={2024},
      eprint={2310.05264},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{carlini2023extracting,
      title={Extracting Training Data from Diffusion Models}, 
      author={Nicholas Carlini and Jamie Hayes and Milad Nasr and Matthew Jagielski and Vikash Sehwag and Florian Tramèr and Borja Balle and Daphne Ippolito and Eric Wallace},
      year={2023},
      eprint={2301.13188},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{dar2023investigating,
      title={Investigating Data Memorization in 3D Latent Diffusion Models for Medical Image Synthesis}, 
      author={Salman Ul Hassan Dar and Arman Ghanaat and Jannik Kahmann and Isabelle Ayx and Theano Papavassiliu and Stefan O. Schoenberg and Sandy Engelhardt},
      year={2023},
      eprint={2307.01148},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{somepalli2022diffusion,
      title={Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models}, 
      author={Gowthami Somepalli and Vasu Singla and Micah Goldblum and Jonas Geiping and Tom Goldstein},
      year={2022},
      eprint={2212.03860},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{he2015delving,
      title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1502.01852},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liu2015faceattributes,
  title = {Deep Learning Face Attributes in the Wild},
  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
  month = {December},
  year = {2015} 
}

@misc{zhang2023texttoimage,
      title={Text-to-image Diffusion Models in Generative AI: A Survey}, 
      author={Chenshuang Zhang and Chaoning Zhang and Mengchun Zhang and In So Kweon},
      year={2023},
      eprint={2303.07909},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{hendrycks2023gaussian,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{okawa2024compositional,
      title={Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task}, 
      author={Maya Okawa and Ekdeep Singh Lubana and Robert P. Dick and Hidenori Tanaka},
      year={2024},
      eprint={2310.09336},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{liang2024diffusion,
      title={Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?}, 
      author={Qiyao Liang and Ziming Liu and Ila Fiete},
      year={2024},
      eprint={2402.03305},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wiedemer2023compositional,
      title={Compositional Generalization from First Principles}, 
      author={Thaddäus Wiedemer and Prasanna Mayilvahanan and Matthias Bethge and Wieland Brendel},
      year={2023},
      eprint={2307.05596},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhang2017understanding,
      title={Understanding deep learning requires rethinking generalization}, 
      author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
      year={2017},
      eprint={1611.03530},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hutchinson2022underspecification,
  title={Underspecification in scene description-to-depiction tasks},
  author={Hutchinson, Ben and Baldridge, Jason and Prabhakaran, Vinodkumar},
  journal={arXiv preprint arXiv:2210.05815},
  year={2022}
}

@misc{chen2023pixartalpha,
    title={PixArt-$\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis}, 
    author={Junsong Chen and Jincheng Yu and Chongjian Ge and Lewei Yao and Enze Xie and Yue Wu and Zhongdao Wang and James Kwok and Ping Luo and Huchuan Lu and Zhenguo Li},
    year={2023},
    eprint={2310.00426},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{wang2023concept,
  title={Concept algebra for score-based conditional model},
  author={Wang, Zihao and Gui, Lin and Negrea, Jeffrey and Veitch, Victor},
  booktitle={ICML 2023 Workshop on Structured Probabilistic Inference $\{$$\backslash$\&$\}$ Generative Modeling},
  year={2023}
}

@inproceedings{
kwon2023diffusion,
title={Diffusion Models Already Have A Semantic Latent Space},
author={Mingi Kwon and Jaeseok Jeong and Youngjung Uh},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=pd1P2eUBVfq}
}

@article{chen2023beyond,
  title={Beyond surface statistics: Scene representations in a latent diffusion model},
  author={Chen, Yida and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2306.05720},
  year={2023}
}

@article{haas2023discovering,
  title={Discovering interpretable directions in the semantic latent space of diffusion models},
  author={Haas, Ren{\'e} and Huberman-Spiegelglas, Inbar and Mulayoff, Rotem and Michaeli, Tomer},
  journal={arXiv preprint arXiv:2303.11073},
  year={2023}
}

@article{park2023unsupervised,
  title={Unsupervised discovery of semantic latent directions in diffusion models},
  author={Park, Yong-Hyun and Kwon, Mingi and Jo, Junghyo and Uh, Youngjung},
  journal={arXiv preprint arXiv:2302.12469},
  year={2023}
}

@article{basu2024mechanistic,
  title={On Mechanistic Knowledge Localization in Text-to-Image Generative Models},
  author={Basu, Samyadeep and Rezaei, Keivan and Rossi, Ryan and Zhao, Cherry and Morariu, Vlad and Manjunatha, Varun and Feizi, Soheil},
  journal={arXiv preprint arXiv:2405.01008},
  year={2024}
}

@article{zhao2018bias,
  title={Bias and generalization in deep generative models: An empirical study},
  author={Zhao, Shengjia and Ren, Hongyu and Yuan, Arianna and Song, Jiaming and Goodman, Noah and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{green2023emergence,
  title={Emergence in complex networks of simple agents},
  author={Green, David G},
  journal={Journal of Economic Interaction and Coordination},
  pages={1--44},
  year={2023},
  publisher={Springer}
}

@article{bedau2008weak,
  title={Is weak emergence just in the mind?},
  author={Bedau, Mark A},
  journal={Minds and Machines},
  volume={18},
  pages={443--459},
  year={2008},
  publisher={Springer}
}

@article{schaeffer2023emergent,
  title={Are emergent abilities of Large Language Models a mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2304.15004},
  year={2023}
}

@article{ramesh2023capable,
  title={How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks},
  author={Ramesh, Rahul and Khona, Mikail and Dick, Robert P and Tanaka, Hidenori and Lubana, Ekdeep Singh},
  journal={arXiv preprint arXiv:2311.12997},
  year={2023}
}

@article{wiedemer2023compositional,
  title={Compositional Generalization from First Principles},
  author={Wiedemer, Thadd{\"a}us and Mayilvahanan, Prasanna and Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:2307.05596},
  year={2023}
}

@article{arora2023theory,
  title={A theory for emergence of complex skills in language models},
  author={Arora, Sanjeev and Goyal, Anirudh},
  journal={arXiv preprint arXiv:2307.15936},
  year={2023}
}

@article{power2022grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}


@article{barak2022hidden,
  title={Hidden progress in deep learning: Sgd learns parities near the computational limit},
  author={Barak, Boaz and Edelman, Benjamin and Goel, Surbhi and Kakade, Sham and Malach, Eran and Zhang, Cyril},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21750--21764},
  year={2022}
}

@article{desai2021redcaps,
  title={Redcaps: Web-curated image-text data created by the people, for the people},
  author={Desai, Karan and Kaul, Gaurav and Aysola, Zubin and Johnson, Justin},
  journal={arXiv preprint arXiv:2111.11431},
  year={2021}
}

@article{kumar2017variational,
  title={Variational inference of disentangled latent concepts from unlabeled observations},
  author={Kumar, Abhishek and Sattigeri, Prasanna and Balakrishnan, Avinash},
  journal={arXiv preprint arXiv:1711.00848},
  year={2017}
}

@article{chen2018isolating,
  title={Isolating sources of disentanglement in variational autoencoders},
  author={Chen, Ricky TQ and Li, Xuechen and Grosse, Roger B and Duvenaud, David K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{kim2018disentangling,
  title={Disentangling by factorising},
  author={Kim, Hyunjik and Mnih, Andriy},
  booktitle={International Conference on Machine Learning},
  pages={2649--2658},
  year={2018},
  organization={PMLR}
}

@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press}
}

@article{tenney2019bert,
  title={BERT rediscovers the classical NLP pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  journal={arXiv preprint arXiv:1905.05950},
  year={2019}
}

@inproceedings{li2023emergent,
title={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},
author={Kenneth Li and Aspen K Hopkins and David Bau and Fernanda Vi{\'e}gas and Hanspeter Pfister and Martin Wattenberg},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=DeG07_TcZvT}
}

@book{margolis1999concepts,
  title={Concepts: core readings.},
  author={Margolis, Eric Ed and Laurence, Stephen Ed},
  year={1999},
  publisher={The MIT Press}
}


@article{bugliarello2021role,
  title={The role of syntactic planning in compositional image captioning},
  author={Bugliarello, Emanuele and Elliott, Desmond},
  journal={arXiv preprint arXiv:2101.11911},
  year={2021}
}

@article{franklin2018compositional,
  title={Compositional clustering in task structure learning},
  author={Franklin, Nicholas T and Frank, Michael J},
  journal={PLoS computational biology},
  volume={14},
  number={4},
  pages={e1006116},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{reverberi2012compositionality,
  title={Compositionality of rule representations in human prefrontal cortex},
  author={Reverberi, Carlo and G{\"o}rgen, Kai and Haynes, John-Dylan},
  journal={Cerebral cortex},
  volume={22},
  number={6},
  pages={1237--1246},
  year={2012},
  publisher={Oxford University Press}
}

@article{kirk2023survey,
  title={A Survey of Zero-shot Generalisation in Deep Reinforcement Learning},
  author={Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={Journal of Artificial Intelligence Research},
  volume={76},
  pages={201--264},
  year={2023}
}

@article{frankland2020concepts,
  title={Concepts and compositionality: in search of the brain's language of thought},
  author={Frankland, Steven M and Greene, Joshua D},
  journal={Annual review of psychology},
  volume={71},
  pages={273--303},
  year={2020},
  publisher={Annual Reviews}
}

@article{phillips2010categorial,
  title={Categorial compositionality: A category theory explanation for the systematicity of human cognition},
  author={Phillips, Steven and Wilson, William H},
  journal={PLoS computational biology},
  volume={6},
  number={7},
  pages={e1000858},
  year={2010},
  publisher={Public Library of Science San Francisco, USA}
}

@article{goodman2008compositionality,
  title={Compositionality in rational analysis: Grammar-based induction for concept learning},
  author={Goodman, Noah D and Tenenbaum, Joshua B and Griffiths, Thomas L and Feldman, Jacob},
  journal={The probabilistic mind: Prospects for Bayesian cognitive science},
  year={2008},
  publisher={Oxford University Press}
}

@inproceedings{zhang2021can,
  title={Can subnetwork structure be the key to out-of-distribution generalization?},
  author={Zhang, Dinghuai and Ahuja, Kartik and Xu, Yilun and Wang, Yisen and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={12356--12367},
  year={2021},
  organization={PMLR}
}

@article{kumari2023ablating,
  title={Ablating Concepts in Text-to-Image Diffusion Models},
  author={Kumari, Nupur and Zhang, Bingliang and Wang, Sheng-Yu and Shechtman, Eli and Zhang, Richard and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2303.13516},
  year={2023}
}

@article{spilsbury2022compositional,
  title={Compositional Generalization in Grounded Language Learning via Induced Model Sparsity},
  author={Spilsbury, Sam and Ilin, Alexander},
  journal={arXiv preprint arXiv:2207.02518},
  year={2022}
}

@article{yuksekgonul2022and,
  title={When and why vision-language models behave like bag-of-words models, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv preprint arXiv:2210.01936},
  year={2022}
}

@article{xu2022prompting,
  title={Prompting Large Pre-trained Vision-Language Models For Compositional Concept Learning},
  author={Xu, Guangyue and Kordjamshidi, Parisa and Chai, Joyce},
  journal={arXiv preprint arXiv:2211.05077},
  year={2022}
}

@inproceedings{lake2018generalization,
  title={Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks},
  author={Lake, Brenden and Baroni, Marco},
  booktitle={International conference on machine learning},
  pages={2873--2882},
  year={2018},
  organization={PMLR}
}

@inproceedings{valvoda2022benchmarking,
  title={Benchmarking Compositionality with Formal Languages},
  author={Valvoda, Josef and Saphra, Naomi and Rawski, Jonathan and Williams, Adina and Cotterell, Ryan},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={6007--6018},
  year={2022}
}

@article{lepori2023break,
  title={Break It Down: Evidence for Structural Compositionality in Neural Networks},
  author={Lepori, Michael A and Serre, Thomas and Pavlick, Ellie},
  journal={arXiv preprint arXiv:2301.10884},
  year={2023}
}

@article{yun2022vision,
  title={Do Vision-Language Pretrained Models Learn Primitive Concepts?},
  author={Yun, Tian and Bhalla, Usha and Pavlick, Ellie and Sun, Chen},
  journal={arXiv preprint arXiv:2203.17271},
  year={2022}
}

@article{lewis2022does,
  title={Does CLIP Bind Concepts? Probing Compositionality in Large Image Models},
  author={Lewis, Martha and Yu, Qinan and Merullo, Jack and Pavlick, Ellie},
  journal={arXiv preprint arXiv:2212.10537},
  year={2022}
}

@inproceedings{thrush2022winoground,
  title={Winoground: Probing vision and language models for visio-linguistic compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@article{hupkes2020compositionality,
  title={Compositionality decomposed: How do neural networks generalise?},
  author={Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
  journal={Journal of Artificial Intelligence Research},
  volume={67},
  pages={757--795},
  year={2020}
}

@article{li2024scalability,
  title={On the Scalability of Diffusion-based Text-to-Image Generation},
  author={Li, Hao and Zou, Yang and Wang, Ying and Majumder, Orchid and Xie, Yusheng and Manmatha, R and Swaminathan, Ashwin and Tu, Zhuowen and Ermon, Stefano and Soatto, Stefano},
  journal={arXiv preprint arXiv:2404.02883},
  year={2024}
}

@article{feng2022training,
  title={Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis},
  author={Feng, Weixi and He, Xuehai and Fu, Tsu-Jui and Jampani, Varun and Akula, Arjun and Narayana, Pradyumna and Basu, Sugato and Wang, Xin Eric and Wang, William Yang},
  journal={arXiv preprint arXiv:2212.05032},
  year={2022}
}

@article{rassin2022dalle,
  title={Dalle-2 is seeing double: flaws in word-to-concept mapping in Text2Image models},
  author={Rassin, Royi and Ravfogel, Shauli and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2210.10606},
  year={2022}
}

@article{singh2021illiterate,
  title={Illiterate dall-e learns to compose},
  author={Singh, Gautam and Deng, Fei and Ahn, Sungjin},
  journal={arXiv preprint arXiv:2110.11405},
  year={2021}
}

@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  year={2022}
}

@article{brooks2022instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  journal={arXiv preprint arXiv:2211.09800},
  year={2022}
}

@article{couairon2022diffedit,
  title={Diffedit: Diffusion-based semantic image editing with mask guidance},
  author={Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu},
  journal={arXiv preprint arXiv:2210.11427},
  year={2022}
}

@article{ravi2023preditor,
  title={PRedItOR: Text Guided Image Editing with Diffusion Prior},
  author={Ravi, Hareesh and Kelkar, Sachin and Harikumar, Midhun and Kale, Ajinkya},
  journal={arXiv preprint arXiv:2302.07979},
  year={2023}
}

@article{goel2023pair,
  title={PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models},
  author={Goel, Vidit and Peruzzo, Elia and Jiang, Yifan and Xu, Dejia and Sebe, Nicu and Darrell, Trevor and Wang, Zhangyang and Shi, Humphrey},
  journal={arXiv preprint arXiv:2303.17546},
  year={2023}
}

@article{huang2022ladis,
  title={LADIS: Language disentanglement for 3D shape editing},
  author={Huang, Ian and Achlioptas, Panos and Zhang, Tianyi and Tulyakov, Sergey and Sung, Minhyuk and Guibas, Leonidas},
  journal={arXiv preprint arXiv:2212.05011},
  year={2022}
}

@article{lim2023score,
  title={Score-based diffusion models in function space},
  author={Lim, Jae Hyun and Kovachki, Nikola B and Baptista, Ricardo and Beckham, Christopher and Azizzadenesheli, Kamyar and Kossaifi, Jean and Voleti, Vikram and Song, Jiaming and Kreis, Karsten and Kautz, Jan and others},
  journal={arXiv preprint arXiv:2302.07400},
  year={2023}
}

@article{richardson2023texture,
  title={Texture: Text-guided texturing of 3d shapes},
  author={Richardson, Elad and Metzer, Gal and Alaluf, Yuval and Giryes, Raja and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2302.01721},
  year={2023}
}

@article{shin2023edit,
  title={Edit-A-Video: Single Video Editing with Object-Aware Consistency},
  author={Shin, Chaehun and Kim, Heeseung and Lee, Che Hyun and Lee, Sang-gil and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2303.07945},
  year={2023}
}

@article{ceylan2023pix2video,
  title={Pix2video: Video editing using image diffusion},
  author={Ceylan, Duygu and Huang, Chun-Hao Paul and Mitra, Niloy J},
  journal={arXiv preprint arXiv:2303.12688},
  year={2023}
}

@article{mei2022vidm,
  title={VIDM: Video Implicit Diffusion Models},
  author={Mei, Kangfu and Patel, Vishal M},
  journal={arXiv preprint arXiv:2212.00235},
  year={2022}
}

@article{yu2023video,
  title={Video Probabilistic Diffusion Models in Projected Latent Space},
  author={Yu, Sihyun and Sohn, Kihyuk and Kim, Subin and Shin, Jinwoo},
  journal={arXiv preprint arXiv:2302.07685},
  year={2023}
}

@article{jiang2023text2performer,
  title={Text2Performer: Text-Driven Human Video Generation},
  author={Jiang, Yuming and Yang, Shuai and Koh, Tong Liang and Wu, Wayne and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint arXiv:2304.08483},
  year={2023}
}

@article{chen2023motion,
  title={Motion-Conditioned Diffusion Model for Controllable Video Synthesis},
  author={Chen, Tsai-Shien and Lin, Chieh Hubert and Tseng, Hung-Yu and Lin, Tsung-Yi and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2304.14404},
  year={2023}
}

@article{blattmann2023align,
  title={Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  journal={arXiv preprint arXiv:2304.08818},
  year={2023}
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={arXiv preprint arXiv:2204.03458},
  year={2022}
}

@inproceedings{conwell2023comprehensive,
  title={A Comprehensive Benchmark of Human-Like Relational Reasoning for Text-to-Image Foundation Models},
  author={Conwell, Colin and Ullman, Tomer},
  booktitle={ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models},
  year={2023},
}

@article{gokhale2022benchmarking,
  title={Benchmarking Spatial Relationships in Text-to-Image Generation},
  author={Gokhale, Tejas and Palangi, Hamid and Nushi, Besmira and Vineet, Vibhav and Horvitz, Eric and Kamar, Ece and Baral, Chitta and Yang, Yezhou},
  journal={arXiv preprint arXiv:2212.10015},
  year={2022}
}

@article{du2021unsupervised,
  title={Unsupervised learning of compositional energy concepts},
  author={Du, Yilun and Li, Shuang and Sharma, Yash and Tenenbaum, Josh and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15608--15620},
  year={2021}
}

@article{du2023reduce,
  title={Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC},
  author={Du, Yilun and Durkan, Conor and Strudel, Robin and Tenenbaum, Joshua B and Dieleman, Sander and Fergus, Rob and Sohl-Dickstein, Jascha and Doucet, Arnaud and Grathwohl, Will},
  journal={arXiv preprint arXiv:2302.11552},
  year={2023}
}

@inproceedings{liu2022compositional,
  title={Compositional visual generation with composable diffusion models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XVII},
  pages={423--439},
  year={2022},
  organization={Springer}
}

@article{marcus2022very,
  title={A very preliminary analysis of dall-e 2},
  author={Marcus, Gary and Davis, Ernest and Aaronson, Scott},
  journal={arXiv preprint arXiv:2204.13807},
  year={2022}
}

@article{leivada2022dall,
  title={DALL-E 2 Fails to Reliably Capture Common Syntactic Processes},
  author={Leivada, Evelina and Murphy, Elliot and Marcus, Gary},
  journal={arXiv preprint arXiv:2210.12889},
  year={2022}
}

@article{singh2022progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  journal={arXiv preprint arXiv:2209.11302},
  year={2022}
}

@article{vemprala2023chatgpt,
  title={Chatgpt for robotics: Design principles and model abilities},
  author={Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
  journal={2023},
  year={2023}
}

@article{lin2022magic3d,
  title={Magic3D: High-Resolution Text-to-3D Content Creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  journal={arXiv preprint arXiv:2211.10440},
  year={2022}
}

@article{poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2022}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{ho2022classifierfree,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@misc{kadkhodaie2024generalization,
      title={Generalization in diffusion models arises from geometry-adaptive harmonic representations}, 
      author={Zahra Kadkhodaie and Florentin Guth and Eero P. Simoncelli and Stéphane Mallat},
      year={2024},
      eprint={2310.02557},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International Conference on Machine Learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}


@inproceedings{pan2023arbitrary,
  title={Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation},
  author={Pan, Zhihong and Zhou, Xin and Tian, Hao},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4461--4471},
  year={2023}
}

@article{kawar2022imagic,
  title={Imagic: Text-based real image editing with diffusion models},
  author={Kawar, Bahjat and Zada, Shiran and Lang, Oran and Tov, Omer and Chang, Huiwen and Dekel, Tali and Mosseri, Inbar and Irani, Michal},
  journal={arXiv preprint arXiv:2210.09276},
  year={2022}
}

@article{li2022diffusion,
  title={Diffusion-lm improves controllable text generation},
  author={Li, Xiang and Thickstun, John and Gulrajani, Ishaan and Liang, Percy S and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4328--4343},
  year={2022}
}

@article{janner2022planning,
  title={Planning with diffusion for flexible behavior synthesis},
  author={Janner, Michael and Du, Yilun and Tenenbaum, Joshua B and Levine, Sergey},
  journal={arXiv preprint arXiv:2205.09991},
  year={2022}
}

@article{brehmer2023edgi,
  title={EDGI: Equivariant Diffusion for Planning with Embodied Agents},
  author={Brehmer, Johann and Bose, Joey and De Haan, Pim and Cohen, Taco},
  journal={arXiv preprint arXiv:2303.12410},
  year={2023}
}

@article{chi2023diffusion,
  title={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
  author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  journal={arXiv preprint arXiv:2303.04137},
  year={2023}
}

@article{nijkamp2022codegen,
  title={Codegen: An open large language model for code with multi-turn program synthesis},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  journal={arXiv preprint arXiv:2203.13474},
  year={2022}
}

@article{zheng2023codegeex,
  title={Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x},
  author={Zheng, Qinkai and Xia, Xiao and Zou, Xu and Dong, Yuxiao and Wang, Shan and Xue, Yufei and Wang, Zihan and Shen, Lei and Wang, Andi and Li, Yang and others},
  journal={arXiv preprint arXiv:2303.17568},
  year={2023}
}

@article{cassano2023multipl,
  title={MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation},
  author={Cassano, Federico and Gouwar, John and Nguyen, Daniel and Nguyen, Sydney and Phipps-Costin, Luna and Pinckney, Donald and Yee, Ming-Ho and Zi, Yangtian and Anderson, Carolyn Jane and Feldman, Molly Q and others},
  journal={IEEE Transactions on Software Engineering},
  year={2023},
  publisher={IEEE}
}

@article{sharma2021skill,
  title={Skill induction and planning with latent language},
  author={Sharma, Pratyusha and Torralba, Antonio and Andreas, Jacob},
  journal={arXiv preprint arXiv:2110.01517},
  year={2021}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}

@article{liu2023picture,
  title={A Picture is Worth a Thousand Words: Language Models Plan from Pixels},
  author={Liu, Anthony Z and Logeswaran, Lajanugen and Sohn, Sungryull and Lee, Honglak},
  journal={arXiv preprint arXiv:2303.09031},
  year={2023}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@article{wang2023diffusion,
  title={Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later},
  author={Wang, Binxu and Vastola, John J},
  journal={arXiv preprint arXiv:2303.02490},
  year={2023}
}


@article{schott2021visual,
  title={Visual representation learning does not generalize strongly within the same domain},
  author={Schott, Lukas and Von K{\"u}gelgen, Julius and Tr{\"a}uble, Frederik and Gehler, Peter and Russell, Chris and Bethge, Matthias and Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Brendel, Wieland},
  journal={arXiv preprint arXiv:2107.08221},
  year={2021}
}

@inproceedings{ahmed2021systematic,
  title={Systematic generalisation with group invariant predictions},
  author={Ahmed, Faruk and Bengio, Yoshua and Van Seijen, Harm and Courville, Aaron},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{dasgupta2022distinguishing,
  title={Distinguishing rule and exemplar-based generalization in learning systems},
  author={Dasgupta, Ishita and Grant, Erin and Griffiths, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4816--4830},
  year={2022},
  organization={PMLR}
}

@misc{yang2024diffusion,
      title={Diffusion Models: A Comprehensive Survey of Methods and Applications}, 
      author={Ling Yang and Zhilong Zhang and Yang Song and Shenda Hong and Runsheng Xu and Yue Zhao and Wentao Zhang and Bin Cui and Ming-Hsuan Yang},
      year={2024},
      eprint={2209.00796},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{andreas2019measuring,
  title={Measuring compositionality in representation learning},
  author={Andreas, Jacob},
  journal={arXiv preprint arXiv:1902.07181},
  year={2019}
}

@misc{qiu2022evaluating,
      title={Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing}, 
      author={Linlu Qiu and Peter Shaw and Panupong Pasupat and Tianze Shi and Jonathan Herzig and Emily Pitler and Fei Sha and Kristina Toutanova},
      year={2022},
      eprint={2205.12253},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{karras2024analyzing,
      title={Analyzing and Improving the Training Dynamics of Diffusion Models}, 
      author={Tero Karras and Miika Aittala and Jaakko Lehtinen and Janne Hellsten and Timo Aila and Samuli Laine},
      year={2024},
      eprint={2312.02696},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{chen2020wavegrad,
  title={Wavegrad: Estimating gradients for waveform generation},
  author={Chen, Nanxin and Zhang, Yu and Zen, Heiga and Weiss, Ron J and Norouzi, Mohammad and Chan, William},
  journal={ICML},
  year={2021}
}

@article{saharia2022image,
  title={Image super-resolution via iterative refinement},
  author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@inproceedings{kingma2015adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={ICLR},
  year={2015}
}


@article{conwell2022testing,
  title={Testing relational understanding in text-guided image generation},
  author={Conwell, Colin and Ullman, Tomer},
  journal={arXiv preprint arXiv:2208.00005},
  year={2022}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{wies2022sub,
  title={Sub-task decomposition enables learning in sequence to sequence tasks},
  author={Wies, Noam and Levine, Yoav and Shashua, Amnon},
  journal={arXiv preprint arXiv:2204.02892},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}


@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2901--2910},
  year={2017}
}


@article{michaud2023quantization,
  title={The Quantization Model of Neural Scaling},
  author={Michaud, Eric J and Liu, Ziming and Girit, Uzay and Tegmark, Max},
  journal={arXiv preprint arXiv:2303.13506},
  year={2023}
}

@article{trivedi2023closer,
  title={A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias},
  author={Trivedi, Puja and Koutra, Danai and Thiagarajan, Jayaraman J},
  journal={arXiv preprint arXiv:2303.13500},
  year={2023}
}

@article{petrini2021relative,
  title={Relative stability toward diffeomorphisms indicates performance in deep nets},
  author={Petrini, Leonardo and Favero, Alessandro and Geiger, Mario and Wyart, Matthieu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8727--8739},
  year={2021}
}

@article{cantelobre2022measuring,
  title={Measuring dissimilarity with diffeomorphism invariance},
  author={Cantelobre, Th{\'e}ophile and Ciliberto, Carlo and Guedj, Benjamin and Rudi, Alessandro},
  journal={arXiv preprint arXiv:2202.05614},
  year={2022}
}

@inproceedings{edelman2022inductive,
  title={Inductive biases and variable creation in self-attention mechanisms},
  author={Edelman, Benjamin L and Goel, Surbhi and Kakade, Sham and Zhang, Cyril},
  booktitle={International Conference on Machine Learning},
  pages={5793--5831},
  year={2022},
  organization={PMLR}
}

@article{bhattamishra2022simplicity,
  title={Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions},
  author={Bhattamishra, Satwik and Patel, Arkil and Kanade, Varun and Blunsom, Phil},
  journal={arXiv preprint arXiv:2211.12316},
  year={2022}
}

@article{lubana2022mechanistic,
  title={Mechanistic Mode Connectivity},
  author={Lubana, Ekdeep Singh and Bigelow, Eric J and Dick, Robert P and Krueger, David and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2211.08422},
  year={2022}
}

@article{cunningham2022principal,
  title={Principal manifold flows},
  author={Cunningham, Edmond and Cobb, Adam and Jha, Susmit},
  journal={arXiv preprint arXiv:2202.07037},
  year={2022}
}

@article{hoffman2019robust,
  title={Robust learning with jacobian regularization},
  author={Hoffman, Judy and Roberts, Daniel A and Yaida, Sho},
  journal={arXiv preprint arXiv:1908.02729},
  year={2019}
}

@inproceedings{teney2022evading,
  title={Evading the simplicity bias: Training a diverse set of models discovers solutions with superior ood generalization},
  author={Teney, Damien and Abbasnejad, Ehsan and Lucey, Simon and Van den Hengel, Anton},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16761--16772},
  year={2022}
}

@article{srinivas2018local,
  title={Local affine approximations for improving knowledge transfer},
  author={Srinivas, Suraj and Fleuret, Francois},
  journal={Idiap-Com Idiap-Com-01-2018, Idiap},
  volume={3},
  year={2018}
}

@inproceedings{srinivas2018knowledge,
  title={Knowledge transfer with jacobian matching},
  author={Srinivas, Suraj and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning},
  pages={4723--4731},
  year={2018},
  organization={PMLR}
}

@article{harutyunyan2023supervision,
  title={Supervision Complexity and its Role in Knowledge Distillation},
  author={Harutyunyan, Hrayr and Rawat, Ankit Singh and Menon, Aditya Krishna and Kim, Seungyeon and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2301.12245},
  year={2023}
}

@inproceedings{khemakhem2020variational,
    title        = {{Variational autoencoders and nonlinear ica: A unifying framework}},
    author       = {Khemakhem, Ilyes and Kingma, Diederik and Monti, Ricardo and Hyvarinen, Aapo},
    year         = {2020},
    booktitle    = {Int.\ Conf.\ on Artificial Intelligence and Statistics (AISTATS)},
}

@inproceedings{khemakhem2021causal,
    title        = {{Causal autoregressive flows}},
    author       = {Khemakhem, Ilyes and Monti, Ricardo and Leech, Robert and Hyvarinen, Aapo},
    year         = {2021},
    booktitle    = {Int.\ conf.\ on artificial intelligence and statistics (AISTATS)},
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint. arXiv:2108.07258},
  year={2021}
}


@Misc{compositionOOP,
  Author = {Wikipedia.},
  Title  = "\emph{Composition over Inheritance}",
  Note   = "\url{https://en.wikipedia.org/wiki/Composition_over_inheritance}",
  year = 2023,
}


@Misc{percolationwiki,
  Author = {Wikipedia.},
  Title  = "\emph{Percolation Threshold}",
  Note   = "\url{https://en.wikipedia.org/wiki/Percolation_threshold}",
  year = 2024,
}


@Misc{midjourney,
  Author = {Midjourney AI.},
  Title  = "\emph{Midjourney}",
  Note   = "\url{https://docs.midjourney.com}",
  year = 2023,
}

@Misc{stablediffusion,
  Author = {Stability AI.},
  Title  = "\emph{Stable Diffusion v2.1}",
  Note   = "\url{https://beta.dreamstudio.ai/generate}",
  year = 2023,
}


@Misc{reverseeng,
  Author = {David Adler, IEEE Spectrum.},
  Title  = "\emph{Reverse Engineering the Brain}",
  Note   = "\url{https://spectrum.ieee.org/reverse-engineering-the-brain}",
  year = 2008,
}

@Misc{flies,
  Author = {Emily Anthes, NYTimes.},
  Title  = "\emph{Why Scientists Have Spent Years Mapping This Creature’s Brain}",
  Note   = "\url{https://www.nytimes.com/2021/10/26/science/drosophila-fly-brain-connectome.html}",
  year = 2021,
}

@Misc{distillclip,
  Author = {Vinay Sisodia},
  Title  = "\emph{Distillation of CLIP model and other experiments}",
  Note   = "\url{https://tech.pic-collage.com/distillation-of-clip-model-and-other-experiments-f8394b7321ce}",
  year = 2021,
}

@article{gupta2022mitigating,
  title={Mitigating gender bias in distilled language models via counterfactual role reversal},
  author={Gupta, Umang and Dhamala, Jwala and Kumar, Varun and Verma, Apurv and Pruksachatkun, Yada and Krishna, Satyapriya and Gupta, Rahul and Chang, Kai-Wei and Steeg, Greg Ver and Galstyan, Aram},
  journal={arXiv preprint arXiv:2203.12574},
  year={2022}
}

@Misc{distillrepo,
  Author = {Hugging Face Co.},
  Title  = "\emph{Distil* repository.}",
  Note   = "\url{https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation}",
  year = 2020,
}

@Misc{distillgpt2,
  Author = {Hugging Face Co.},
  Title  = "\emph{DistilGPT2}",
  Note   = "\url{https://huggingface.co/distilgpt2}",
  year = 2020,
}

@article{nagarajan2023student,
  title={On student-teacher deviations in distillation: does it pay to disobey?},
  author={Nagarajan, Vaishnavh and Menon, Aditya Krishna and Bhojanapalli, Srinadh and Mobahi, Hossein and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2301.12923},
  year={2023}
}

@article{kaplun2022knowledge,
  title={Knowledge Distillation: Bad Models Can Be Good Role Models},
  author={Kaplun, Gal and Malach, Eran and Nakkiran, Preetum and Shalev-Shwartz, Shai},
  journal={arXiv preprint arXiv:2203.14649},
  year={2022}
}

@inproceedings{furlanello2018born,
  title={Born again neural networks},
  author={Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle={International Conference on Machine Learning},
  pages={1607--1616},
  year={2018},
  organization={PMLR}
}

@article{abnar2020transferring,
  title={Transferring inductive biases through knowledge distillation},
  author={Abnar, Samira and Dehghani, Mostafa and Zuidema, Willem},
  journal={arXiv preprint arXiv:2006.00555},
  year={2020}
}

@article{wang2022makes,
  title={What Makes a" Good" Data Augmentation in Knowledge Distillation-A Statistical Perspective},
  author={Wang, Huan and Lohit, Suhas and Jones, Michael N and Fu, Yun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={13456--13469},
  year={2022}
}

@article{zhang2021graph,
  title={Graph-less neural networks: Teaching old mlps new tricks via distillation},
  author={Zhang, Shichang and Liu, Yozen and Sun, Yizhou and Shah, Neil},
  journal={arXiv preprint arXiv:2110.08727},
  year={2021}
}

@inproceedings{phuong2019towards,
  title={Towards understanding knowledge distillation},
  author={Phuong, Mary and Lampert, Christoph},
  booktitle={International Conference on Machine Learning},
  pages={5142--5151},
  year={2019},
  organization={PMLR}
}

@article{stanton2021does,
  title={Does knowledge distillation really work?},
  author={Stanton, Samuel and Izmailov, Pavel and Kirichenko, Polina and Alemi, Alexander A and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6906--6919},
  year={2021}
}

@article{allen2020towards,
  title={Towards understanding ensemble, knowledge distillation and self-distillation in deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2012.09816},
  year={2020}
}

@inproceedings{cheng2020explaining,
  title={Explaining knowledge distillation by quantifying the knowledge},
  author={Cheng, Xu and Rao, Zhefan and Chen, Yilan and Zhang, Quanshi},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12925--12935},
  year={2020}
}

@article{malinin2019ensemble,
  title={Ensemble distribution distillation},
  author={Malinin, Andrey and Mlodozeniec, Bruno and Gales, Mark},
  journal={arXiv preprint arXiv:1905.00076},
  year={2019}
}

@inproceedings{beyer2022knowledge,
  title={Knowledge distillation: A good teacher is patient and consistent},
  author={Beyer, Lucas and Zhai, Xiaohua and Royer, Am{\'e}lie and Markeeva, Larisa and Anil, Rohan and Kolesnikov, Alexander},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10925--10934},
  year={2022}
}

@article{wu2021causal,
  title={Causal distillation for language models},
  author={Wu, Zhengxuan and Geiger, Atticus and Rozner, Josh and Kreiss, Elisa and Lu, Hanson and Icard, Thomas and Potts, Christopher and Goodman, Noah D},
  journal={arXiv preprint arXiv:2112.02505},
  year={2021}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{tang2020understanding,
  title={Understanding and improving knowledge distillation},
  author={Tang, Jiaxi and Shivanna, Rakesh and Zhao, Zhe and Lin, Dong and Singh, Anima and Chi, Ed H and Jain, Sagar},
  journal={arXiv preprint arXiv:2002.03532},
  year={2020}
}

@inproceedings{cho2019efficacy,
  title={On the efficacy of knowledge distillation},
  author={Cho, Jang Hyun and Hariharan, Bharath},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4794--4802},
  year={2019}
}


@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}


@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{lubana2023mechanistic,
  title={Mechanistic mode connectivity},
  author={Lubana, Ekdeep Singh and Bigelow, Eric J and Dick, Robert P and Krueger, David and Tanaka, Hidenori},
  booktitle={International Conference on Machine Learning},
  pages={22965--23004},
  year={2023},
  organization={PMLR}
}

@article{jain2023mechanistically,
  title={Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks},
  author={Jain, Samyak and Kirk, Robert and Lubana, Ekdeep Singh and Dick, Robert P and Tanaka, Hidenori and Grefenstette, Edward and Rockt{\"a}schel, Tim and Krueger, David Scott},
  journal={arXiv preprint arXiv:2311.12786},
  year={2023}
}

@article{garrido2021survey,
  title={A survey on bias in deep nlp},
  author={Garrido-Mu{\~n}oz, Ismael and Montejo-R{\'a}ez, Arturo and Mart{\'\i}nez-Santiago, Fernando and Ure{\~n}a-L{\'o}pez, L Alfonso},
  journal={Applied Sciences},
  volume={11},
  number={7},
  pages={3184},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from language models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}

@article{prystawski2024think,
  title={Why think step by step? Reasoning emerges from the locality of experience},
  author={Prystawski, Ben and Li, Michael and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{rameshcompositional,
  title={Compositional Capabilities of Autoregressive Transformers: A Study on Synthetic, Interpretable Tasks},
  author={Ramesh, Rahul and Lubana, Ekdeep Singh and Khona, Mikail and Dick, Robert P and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2311.12997},
  year={2023}
}

@article{bigelowcontext,
  title={In-context learning dynamics with random binary sequences},
  author={Bigelow, Eric J and Lubana, Ekdeep Singh and Dick, Robert P and Tanaka, Hidenori and Ullman, Tomer D},
  journal={arXiv preprint arXiv:2310.17639},
  year={2023}
}

@article{mcguffie2020radicalization,
  title={The radicalization risks of GPT-3 and advanced neural language models},
  author={McGuffie, Kris and Newhouse, Alex},
  journal={arXiv preprint arXiv:2009.06807},
  year={2020}
}

@article{perez2022ignore,
  title={Ignore Previous Prompt: Attack Techniques For Language Models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}

@article{mu2023learning,
  title={Learning to Compress Prompts with Gist Tokens},
  author={Mu, Jesse and Li, Xiang Lisa and Goodman, Noah},
  journal={arXiv preprint arXiv:2304.08467},
  year={2023}
}

@article{recchia2021teaching,
  title={Teaching autoregressive language models complex tasks by demonstration},
  author={Recchia, Gabriel},
  journal={arXiv preprint arXiv:2109.02102},
  year={2021}
}

@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}

@article{sorensen2022information,
  title={An information-theoretic approach to prompt engineering without ground truth labels},
  author={Sorensen, Taylor and Robinson, Joshua and Rytting, Christopher Michael and Shaw, Alexander Glenn and Rogers, Kyle Jeffrey and Delorey, Alexia Pauline and Khalil, Mahmoud and Fulda, Nancy and Wingate, David},
  journal={arXiv preprint arXiv:2203.11364},
  year={2022}
}

@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{min2022rethinking,
  title={Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{wies2023learnability,
  title={The Learnability of In-Context Learning},
  author={Wies, Noam and Levine, Yoav and Shashua, Amnon},
  journal={arXiv preprint arXiv:2303.07895},
  year={2023}
}

@article{wang2023large,
  title={Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning},
  author={Wang, Xinyi and Zhu, Wanrong and Wang, William Yang},
  journal={arXiv preprint arXiv:2301.11916},
  year={2023}
}

@article{li2023transformers,
  title={Transformers as Algorithms: Generalization and Implicit Model Selection in In-context Learning},
  author={Li, Yingcong and Ildiz, M Emrullah and Papailiopoulos, Dimitris and Oymak, Samet},
  journal={arXiv preprint arXiv:2301.07067},
  year={2023}
}

@article{andreas2022language,
  title={Language models as agent models},
  author={Andreas, Jacob},
  journal={arXiv preprint arXiv:2212.01681},
  year={2022}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{weng2022large,
  title={Large Language Models are reasoners with Self-Verification},
  author={Weng, Yixuan and Zhu, Minjun and He, Shizhu and Liu, Kang and Zhao, Jun},
  journal={arXiv preprint arXiv:2212.09561},
  year={2022}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{zelikman2022star,
  title={Star: Bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15476--15488},
  year={2022}
}

@article{gao2022pal,
  title={PAL: Program-aided Language Models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2211.10435},
  year={2022}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}


@article{shah2022goal,
  title={Goal misgeneralization: Why correct specifications aren't enough for correct goals},
  author={Shah, Rohin and Varma, Vikrant and Kumar, Ramana and Phuong, Mary and Krakovna, Victoria and Uesato, Jonathan and Kenton, Zac},
  journal={arXiv preprint arXiv:2210.01790},
  year={2022}
}

@article{krakovna2020avoiding,
  title={Avoiding side effects by considering future tasks},
  author={Krakovna, Victoria and Orseau, Laurent and Ngo, Richard and Martic, Miljan and Legg, Shane},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19064--19074},
  year={2020}
}

@inproceedings{tiencausal,
  title={Causal Confusion and Reward Misidentification in Preference-Based Reward Learning},
  author={Tien, Jeremy and He, Jerry Zhi-Yang and Erickson, Zackory and Dragan, Anca and Brown, Daniel S},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@Misc{specgamingblog,
  Author = {Krakovna, Victoria and Uesato, Jonathan and Mikulik, Vladimir and Rahtz, Matthew and Everitt, Tom and Kumar, Ramana and Kenton, Zac and Leike, Jan and Legg, Shane},
  Title  = "\emph{Specification gaming: the flip side of AI ingenuity}",
  Note   = "\url{https://www.deepmind.com/blog/specification-gaming-the-flip-side-of-ai-ingenuity}",
  year = 2020,
}

@Misc{specgaminglist,
  Author = {Krakovna, Victoria and Uesato, Jonathan and Mikulik, Vladimir and Rahtz, Matthew and Everitt, Tom and Kumar, Ramana and Kenton, Zac and Leike, Jan and Legg, Shane},
  Title  = "\emph{Specification gaming examples in AI}",
  Note   = "\url{https://docs.google.com/spreadsheets/u/1/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml}",
  year = 2020,
}

@article{chan2023harms,
  title={Harms from Increasingly Agentic Algorithmic Systems},
  author={Chan, Alan and Salganik, Rebecca and Markelius, Alva and Pang, Chris and Rajkumar, Nitarshan and Krasheninnikov, Dmitrii and Langosco, Lauro and He, Zhonghao and Duan, Yawen and Carroll, Micah and others},
  journal={arXiv preprint arXiv:2302.10329},
  year={2023}
}

@article{carroll2023characterizing,
  title={Characterizing Manipulation from AI Systems},
  author={Carroll, Micah and Chan, Alan and Ashton, Henry and Krueger, David},
  journal={arXiv preprint arXiv:2303.09387},
  year={2023}
}

@article{meta2022human,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Meta Fundamental AI Research Diplomacy Team (FAIR)† and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{rajkumar2022evaluating,
  title={Evaluating the text-to-sql capabilities of large language models},
  author={Rajkumar, Nitarshan and Li, Raymond and Bahdanau, Dzmitry},
  journal={arXiv preprint arXiv:2204.00498},
  year={2022}
}

@article{irving2018ai,
  title={AI safety via debate},
  author={Irving, Geoffrey and Christiano, Paul and Amodei, Dario},
  journal={arXiv preprint arXiv:1805.00899},
  year={2018}
}

@article{christiano2018supervising,
  title={Supervising strong learners by amplifying weak experts},
  author={Christiano, Paul and Shlegeris, Buck and Amodei, Dario},
  journal={arXiv preprint arXiv:1810.08575},
  year={2018}
}

@article{tamkin2021understanding,
  title={Understanding the capabilities, limitations, and societal impact of large language models},
  author={Tamkin, Alex and Brundage, Miles and Clark, Jack and Ganguli, Deep},
  journal={arXiv preprint arXiv:2102.02503},
  year={2021}
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{everitt2021reward,
  title={Reward tampering problems and solutions in reinforcement learning: A causal influence diagram perspective},
  author={Everitt, Tom and Hutter, Marcus and Kumar, Ramana and Krakovna, Victoria},
  journal={Synthese},
  volume={198},
  number={Suppl 27},
  pages={6435--6467},
  year={2021},
  publisher={Springer}
}

@article{kenton2021alignment,
  title={Alignment of language agents},
  author={Kenton, Zachary and Everitt, Tom and Weidinger, Laura and Gabriel, Iason and Mikulik, Vladimir and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2103.14659},
  year={2021}
}

@article{parrish2021bbq,
  title={BBQ: A hand-built bias benchmark for question answering},
  author={Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2110.08193},
  year={2021}
}

@article{wallace2019universal,
  title={Universal adversarial triggers for attacking and analyzing NLP},
  author={Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
  journal={arXiv preprint arXiv:1908.07125},
  year={2019}
}

@article{xu2021detoxifying,
  title={Detoxifying language models risks marginalizing minority voices},
  author={Xu, Albert and Pathak, Eshaan and Wallace, Eric and Gururangan, Suchin and Sap, Maarten and Klein, Dan},
  journal={arXiv preprint arXiv:2104.06390},
  year={2021}
}

@article{zhou2021challenges,
  title={Challenges in Automated Debiasing for Toxic Language Detection},
  author={Zhou, Xuhui and Sap, Maarten and Swayamdipta, Swabha and Smith, Noah A and Choi, Yejin},
  journal={arXiv preprint arXiv:2102.00086},
  year={2021}
}

@article{sheng2019woman,
  title={The woman worked as a babysitter: On biases in language generation},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:1909.01326},
  year={2019}
}

@article{huang2019reducing,
  title={Reducing sentiment bias in language models via counterfactual evaluation},
  author={Huang, Po-Sen and Zhang, Huan and Jiang, Ray and Stanforth, Robert and Welbl, Johannes and Rae, Jack and Maini, Vishal and Yogatama, Dani and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:1911.03064},
  year={2019}
}

@inproceedings{abid2021persistent,
  title={Persistent anti-muslim bias in large language models},
  author={Abid, Abubakar and Farooqi, Maheen and Zou, James},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={298--306},
  year={2021}
}

@article{welbl2021challenges,
  title={Challenges in detoxifying language models},
  author={Welbl, Johannes and Glaese, Amelia and Uesato, Jonathan and Dathathri, Sumanth and Mellor, John and Hendricks, Lisa Anne and Anderson, Kirsty and Kohli, Pushmeet and Coppin, Ben and Huang, Po-Sen},
  journal={arXiv preprint arXiv:2109.07445},
  year={2021}
}

@article{gabriel2020artificial,
  title={Artificial intelligence, values, and alignment},
  author={Gabriel, Iason},
  journal={Minds and machines},
  volume={30},
  number={3},
  pages={411--437},
  year={2020},
  publisher={Springer}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@article{jiang2021can,
  title={Can machines learn morality? The Delphi experiment},
  author={Jiang, Liwei and Hwang, Jena D and Bhagavatula, Chandra and Le Bras, Ronan and Liang, Jenny and Dodge, Jesse and Sakaguchi, Keisuke and Forbes, Maxwell and Borchardt, Jon and Gabriel, Saadia and others},
  journal={arXiv e-prints},
  pages={arXiv--2110},
  year={2021}
}

@article{hendrycks2020aligning,
  title={Aligning ai with shared human values},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2008.02275},
  year={2020}
}

@article{lin2021truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}

@article{xu2020recipes,
  title={Recipes for safety in open-domain chatbots},
  author={Xu, Jing and Ju, Da and Li, Margaret and Boureau, Y-Lan and Weston, Jason and Dinan, Emily},
  journal={arXiv preprint arXiv:2010.07079},
  year={2020}
}


@Misc{doggpt,
  Author = {Boston Globe.},
  Title  = "\emph{A Boston Dynamics robot can now be run using ChatGPT. What could go wrong?}",
  Note   = "\url{https://www.bostonglobe.com/2023/05/03/business/robots-can-now-be-run-using-chatgpt-what-could-go-wrong/}",
  year = 2023,
}

@Misc{gptkills,
  Author = {Riera, Kevin and Rousseau, Anne-Laure and Baudelaire, Clement},
  Title  = "\emph{Doctor GPT-3: hype or reality?}",
  Note   = "\url{https://www.nabla.com/blog/gpt-3/}",
  year = 2020,
}


@Misc{nytimes,
  Author = "Kevin Roose",
  Title  = "\emph{A Conversation With Bing’s Chatbot Left Me Deeply Unsettled}",
  Note   = "\url{https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html}",
  year = 2023,
}

@article{tanzer2021memorisation,
  title={Memorisation versus generalisation in pre-trained language models},
  author={T{\"a}nzer, Michael and Ruder, Sebastian and Rei, Marek},
  journal={arXiv preprint arXiv:2105.00828},
  year={2021}
}

@article{carlini2022quantifying,
  title={Quantifying memorization across neural language models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2202.07646},
  year={2022}
}

@article{gehman2020realtoxicityprompts,
  title={Realtoxicityprompts: Evaluating neural toxic degeneration in language models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  journal={arXiv preprint arXiv:2009.11462},
  year={2020}
}

@article{pan2022effects,
  title={The effects of reward misspecification: Mapping and mitigating misaligned models},
  author={Pan, Alexander and Bhatia, Kush and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2201.03544},
  year={2022}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{di2022goal,
  title={Goal misgeneralization in deep reinforcement learning},
  author={Di Langosco, Lauro Langosco and Koch, Jack and Sharkey, Lee D and Pfau, Jacob and Krueger, David},
  booktitle={International Conference on Machine Learning},
  pages={12004--12019},
  year={2022},
  organization={PMLR}
}

@article{ngo2022alignment,
  title={The alignment problem from a deep learning perspective},
  author={Ngo, Richard},
  journal={arXiv preprint arXiv:2209.00626},
  year={2022}
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{nori2023capabilities,
  title={Capabilities of gpt-4 on medical challenge problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{bakker2022fine,
  title={Fine-tuning language models to find agreement among humans with diverse preferences},
  author={Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38176--38189},
  year={2022}
}

@article{glaese2022improving,
  title={Improving alignment of dialogue agents via targeted human judgements},
  author={Glaese, Amelia and McAleese, Nat and Tr{\k{e}}bacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and others},
  journal={arXiv preprint arXiv:2209.14375},
  year={2022}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{warnell2018deep,
  title={Deep tamer: Interactive agent shaping in high-dimensional state spaces},
  author={Warnell, Garrett and Waytowich, Nicholas and Lawhern, Vernon and Stone, Peter},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{wu2021recursively,
  title={Recursively summarizing books with human feedback},
  author={Wu, Jeff and Ouyang, Long and Ziegler, Daniel M and Stiennon, Nisan and Lowe, Ryan and Leike, Jan and Christiano, Paul},
  journal={arXiv preprint arXiv:2109.10862},
  year={2021}
}

@inproceedings{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Naik, Atharva and Ashok, Arjun and Dhanasekaran, Arut Selvan and Arunkumar, Anjana and Stap, David and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5085--5109},
  year={2022}
}

@article{go2023aligning,
  title={Aligning Language Models with Preferences through f-divergence Minimization},
  author={Go, Dongyoung and Korbak, Tomasz and Kruszewski, Germ{\'a}n and Rozen, Jos and Ryu, Nahyeon and Dymetman, Marc},
  journal={arXiv preprint arXiv:2302.08215},
  year={2023}
}

@article{korbak2023pretraining,
  title={Pretraining Language Models with Human Preferences},
  author={Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika and Buckley, Christopher L and Phang, Jason and Bowman, Samuel R and Perez, Ethan},
  journal={arXiv preprint arXiv:2302.08582},
  year={2023}
}

@article{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{solaiman2021process,
  title={Process for adapting language models to society (palms) with values-targeted datasets},
  author={Solaiman, Irene and Dennison, Christy},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5861--5873},
  year={2021}
}

@article{wang2022self,
  title={Self-Instruct: Aligning Language Model with Self Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@inproceedings{kaddourflat,
  title={When Do Flat Minima Optimizers Work?},
  author={Kaddour, Jean and Liu, Linqing and Silva, Ricardo and Kusner, Matt},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{dasgupta2022distinguishing,
  title={Distinguishing rule and exemplar-based generalization in learning systems},
  author={Dasgupta, Ishita and Grant, Erin and Griffiths, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4816--4830},
  year={2022},
  organization={PMLR}
}

@misc{trunc,
    key = {Truncated Gaussian Distribution},
    title = {Truncated normal distribution},
    url = {{https://en.wikipedia.org/wiki/Truncated_normal_distribution}},
    year = {2022}
}

@article{thiagarajan2021designing,
  title={Designing counterfactual generators using deep model inversion},
  author={Thiagarajan, Jayaraman and Narayanaswamy, Vivek Sivaraman and Rajan, Deepta and Liang, Jia and Chaudhari, Akshay and Spanias, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16873--16884},
  year={2021}
}

@inproceedings{li2018domain,
  title={Domain generalization via conditional invariant representations},
  author={Li, Ya and Gong, Mingming and Tian, Xinmei and Liu, Tongliang and Tao, Dacheng},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}


@inproceedings{sun2016deep,
  title={Deep coral: Correlation alignment for deep domain adaptation},
  author={Sun, Baochen and Saenko, Kate},
  booktitle={European conference on computer vision},
  pages={443--450},
  year={2016},
  organization={Springer}
}


@article{pittorino2022deep,
  title={Deep Networks on Toroids: Removing Symmetries Reveals the Structure of Flat Regions in the Landscape Geometry},
  author={Pittorino, Fabrizio and Ferraro, Antonio and Perugini, Gabriele and Feinauer, Christoph and Baldassi, Carlo and Zecchina, Riccardo},
  journal={arXiv preprint arXiv:2202.03038},
  year={2022}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint. arXiv:1907.02893},
  year={2019}
}

@inproceedings{mitchell2021fast,
    title={Fast model editing at scale},
    author={Eric Mitchell and Charles Lin and Antoine Bosselut and Chelsea Finn and Christopher D Manning},
    booktitle={Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
    year={2022},
}

@article{ainsworth2022,
    title        = {{Git re-basin: Merging models modulo permutation symmetries}},
    author       = {Ainsworth, Samuel K. and Hayase, Jonathan and Srinivasa, Siddhartha},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2209.04836}
}

@inproceedings{arora2018optimization,
    title        = {{On the optimization of deep networks: Implicit acceleration by overparameterization}},
    author       = {Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
    year         = {2018},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@inproceedings{arora2019fine,
    title        = {{Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks}},
    author       = {Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
    year         = {2019},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{arpit2021ensemble,
    title={Ensemble of averages: Improving model selection and boosting performance in domain generalization},
    author       = {Arpit, Devansh and Wang, Huan and Zhou, Yingbo and Xiong, Caiming},
    journal={Adv.\ in Neural Information Processing Systems (NeurIPS)},
    year={2022},
}

@article{beekman2019introduction,
    title        = {{An introduction to spontaneous symmetry breaking}},
    author       = {Beekman, Aron and Rademaker, Louk and van Wezel, Jasper},
    year         = {2019},
    journal      = {SciPost Physics Lecture Notes},
}

@inproceedings{beery2018recognition,
    title        = {{Recognition in terra incognita}},
    author       = {Beery, Sara and Van Horn, Grant and Perona, Pietro},
    year         = {2018},
    booktitle    = {Proc.\ Euro.\ Conf.\ on Computer Vision (ECCV)},
}

@inproceedings{benton2021loss,
    title        = {{Loss surface simplexes for mode connecting volumes and fast ensembling}},
    author       = {Benton, Gregory and Maddox, Wesley and Lotfi, Sanae and Wilson, Andrew Gordon Gordon},
    year         = {2021},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{besserve2018counterfactuals,
    title        = {{Counterfactuals uncover the modular structure of deep generative models}},
    author       = {Besserve, Michel and Mehrjou, Arash and Sun, R{\'e}my and Sch{\"o}lkopf, Bernhard},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1812.03253}
}

@inproceedings{besserve2018group,
    title        = {{Group invariance principles for causal generative models}},
    author       = {Besserve, Michel and Shajarisales, Naji and Sch{\"o}lkopf, Bernhard and Janzing, Dominik},
    year         = {2018},
    booktitle    = {Int.\ Conf.\ on Artificial Intelligence and Statistics (AISTATS)},
}

@article{cooper2020critical,
    title        = {{The critical locus of overparameterized neural networks}},
    author       = {Cooper, Y},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2005.04210}
}

@article{czarnecki2019deep,
    title        = {{A Deep Neural Network's Loss Surface Contains Every Low-dimensional Pattern}},
    author       = {Czarnecki, Wojciech Marian and Osindero, Simon and Pascanu, Razvan and Jaderberg, Max},
    year         = {2019},
    journal      = {arXiv preprint. arXiv:1912.07559}
}

@article{dittadi2020transfer,
    title        = {{On the transfer of disentangled representations in realistic settings}},
    author       = {Dittadi, Andrea and Tr{\"a}uble, Frederik and Locatello, Francesco and W{\"u}thrich, Manuel and Agrawal, Vaibhav and Winther, Ole and Bauer, Stefan and Sch{\"o}lkopf, Bernhard},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2010.14407}
}

@inproceedings{draxler2018essentially,
    title        = {{Essentially no barriers in neural network energy landscape}},
    author       = {Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred},
    year         = {2018},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@article{du2018gradient,
    title        = {{Gradient descent provably optimizes over-parameterized neural networks}},
    author       = {Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1810.02054}
}

@inproceedings{du2019gradient,
    title        = {{Gradient descent finds global minima of deep neural networks}},
    author       = {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
    year         = {2019},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@article{entezari2021role,
    title        = {{The role of permutation invariance in linear mode connectivity of neural networks}},
    author       = {Entezari, Rahim and Sedghi, Hanie and Saukh, Olga and Neyshabur, Behnam},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2110.06296}
}

@article{fort2019deep,
    title        = {{Deep ensembles: A loss landscape perspective}},
    author       = {Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
    year         = {2019},
    journal      = {arXiv preprint. arXiv:1912.02757}
}

@article{fort2019large,
    title        = {{Large scale structure of neural network loss landscapes}},
    author       = {Fort, Stanislav and Jastrzebski, Stanislaw},
    year         = {2019},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{frankle2020linear,
    title        = {{Linear mode connectivity and the lottery ticket hypothesis}},
    author       = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
    year         = {2020},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{freeman2016topology,
    title        = {{Topology and geometry of half-rectified network optimization}},
    author       = {Freeman, C Daniel and Bruna, Joan},
    year         = {2016},
    journal      = {arXiv preprint. arXiv:1611.01540}
}

@article{garcia1966relation,
    title        = {{Relation of cue to consequence in avoidance learning}},
    author       = {Garcia, John and Koelling, Robert A},
    year         = {1966},
    journal      = {Psychonomic science},
    publisher    = {Springer},
    number       = {1},
}

@article{garipov2018loss,
    title        = {{Loss surfaces, mode connectivity, and fast ensembling of dnns}},
    author       = {Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
    year         = {2018},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{geirhos2018imagenet,
    title        = {{ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness}},
    author       = {Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1811.12231}
}

@article{geirhos2020shortcut,
    title        = {{Shortcut learning in deep neural networks}},
    author       = {Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
    year         = {2020},
    journal      = {Nature Machine Intelligence},
}

@article{lu2021nonlinear,
  title={Nonlinear invariant risk minimization: A causal approach},
  author={Lu, Chaochao and Wu, Yuhuai and Hern{\'a}ndez-Lobato, Jo{\'s}e Miguel and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint. arXiv:2102.12353},
  year={2021}
}

@inproceedings{krueger2021out,
  title={Out-of-distribution generalization via risk extrapolation (rex)},
  author={Krueger, David and Caballero, Ethan and Jacobsen, Joern-Henrik and Zhang, Amy and Binas, Jonathan and Zhang, Dinghuai and Le Priol, Remi and Courville, Aaron},
  booktitle={Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
  year={2021},
}

@article{kaur2022modeling,
  title={Modeling the data-generating process is necessary for out-of-distribution generalization},
  author={Kaur, Jivat Neet and Kiciman, Emre and Sharma, Amit},
  journal={arXiv preprint. arXiv:2206.07837},
  year={2022}
}


@article{gontijo2021no,
    title        = {{No one representation to rule them all: Overlapping features of training methods}},
    author       = {Gontijo-Lopes, Raphael and Dauphin, Yann and Cubuk, Ekin D},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2110.12899}
}


@incollection{hecht1990algebraic,
    title        = {{On the algebraic structure of feedforward network weight spaces}},
    author       = {Hecht-Nielsen, Robert},
    year         = {1990},
    booktitle    = {Advanced Neural Computers},
    publisher    = {Elsevier},
}

@inproceedings{hendrycks2021many,
    title        = {{The many faces of robustness: A critical analysis of out-of-distribution generalization}},
    author       = {Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
    year         = {2021},
    booktitle    = {Proc.\ Int.\ Conf.\ on Computer Vision (ICCV)},
}

@article{hermann2020origins,
    title        = {{The origins and prevalence of texture bias in convolutional neural networks}},
    author       = {Hermann, Katherine and Chen, Ting and Kornblith, Simon},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{hermann2020shapes,
    title        = {{What shapes feature representations? exploring datasets, architectures, and training}},
    author       = {Hermann, Katherine and Lampinen, Andrew},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{hernandez2021scaling,
    title        = {{Scaling laws for transfer}},
    author       = {Hernandez, Danny and Kaplan, Jared and Henighan, Tom and McCandlish, Sam},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2102.01293}
}

@inproceedings{trivedi2022augmentations,
  title={Augmentations in graph contrastive learning: Current methodological flaws \& towards better practices},
  author={Trivedi, Puja and Lubana, Ekdeep Singh and Yan, Yujun and Yang, Yaoqing and Koutra, Danai},
  booktitle={Proceedings of the ACM Web Conference 2022},
  pages={1538--1549},
  year={2022}
}

@article{lubana2021quadratic,
  title={How do quadratic regularizers prevent catastrophic forgetting: The role of interpolation},
  author={Lubana, Ekdeep Singh and Trivedi, Puja and Koutra, Danai and Dick, Robert P},
  journal={arXiv preprint. arXiv:2102.02805},
  year={2021}
}

@article{hooker2019compressed,
    title        = {{What do compressed deep neural networks forget?}},
    author       = {Hooker, Sara and Courville, Aaron and Clark, Gregory and Dauphin, Yann and Frome, Andrea},
    year         = {2019},
    journal      = {arXiv preprint. arXiv:1911.05248}
}


@inproceedings{hyvarinen2019nonlinear,
    title        = {{Nonlinear ICA using auxiliary variables and generalized contrastive learning}},
    author       = {Hyvarinen, Aapo and Sasaki, Hiroaki and Turner, Richard},
    year         = {2019},
    booktitle    = {The 22nd Int.\ Conf.\ on Artificial Intelligence and Statistics (AISTATS)},
}

@article{islam2021shape,
    title        = {{Shape or texture: Understanding discriminative features in cnns}},
    author       = {Islam, Md Amirul and Kowal, Matthew and Esser, Patrick and Jia, Sen and Ommer, Bjorn and Derpanis, Konstantinos G and Bruce, Neil},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2101.11604}
}

@article{izmailov2018averaging,
    title        = {{Averaging weights leads to wider optima and better generalization}},
    author       = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1803.05407}
}

@article{jacobsen2018excessive,
    title        = {{Excessive invariance causes adversarial vulnerability}},
    author       = {Jacobsen, J{\"o}rn-Henrik and Behrmann, Jens and Zemel, Richard and Bethge, Matthias},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1811.00401}
}

@article{jacot2018neural,
    title        = {{Neural tangent kernel: Convergence and generalization in neural networks}},
    author       = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
    year         = {2018},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{jo2017measuring,
    title        = {{Measuring the tendency of cnns to learn surface statistical regularities}},
    author       = {Jo, Jason and Bengio, Yoshua},
    year         = {2017},
    journal      = {arXiv preprint. arXiv:1711.11561}
}


@article{kalimeris2019sgd,
    title        = {{Sgd on neural networks learns functions of increasing complexity}},
    author       = {Nakkiran, Preetum and Kalimeris, Dimitris and Kaplun, Gal and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
    year         = {2019},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{kawaguchi2016deep,
    title        = {{Deep learning without poor local minima}},
    author       = {Kawaguchi, Kenji},
    year         = {2016},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{kawaguchi2020elimination,
    title        = {{Elimination of all bad local minima in deep learning}},
    author       = {Kawaguchi, Kenji and Kaelbling, Leslie},
    year         = {2020},
    booktitle    = {Int.\ Conf.\ on Artificial Intelligence and Statistics (AISTATS)},
}



@article{teney2022predicting,
  title={Predicting is not understanding: Recognizing and addressing underspecification in machine learning},
  author={Teney, Damien and Peyrard, Maxime and Abbasnejad, Ehsan},
  journal={arXiv preprint. arXiv:2207.02598},
  year={2022}
}

@article{hu2020surprising,
  title={The surprising simplicity of the early-time learning dynamics of neural networks},
  author={Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
  journal={Adv.\ in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lee2022diversify,
  title={Diversify and Disambiguate: Learning From Underspecified Data},
  author={Lee, Yoonho and Yao, Huaxiu and Finn, Chelsea},
  journal={arXiv preprint. arXiv:2202.03418},
  year={2022}
}

@inproceedings{balestriero2018spline,
  title={A spline theory of deep learning},
  author={Balestriero, Randall and others},
  booktitle={Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
  year={2018},
}

@article{balestriero2017neural,
  title={Neural decision trees},
  author={Balestriero, Randall},
  journal={arXiv preprint. arXiv:1702.07360},
  year={2017}
}

@inproceedings{wang2018max,
  title={A max-affine spline perspective of recurrent neural networks},
  author={Wang, Zichao and Balestriero, Randall and Baraniuk, Richard},
  booktitle={Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  year={2018}
}

@article{bronstein2021geometric,
  title={Geometric deep learning: Grids, groups, graphs, geodesics, and gauges},
  author={Bronstein, Michael M and Bruna, Joan and Cohen, Taco and Veli{\v{c}}kovi{\'c}, Petar},
  journal={arXiv preprint. arXiv:2104.13478},
  year={2021}
}

@article{balestriero2018mad,
  title={Mad max: Affine spline insights into deep learning},
  author={Balestriero, Randall and Baraniuk, Richard},
  journal={arXiv preprint. arXiv:1805.06576},
  year={2018}
}

@inproceedings{he2019rethinking,
  title={Rethinking imagenet pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle={Proc.\ Int.\ Conf.\ on Computer Vision},
  year={2019}
}

@article{flkirichenko2022,
    title        = {{On feature learning in the presence of spurious correlations}},
    author       = {Kirichenko, Polina and Izmailov, Pavel and Nate Gruver and Wilson, Andrew Gordon},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2210.11369}
}

@article{kirichenko2022last,
    title        = {{Last layer re-training is sufficient for robustness to spurious correlations}},
    author       = {Kirichenko, Polina and Izmailov, Pavel and Wilson, Andrew Gordon},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2204.02937}
}

@article{rosenfeld2022domain,
  title={Domain-adjusted regression or: Erm may already learn features sufficient for out-of-distribution generalization},
  author={Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
  journal={arXiv preprint. arXiv:2202.06856},
  year={2022}
}

@article{klindt2020towards,
    title        = {{Towards nonlinear disentanglement in natural data with temporal sparse coding}},
    author       = {Klindt, David and Schott, Lukas and Sharma, Yash and Ustyuzhaninov, Ivan and Brendel, Wieland and Bethge, Matthias and Paiton, Dylan},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2007.10930}
}

@article{koch2021objective,
    title        = {{Objective robustness in deep reinforcement learning}},
    author       = {Koch, Jack and Langosco, Lauro and Pfau, Jacob and Le, James and Sharkey, Lee},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2105.14111}
}

@inproceedings{kornblithcka,
    title        = {{Similarity of Neural Network Representations Revisited}},
    author       = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
    year         = {2019},
    month        = {09--15 Jun},
    booktitle    = {Proc.\ of the 36th Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
    publisher    = {PMLR},
    series       = {Proc.\ of Machine Learning Research},
}

@article{d2020underspecification,
  title={Underspecification presents challenges for credibility in modern machine learning},
  author={D’Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoffman, Matthew D and others},
  journal={Journal of Machine Learning Research (JMLR)},
  year={2020}
}


@misc{krizhevsky2009learning,
    title        = {{Learning multiple layers of features from tiny images}},
    author       = {Krizhevsky, Alex and Hinton, Geoffrey and others},
    year         = {2009},
    publisher    = {Citeseer}
}

@article{kuditipudi2019explaining,
    title        = {{Explaining landscape connectivity of low-cost solutions for multilayer nets}},
    author       = {Kuditipudi, Rohith and Wang, Xiang and Lee, Holden and Zhang, Yi and Li, Zhiyuan and Hu, Wei and Ge, Rong and Arora, Sanjeev},
    year         = {2019},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{kumar2022fine,
    title        = {{Fine-tuning can distort pretrained features and underperform out-of-distribution}},
    author       = {Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2202.10054}
}

@article{lacoste2020synbols,
    title        = {{Synbols: Probing learning algorithms with synthetic datasets}},
    author       = {Lacoste, Alexandre and Rodr{\'\i}guez L{\'o}pez, Pau and Branchaud-Charron, Fr{\'e}d{\'e}ric and Atighehchian, Parmida and Caccia, Massimo and Laradji, Issam Hadj and Drouin, Alexandre and Craddock, Matthew and Charlin, Laurent and V{\'a}zquez, David},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{lengyel2020genni,
    title        = {{Genni: Visualising the geometry of equivalences for neural network identifiability}},
    author       = {Lengyel, Daniel and Petangoda, Janith and Falk, Isak and Highnam, Kate and Lazarou, Michalis and Kolbeinsson, Arinbj{\"o}rn and Deisenroth, Marc Peter and Jennings, Nicholas R},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2011.07407}
}

@article{liang2018adding,
    title        = {{Adding one neuron can eliminate all bad local minima}},
    author       = {Liang, Shiyu and Sun, Ruoyu and Lee, Jason D and Srikant, Rayadurgam},
    year         = {2018},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{locatello2020weakly,
    title        = {{Weakly-supervised disentanglement without compromises}},
    author       = {Locatello, Francesco and Poole, Ben and R{\"a}tsch, Gunnar and Sch{\"o}lkopf, Bernhard and Bachem, Olivier and Tschannen, Michael},
    year         = {2020},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{lu2017depth,
    title        = {{Depth creates no bad local minima}},
    author       = {Lu, Haihao and Kawaguchi, Kenji},
    year         = {2017},
    journal      = {arXiv preprint. arXiv:1702.08580}
}

@inproceedings{maini2022characterizing,
    title        = {{Characterizing Datapoints via Second-Split Forgetting}},
    author       = {Maini, Pratyush and Garg, Saurabh and Lipton, Zachary Chase and Kolter, J Zico},
    year         = {2022},
    booktitle    = {ICML 2022: Workshop on Spurious Correlations, Invariance and Stability}
}

@inproceedings{mangalam2019deep,
    title        = {{Do deep neural networks learn shallow learnable examples first?}},
    author       = {Karttikeya Mangalam and Vinay Uday Prabhu},
    year         = {2019},
    booktitle    = {ICML 2019 Workshop on Identifying and Understanding Deep Learning Phenomena},
    url          = {https://openreview.net/forum?id=HkxHv4rn24}
}

@article{mania2019model,
    title        = {{Model similarity mitigates test set overuse}},
    author       = {Mania, Horia and Miller, John and Schmidt, Ludwig and Hardt, Moritz and Recht, Benjamin},
    year         = {2019},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{marr1976early,
    title        = {{Early processing of visual information}},
    author       = {Marr, David},
    year         = {1976},
    journal      = {Philosophical Transactions of the Royal Society of London. B, Biological Sciences},
    publisher    = {The Royal Society London},
    number       = {942},
    volume       = {275},
}

@article{mirzadeh2020linear,
    title        = {{Linear mode connectivity in multitask and continual learning}},
    author       = {Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Gorur, Dilan and Pascanu, Razvan and Ghasemzadeh, Hassan},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2010.04495}
}

@inproceedings{mitchell2022memory,
    title        = {{Memory-Based Model Editing at Scale}},
    author       = {Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Manning, Christopher D and Finn, Chelsea},
    year         = {2022},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{morcos2018insights,
    title        = {{Insights on representational similarity in neural networks with canonical correlation}},
    author       = {Morcos, Ari and Raghu, Maithra and Bengio, Samy},
    year         = {2018},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{neyshabur2020being,
    title        = {{What is being transferred in transfer learning?}},
    author       = {Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{nguyen2017loss,
    title        = {{The loss surface of deep and wide neural networks}},
    author       = {Nguyen, Quynh and Hein, Matthias},
    year         = {2017},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proc.\ of the IEEE international conference on computer vision},
  year={2015}
}

@inproceedings{nacson2019convergence,
  title={Convergence of gradient descent on separable data},
  author={Nacson, Mor Shpigel and Lee, Jason and Gunasekar, Suriya and Savarese, Pedro Henrique Pamplona and Srebro, Nathan and Soudry, Daniel},
  booktitle={Int.\ Conf.\ on Artificial Intelligence and Statistics (AISTATS)},
  year={2019},
}

@article{soudry2018implicit,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={Journal of Machine Learning Research (JMLR) },
  year={2018}
}

@article{lyu2019gradient,
  title={Gradient descent maximizes the margin of homogeneous neural networks},
  author={Lyu, Kaifeng and Li, Jian},
  journal={arXiv preprint. arXiv:1906.05890},
  year={2019}
}

@article{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  journal={Adv.\ in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@article{nguyen2018loss,
    title        = {{On the loss landscape of a class of deep neural networks with no bad local valleys}},
    author       = {Nguyen, Quynh and Mukkamala, Mahesh Chandra and Hein, Matthias},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1809.10749}
}

@inproceedings{nguyen2018neural,
    title        = {{Neural networks should be wide enough to learn disconnected decision regions}},
    author       = {Nguyen, Quynh and Mukkamala, Mahesh Chandra and Hein, Matthias},
    year         = {2018},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@inproceedings{nguyen2018optimization,
    title        = {{Optimization landscape and expressivity of deep CNNs}},
    author       = {Nguyen, Quynh and Hein, Matthias},
    year         = {2018},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@inproceedings{nguyen2019connected,
    title        = {{On connected sublevel sets in deep learning}},
    author       = {Nguyen, Quynh},
    year         = {2019},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@article{nguyen2020global,
    title        = {{Global convergence of deep networks with one wide layer followed by pyramidal topology}},
    author       = {Nguyen, Quynh and Mondelli, Marco},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{nguyen2020wide,
    title        = {{Do wide and deep networks learn the same things? uncovering how neural network representations vary with width and depth}},
    author       = {Nguyen, Thao and Raghu, Maithra and Kornblith, Simon},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2010.15327}
}

@article{nguyen2021solutions,
    title        = {{When are solutions connected in deep networks?}},
    author       = {Nguyen, Quynh and Br{\'e}chet, Pierre and Mondelli, Marco},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{peebles2020hessian,
    title        = {{The hessian penalty: A weak prior for unsupervised disentanglement}},
    author       = {Peebles, William and Peebles, John and Zhu, Jun-Yan and Efros, Alexei and Torralba, Antonio},
    year         = {2020},
    booktitle    = {Proc.\ Euro.\ Conf.\ on Computer Vision},
    organization = {Springer}
}

@book{peters2017elements,
    title        = {{Elements of causal inference: foundations and learning algorithms}},
    author       = {Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
    year         = {2017},
    publisher    = {The MIT Press}
}

@article{pezeshki2021gradient,
    title        = {{Gradient starvation: A learning proclivity in neural networks}},
    author       = {Pezeshki, Mohammad and Kaba, Oumar and Bengio, Yoshua and Courville, Aaron C and Precup, Doina and Lajoie, Guillaume},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{raghu2017svcca,
    title        = {{Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability}},
    author       = {Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
    year         = {2017},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{raghu2021vision,
    title        = {{Do vision transformers see like convolutional neural networks?}},
    author       = {Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{rahaman2019spectral,
    title        = {{On the spectral bias of neural networks}},
    author       = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
    year         = {2019},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{ramasesh2020anatomy,
    title        = {{Anatomy of catastrophic forgetting: Hidden representations and task semantics}},
    author       = {Ramasesh, Vinay V and Dyer, Ethan and Raghu, Maithra},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2007.07400}
}

@article{rame2022diverse,
    title        = {{Diverse weight averaging for out-of-distribution generalization}},
    author       = {Rame, Alexandre and Kirchmeyer, Matthieu and Rahier, Thibaud and Rakotomamonjy, Alain and Gallinari, Patrick and Cord, Matthieu},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2205.09739}
}

@inproceedings{recht2019imagenet,
    title        = {{Do imagenet classifiers generalize to imagenet?}},
    author       = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
    year         = {2019},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@inproceedings{ritter2017cognitive,
    title        = {{Cognitive psychology for deep neural networks: A shape bias case study}},
    author       = {Ritter, Samuel and Barrett, David GT and Santoro, Adam and Botvinick, Matt M},
    year         = {2017},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@inproceedings{sagawa2020investigation,
    title        = {{An investigation of why overparameterization exacerbates spurious correlations}},
    author       = {Sagawa, Shiori and Raghunathan, Aditi and Koh, Pang Wei and Liang, Percy},
    year         = {2020},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{santurkar2021editing,
    title        = {{Editing a classifier by rewriting its prediction rules}},
    author       = {Santurkar, Shibani and Tsipras, Dimitris and Elango, Mahalaxmi and Bau, David and Torralba, Antonio and Madry, Aleksander},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{scholkopf2021towards,
    title        = {{Towards causal representation learning}},
    author       = {Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2102.11107}
}


@article{sinitsin2020editable,
    title        = {{Editable neural networks}},
    author       = {Sinitsin, Anton and Plokhotnyuk, Vsevolod and Pyrkin, Dmitriy and Popov, Sergei and Babenko, Artem},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2004.00345}
}

@article{skorokhodov2019loss,
    title        = {{Loss landscape sightseeing with multi-point optimization}},
    author       = {Skorokhodov, Ivan and Burtsev, Mikhail},
    year         = {2019},
    journal      = {arXiv preprint. arXiv:1910.03867}
}

@article{tanaka2019deep,
    title        = {{From deep learning to mechanistic understanding in neuroscience: the structure of retinal prediction}},
    author       = {Tanaka, Hidenori and Nayebi, Aran and Maheswaranathan, Niru and McIntosh, Lane and Baccus, Stephen and Ganguli, Surya},
    year         = {2019},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{taori2020measuring,
    title        = {{Measuring robustness to natural distribution shifts in image classification}},
    author       = {Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Carlini, Nicholas and Recht, Benjamin and Schmidt, Ludwig},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{tatro2020optimizing,
    title        = {{Optimizing mode connectivity via neuron alignment}},
    author       = {Tatro, Norman and Chen, Pin-Yu and Das, Payel and Melnyk, Igor and Sattigeri, Prasanna and Lai, Rongjie},
    year         = {2020},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@article{toneva2018empirical,
    title        = {{An empirical study of example forgetting during deep neural network learning}},
    author       = {Toneva, Mariya and Sordoni, Alessandro and Combes, Remi Tachet des and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1812.05159}
}

@article{trivedi2022analyzing,
    title        = {{Analyzing Data-Centric Properties for Contrastive Learning on Graphs}},
    author       = {Trivedi, Puja and Lubana, Ekdeep Singh and Heimann, Mark and Koutra, Danai and Thiagarajan, Jayaraman J},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2208.02810}
}


@misc{zhou2019hype,
      title={HYPE: A Benchmark for Human eYe Perceptual Evaluation of Generative Models}, 
      author={Sharon Zhou and Mitchell L. Gordon and Ranjay Krishna and Austin Narcomey and Li Fei-Fei and Michael S. Bernstein},
      year={2019},
      eprint={1904.01121},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{milliere2024philosophical,
      title={A Philosophical Introduction to Language Models -- Part I: Continuity With Classic Debates}, 
      author={Raphaël Millière and Cameron Buckner},
      year={2024},
      eprint={2401.03910},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{bubeck2023sparks_talk,
    title        = {{Sparks of artificial general intelligence: Early experiments with GPT-4 (Talk)}},
    author       = {Bubeck, S{\'e}bastien},
    year         = {2023},
    url          = {https://www.youtube.com/watch?v=qbIk7-JPB2c}
}

@article{valle2018deep,
    title        = {{Deep learning generalizes because the parameter-function map is biased towards simple functions}},
    author       = {Valle-Perez, Guillermo and Camargo, Chico Q and Louis, Ard A},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1805.08522}
}


@article{von2021self,
    title        = {{Self-supervised learning with data augmentations provably isolates content from style}},
    author       = {Von K{\"u}gelgen, Julius and Sharma, Yash and Gresele, Luigi and Brendel, Wieland and Sch{\"o}lkopf, Bernhard and Besserve, Michel and Locatello, Francesco},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{voynov2020unsupervised,
    title        = {{Unsupervised discovery of interpretable directions in the gan latent space}},
    author       = {Voynov, Andrey and Babenko, Artem},
    year         = {2020},
    booktitle    = {Proc.\ Int.\ conf.\ on machine learning  (ICML)},
}

@inproceedings{wang2020geometric,
    title        = {{A Geometric Analysis of Deep Generative Image Models and Its Applications}},
    author       = {Wang, Binxu and Ponce, Carlos R},
    year         = {2020},
    booktitle    = {Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)}
}

@article{watanabe2020counting,
    title        = {{Counting rules of Nambu--Goldstone modes}},
    author       = {Watanabe, Haruki},
    year         = {2020},
    journal      = {Annual Review of Condensed Matter Physics},
    publisher    = {Annual Reviews},
}

@inproceedings{wen2022fighting,
    title        = {{Fighting Fire with Fire: Avoiding DNN Shortcuts through Priming}},
    author       = {Wen, Chuan and Qian, Jianing and Lin, Jierui and Teng, Jiaye and Jayaraman, Dinesh and Gao, Yang},
    year         = {2022},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@article{wiles2021fine,
    title        = {{A fine-grained analysis on distribution shift}},
    author       = {Wiles, Olivia and Gowal, Sven and Stimberg, Florian and Alvise-Rebuffi, Sylvestre and Ktena, Ira and Cemgil, Taylan and others},
    year         = {2021},
    journal      = {arXiv preprint. arXiv:2110.11328}
}

@article{williams2021generalized,
    title        = {{Generalized shape metrics on neural representations}},
    author       = {Williams, Alex H and Kunz, Erin and Kornblith, Simon and Linderman, Scott},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{wortsman2021learning,
    title        = {{Learning neural network subspaces}},
    author       = {Wortsman, Mitchell and Horton, Maxwell C and Guestrin, Carlos and Farhadi, Ali and Rastegari, Mohammad},
    year         = {2021},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@inproceedings{wortsman2022model,
    title        = {{Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time}},
    author       = {Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
    year         = {2022},
    booktitle    = {Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
}

@inproceedings{wortsman2022robust,
    title        = {{Robust fine-tuning of zero-shot models}},
    author       = {Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
    year         = {2022},
    booktitle    = {Proc.\ Int.\ Conf.\ on Computer Vision and Pattern Recognition (CVPR)},
}

@article{xiao2020noise,
    title        = {{Noise or signal: The role of image backgrounds in object recognition}},
    author       = {Xiao, Kai and Engstrom, Logan and Ilyas, Andrew and Madry, Aleksander},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2006.09994}
}

@inproceedings{ye2022ood,
    title        = {{OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization}},
    author       = {Ye, Nanyang and Li, Kaican and Bai, Haoyue and Yu, Runpeng and Hong, Lanqing and Zhou, Fengwei and Li, Zhenguo and Zhu, Jun},
    year         = {2022},
    booktitle    = {Proc.\ Int.\ Conf.\ on Computer Vision and Pattern Recognition (CVPR)},
}

@article{zhao2020bridging,
    title        = {{Bridging mode connectivity in loss landscapes and adversarial robustness}},
    author       = {Zhao, Pu and Chen, Pin-Yu and Das, Payel and Ramamurthy, Karthikeyan Natesan and Lin, Xue},
    year         = {2020},
    journal      = {arXiv preprint. arXiv:2005.00060}
}

@article{zhou2017places,
    title        = {{Places: A 10 million Image Database for Scene Recognition}},
    author       = {Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
    year         = {2017},
    journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    publisher    = {IEEE}
}

@inproceedings{nanda2022measuring,
  title={Measuring Representational Robustness of Neural Networks Through Shared Invariances},
  author={Nanda, Vedant and Speicher, Till and Kolling, Camila and Dickerson, John P and Gummadi, Krishna and Weller, Adrian},
  booktitle={Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
  year={2022},
}

@article{kreutzer2022quality,
  title={Quality at a glance: An audit of web-crawled multilingual datasets},
  author={Kreutzer, Julia and Caswell, Isaac and Wang, Lisa and Wahab, Ahsan and van Esch, Daan and Ulzii-Orshikh, Nasanbayar and Tapo, Allahsera and Subramani, Nishant and Sokolov, Artem and Sikasote, Claytone and others},
  journal={Transactions of the Association for Computational Linguistics},
  year={2022},
  publisher={MIT Press}
}


@article{du2018algorithmic,
  title={Algorithmic regularization in learning deep homogeneous models: Layers are automatically balanced},
  author={Du, Simon S and Hu, Wei and Lee, Jason D},
  journal={Adv.\ in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}


@inproceedings{
kunin2021neural,
title={Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics},
author={Daniel Kunin and Javier Sagastuy-Brena and Surya Ganguli and Daniel LK Yamins and Hidenori Tanaka},
booktitle={Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
year={2021}
}

@article{tanaka2021noether,
  title={Noether’s learning dynamics: Role of symmetry breaking in neural networks},
  author={Tanaka, Hidenori and Kunin, Daniel},
  journal={Adv.\ in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@article{wan2020spherical,
  title={Spherical motion dynamics: Learning dynamics of neural network with normalization, weight decay, and sgd},
  author={Wan, Ruosi and Zhu, Zhanxing and Zhang, Xiangyu and Sun, Jian},
  journal={arXiv preprint. arXiv:2006.08419},
  year={2020}
}

@article{roburin2022spherical,
  title={Spherical perspective on learning with normalization layers},
  author={Roburin, Simon and de Mont-Marin, Yann and Bursuc, Andrei and Marlet, Renaud and P{\'e}rez, Patrick and Aubry, Mathieu},
  journal={Neurocomputing},
  year={2022},
}

@inproceedings{kaddourflat,
  title={When Do Flat Minima Optimizers Work?},
  author={Kaddour, Jean and Liu, Linqing and Silva, Ricardo and Kusner, Matt},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{dasgupta2022distinguishing,
  title={Distinguishing rule and exemplar-based generalization in learning systems},
  author={Dasgupta, Ishita and Grant, Erin and Griffiths, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4816--4830},
  year={2022},
  organization={PMLR}
}

@misc{trunc,
    key = {Truncated Gaussian Distribution},
    title = {Truncated normal distribution},
    url = {{https://en.wikipedia.org/wiki/Truncated_normal_distribution}},
    year = {2022}
}

@article{thiagarajan2021designing,
  title={Designing counterfactual generators using deep model inversion},
  author={Thiagarajan, Jayaraman and Narayanaswamy, Vivek Sivaraman and Rajan, Deepta and Liang, Jia and Chaudhari, Akshay and Spanias, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16873--16884},
  year={2021}
}

@inproceedings{li2018domain,
  title={Domain generalization via conditional invariant representations},
  author={Li, Ya and Gong, Mingming and Tian, Xinmei and Liu, Tongliang and Tao, Dacheng},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}


@inproceedings{sun2016deep,
  title={Deep coral: Correlation alignment for deep domain adaptation},
  author={Sun, Baochen and Saenko, Kate},
  booktitle={European conference on computer vision},
  pages={443--450},
  year={2016},
  organization={Springer}
}


@article{pittorino2022deep,
  title={Deep Networks on Toroids: Removing Symmetries Reveals the Structure of Flat Regions in the Landscape Geometry},
  author={Pittorino, Fabrizio and Ferraro, Antonio and Perugini, Gabriele and Feinauer, Christoph and Baldassi, Carlo and Zecchina, Riccardo},
  journal={arXiv preprint arXiv:2202.03038},
  year={2022}
}

@inproceedings{gresele2020incomplete,
    title        = {{The incomplete rosetta stone problem: Identifiability results for multi-view nonlinear ica}},
    author       = {Gresele, Luigi and Rubenstein, Paul K and Mehrjou, Arash and Locatello, Francesco and Sch{\"o}lkopf, Bernhard},
    year         = {2020},
    booktitle    = {Uncertainty in Artificial Intelligence (UAI)},
}

@article{gresele2021independent,
    title        = {{Independent mechanism analysis, a new concept?}},
    author       = {Gresele, Luigi and Von K{\"u}gelgen, Julius and Stimper, Vincent and Sch{\"o}lkopf, Bernhard and Besserve, Michel},
    year         = {2021},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@incollection{hecht1990algebraic,
    title        = {{On the algebraic structure of feedforward network weight spaces}},
    author       = {Hecht-Nielsen, Robert},
    year         = {1990},
    booktitle    = {Advanced Neural Computers},
    publisher    = {Elsevier},
}

@inproceedings{hendrycks2021many,
    title        = {{The many faces of robustness: A critical analysis of out-of-distribution generalization}},
    author       = {Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
    year         = {2021},
    booktitle    = {Proc.\ Int.\ Conf.\ on Computer Vision (ICCV)},
}

@article{hyvarinen2016unsupervised,
    title        = {{Unsupervised feature extraction by time-contrastive learning and nonlinear ica}},
    author       = {Hyvarinen, Aapo and Morioka, Hiroshi},
    year         = {2016},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{hyvarinen2017nonlinear,
    title        = {{Nonlinear ICA of temporally dependent stationary sources}},
    author       = {Hyvarinen, Aapo and Morioka, Hiroshi},
    year         = {2017},
    booktitle    = {Proc. Int.\ Conf.\ on Artificial Intelligence and Statistics (AISTATS)},
}


@article{izmailov2018averaging,
    title        = {{Averaging weights leads to wider optima and better generalization}},
    author       = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1803.05407}
}

@article{jacobsen2018excessive,
    title        = {{Excessive invariance causes adversarial vulnerability}},
    author       = {Jacobsen, J{\"o}rn-Henrik and Behrmann, Jens and Zemel, Richard and Bethge, Matthias},
    year         = {2018},
    journal      = {arXiv preprint. arXiv:1811.00401}
}

@article{jacot2018neural,
    title        = {{Neural tangent kernel: Convergence and generalization in neural networks}},
    author       = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
    year         = {2018},
    journal      = {Adv.\ in Neural Information Processing Systems (NeurIPS)},
}

@misc{edelman2024evolutionstatisticalinductionheads,
      title={The Evolution of Statistical Induction Heads: In-Context Learning Markov Chains}, 
      author={Benjamin L. Edelman and Ezra Edelman and Surbhi Goel and Eran Malach and Nikolaos Tsilivis},
      year={2024},
      eprint={2402.11004},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.11004}, 
}

@misc{akyürek2024incontextlanguagelearningarchitectures,
      title={In-Context Language Learning: Architectures and Algorithms}, 
      author={Ekin Akyürek and Bailin Wang and Yoon Kim and Jacob Andreas},
      year={2024},
      eprint={2401.12973},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.12973}, 
}

@article{jo2017measuring,
    title        = {{Measuring the tendency of cnns to learn surface statistical regularities}},
    author       = {Jo, Jason and Bengio, Yoshua},
    year         = {2017},
    journal      = {arXiv preprint. arXiv:1711.11561}
}

@article{juneja2022linear,
    title        = {{Linear connectivity reveals generalization strategies}},
    author       = {Juneja, Jeevesh and Bansal, Rachit and Cho, Kyunghyun and Sedoc, Jo{\~a}o and Saphra, Naomi},
    year         = {2022},
    journal      = {arXiv preprint. arXiv:2205.12411}
}


@article{teney2022predicting,
  title={Predicting is not understanding: Recognizing and addressing underspecification in machine learning},
  author={Teney, Damien and Peyrard, Maxime and Abbasnejad, Ehsan},
  journal={arXiv preprint. arXiv:2207.02598},
  year={2022}
}

@article{hu2020surprising,
  title={The surprising simplicity of the early-time learning dynamics of neural networks},
  author={Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
  journal={Adv.\ in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lee2022diversify,
  title={Diversify and Disambiguate: Learning From Underspecified Data},
  author={Lee, Yoonho and Yao, Huaxiu and Finn, Chelsea},
  journal={arXiv preprint. arXiv:2202.03418},
  year={2022}
}

@inproceedings{balestriero2018spline,
  title={A spline theory of deep learning},
  author={Balestriero, Randall and others},
  booktitle={Proc.\ Int.\ Conf.\ on Machine Learning  (ICML)},
  year={2018},
}

@article{balestriero2017neural,
  title={Neural decision trees},
  author={Balestriero, Randall},
  journal={arXiv preprint. arXiv:1702.07360},
  year={2017}
}

@inproceedings{wang2018max,
  title={A max-affine spline perspective of recurrent neural networks},
  author={Wang, Zichao and Balestriero, Randall and Baraniuk, Richard},
  booktitle={Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  year={2018}
}

@article{bronstein2021geometric,
  title={Geometric deep learning: Grids, groups, graphs, geodesics, and gauges},
  author={Bronstein, Michael M and Bruna, Joan and Cohen, Taco and Veli{\v{c}}kovi{\'c}, Petar},
  journal={arXiv preprint. arXiv:2104.13478},
  year={2021}
}

@article{balestriero2018mad,
  title={Mad max: Affine spline insights into deep learning},
  author={Balestriero, Randall and Baraniuk, Richard},
  journal={arXiv preprint. arXiv:1805.06576},
  year={2018}
}

@inproceedings{he2019rethinking,
  title={Rethinking imagenet pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle={Proc.\ Int.\ Conf.\ on Computer Vision},
  year={2019}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@inproceedings{tang-etal-2023-lemons,
    title ={When are Lemons Purple? The Concept Association Bias of Vision-Language Models},
    author = {Tang, Yingtian  and
      Yamada, Yutaro  and
      Zhang, Yoyo  and
      Yildirim, Ilker},
    booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
    year = {2023},
}

@misc{raventós2023pretrainingtaskdiversityemergence,
      title={Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression}, 
      author={Allan Raventós and Mansheej Paul and Feng Chen and Surya Ganguli},
      year={2023},
      eprint={2306.15063},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2306.15063}, 
}

@inproceedings{
rassin2023linguistic,
title={Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment},
author={Royi Rassin and Eran Hirsch and Daniel Glickman and Shauli Ravfogel and Yoav Goldberg and Gal Chechik},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=AOKU4nRw1W}
}

@inproceedings{kojima2022large,
 author = {Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Large Language Models are Zero-Shot Reasoners},
 volume = {35},
 year = {2022}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}

@article{hubinger2024sleeper,
  title={Sleeper agents: Training deceptive llms that persist through safety training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M and Maxwell, Tim and Cheng, Newton and others},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}

@inproceedings{li2022emergent,
  title={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},
  author={Li, Kenneth and Hopkins, Aspen K and Bau, David and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{
Mohan2020Robust,
title={Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks},
author={Sreyas Mohan and Zahra Kadkhodaie and Eero P. Simoncelli and Carlos Fernandez-Granda},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJlSmC4FPS}
}

@article{permenter2023interpreting,
  title={Interpreting and improving diffusion models using the euclidean distance function},
  author={Permenter, Frank and Yuan, Chenyang},
  journal={arXiv preprint arXiv:2306.04848},
  year={2023}
}

@article{somepalli2024measuring,
  title={Measuring Style Similarity in Diffusion Models},
  author={Somepalli, Gowthami and Gupta, Anubhav and Gupta, Kamal and Palta, Shramay and Goldblum, Micah and Geiping, Jonas and Shrivastava, Abhinav and Goldstein, Tom},
  journal={arXiv preprint arXiv:2404.01292},
  year={2024}
}

@inproceedings{pezzelle-2023-dealing,
    title = {Dealing with Semantic Underspecification in Multimodal NLP},
    author = {Pezzelle, Sandro},
    booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
}

@article{d2022underspecification,
  title={Underspecification presents challenges for credibility in modern machine learning},
  author={D'Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoffman, Matthew D and others},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={226},
  pages={1--61},
  year={2022}
}

@misc{park2024emergencehiddencapabilitiesexploring,
      title={Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space}, 
      author={Core Francisco Park and Maya Okawa and Andrew Lee and Ekdeep Singh Lubana and Hidenori Tanaka},
      year={2024},
      eprint={2406.19370},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.19370}, 
}

@misc{kang2024deepneuralnetworkstend,
      title={Deep Neural Networks Tend To Extrapolate Predictably}, 
      author={Katie Kang and Amrith Setlur and Claire Tomlin and Sergey Levine},
      year={2024},
      eprint={2310.00873},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.00873}, 
}

@misc{kang2024unfamiliarfinetuningexamplescontrol,
      title={Unfamiliar Finetuning Examples Control How Language Models Hallucinate}, 
      author={Katie Kang and Eric Wallace and Claire Tomlin and Aviral Kumar and Sergey Levine},
      year={2024},
      eprint={2403.05612},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.05612}, 
}

@misc{lin2024dualoperatingmodesincontext,
      title={Dual Operating Modes of In-Context Learning}, 
      author={Ziqian Lin and Kangwook Lee},
      year={2024},
      eprint={2402.18819},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.18819}, 
}

@misc{singh2023transientnatureemergentincontext,
      title={The Transient Nature of Emergent In-Context Learning in Transformers}, 
      author={Aaditya K. Singh and Stephanie C. Y. Chan and Ted Moskovitz and Erin Grant and Andrew M. Saxe and Felix Hill},
      year={2023},
      eprint={2311.08360},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.08360}, 
}

@misc{singh2024needsrightinductionhead,
      title={What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation}, 
      author={Aaditya K. Singh and Ted Moskovitz and Felix Hill and Stephanie C. Y. Chan and Andrew M. Saxe},
      year={2024},
      eprint={2404.07129},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.07129}, 
}

@misc{olsson2022incontextlearninginductionheads,
      title={In-context Learning and Induction Heads}, 
      author={Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah},
      year={2022},
      eprint={2209.11895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.11895}, 
}

@misc{reddy2023mechanisticbasisdatadependence,
      title={The mechanistic basis of data dependence and abrupt learning in an in-context classification task}, 
      author={Gautam Reddy},
      year={2023},
      eprint={2312.03002},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.03002}, 
}

@misc{wei2023largerlanguagemodelsincontext,
      title={Larger language models do in-context learning differently}, 
      author={Jerry Wei and Jason Wei and Yi Tay and Dustin Tran and Albert Webson and Yifeng Lu and Xinyun Chen and Hanxiao Liu and Da Huang and Denny Zhou and Tengyu Ma},
      year={2023},
      eprint={2303.03846},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.03846}, 
}

@misc{pan2023incontextlearninglearnsincontext,
      title={What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning}, 
      author={Jane Pan and Tianyu Gao and Howard Chen and Danqi Chen},
      year={2023},
      eprint={2305.09731},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.09731}, 
}

@article{elhage2021mathematical,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}



@misc{mckenzie2024inversescalingbiggerisnt,
      title={Inverse Scaling: When Bigger Isn't Better}, 
      author={Ian R. McKenzie and Alexander Lyzhov and Michael Pieler and Alicia Parrish and Aaron Mueller and Ameya Prabhu and Euan McLean and Aaron Kirtland and Alexis Ross and Alisa Liu and Andrew Gritsevskiy and Daniel Wurgaft and Derik Kauffman and Gabriel Recchia and Jiacheng Liu and Joe Cavanagh and Max Weiss and Sicong Huang and The Floating Droid and Tom Tseng and Tomasz Korbak and Xudong Shen and Yuhui Zhang and Zhengping Zhou and Najoung Kim and Samuel R. Bowman and Ethan Perez},
      year={2024},
      eprint={2306.09479},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.09479}, 
}

@misc{hoogland2024developmentallandscapeincontextlearning,
      title={The Developmental Landscape of In-Context Learning}, 
      author={Jesse Hoogland and George Wang and Matthew Farrugia-Roberts and Liam Carroll and Susan Wei and Daniel Murfet},
      year={2024},
      eprint={2402.02364},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.02364}, 
}

@misc{karvonen2024emergentworldmodelslatent,
      title={Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models}, 
      author={Adam Karvonen},
      year={2024},
      eprint={2403.15498},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.15498}, 
}

@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{guo2023transformerslearnincontextsimple,
      title={How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations}, 
      author={Tianyu Guo and Wei Hu and Song Mei and Huan Wang and Caiming Xiong and Silvio Savarese and Yu Bai},
      year={2023},
      eprint={2310.10616},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.10616}, 
}

@misc{garg2023transformerslearnincontextcase,
      title={What Can Transformers Learn In-Context? A Case Study of Simple Function Classes}, 
      author={Shivam Garg and Dimitris Tsipras and Percy Liang and Gregory Valiant},
      year={2023},
      eprint={2208.01066},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2208.01066}, 
}

@misc{marks2024geometrytruthemergentlinear,
      title={The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets}, 
      author={Samuel Marks and Max Tegmark},
      year={2024},
      eprint={2310.06824},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.06824}, 
}

@article{anil2024many,
  title={Many-shot jailbreaking},
  author={Anil, Cem and Durmus, Esin and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Rimsky, Nina and Tong, Meg and Mu, Jesse and Ford, Daniel and others},
  journal={Anthropic, April},
  year={2024}
}

@misc{agarwal2024manyshotincontextlearning,
      title={Many-Shot In-Context Learning}, 
      author={Rishabh Agarwal and Avi Singh and Lei M. Zhang and Bernd Bohnet and Luis Rosias and Stephanie Chan and Biao Zhang and Ankesh Anand and Zaheer Abbas and Azade Nova and John D. Co-Reyes and Eric Chu and Feryal Behbahani and Aleksandra Faust and Hugo Larochelle},
      year={2024},
      eprint={2404.11018},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.11018}, 
}

@misc{mikolov2013efficientestimationwordrepresentations,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}

@misc{engels2024languagemodelfeatureslinear,
      title={Not All Language Model Features Are Linear}, 
      author={Joshua Engels and Isaac Liao and Eric J. Michaud and Wes Gurnee and Max Tegmark},
      year={2024},
      eprint={2405.14860},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.14860}, 
}

@misc{akyürek2023learningalgorithmincontextlearning,
      title={What learning algorithm is in-context learning? Investigations with linear models}, 
      author={Ekin Akyürek and Dale Schuurmans and Jacob Andreas and Tengyu Ma and Denny Zhou},
      year={2023},
      eprint={2211.15661},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.15661}, 
}

@misc{vafa2024evaluatingworldmodelimplicit,
      title={Evaluating the World Model Implicit in a Generative Model}, 
      author={Keyon Vafa and Justin Y. Chen and Jon Kleinberg and Sendhil Mullainathan and Ashesh Rambachan},
      year={2024},
      eprint={2406.03689},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.03689}, 
}

@misc{su2023roformerenhancedtransformerrotary,
      title={RoFormer: Enhanced Transformer with Rotary Position Embedding}, 
      author={Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
      year={2023},
      eprint={2104.09864},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.09864}, 
}


@article{guyon-elisseeff-03,
  title   = "An Introduction to Variable and Feature Selection",
  author  = "I. Guyon and A. Elisseeff",
  journal = "JMLR",
  volume  = "3",
  month   = MAR,
  pages   = "1157-1182",
  year    = 2003
}

@techreport{guyon2007causalreport,
  author      = {I. Guyon and C. Aliferis and A. Elisseeff},
  title       = {Causal Feature Selection},
  institution = {Clopinet},
  year        = 2007,
  type        = {Technical Report },
  source      = {\url{http://clopinet.com/isabelle/Papers/causalFS.pdf}}
}



@misc{dubey2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and et al.},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}


@misc{park2024linearrepresentationhypothesisgeometry,
      title={The Linear Representation Hypothesis and the Geometry of Large Language Models}, 
      author={Kiho Park and Yo Joong Choe and Victor Veitch},
      year={2024},
      eprint={2311.03658},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.03658}, 
}

@misc{fiottokaufman2024nnsightndifdemocratizingaccess,
      title={NNsight and NDIF: Democratizing Access to Foundation Model Internals}, 
      author={Jaden Fiotto-Kaufman and Alexander R Loftus and Eric Todd and Jannik Brinkmann and Caden Juang and Koyena Pal and Can Rager and Aaron Mueller and Samuel Marks and Arnab Sen Sharma and Francesca Lucchetti and Michael Ripa and Adam Belfki and Nikhil Prakash and Sumeet Multani and Carla Brodley and Arjun Guha and Jonathan Bell and Byron Wallace and David Bau},
      year={2024},
      eprint={2407.14561},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.14561}, 
}

@article{arditi2024refusal,
  title={Refusal in Language Models Is Mediated by a Single Direction},
  author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
  journal={arXiv preprint arXiv:2406.11717},
  year={2024}
}

@inproceedings{lee2024mechanistic,
  title={A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity},
  author={Lee, Andrew and Bai, Xiaoyan and Pres, Itamar and Wattenberg, Martin and Kummerfeld, Jonathan K and Mihalcea, Rada},
  booktitle={Forty-first International Conference on Machine Learning},
  url={https://arxiv.org/abs/2401.01967},
  year={2024}
}

@inproceedings{nanda2023emergent,
  title={Emergent Linear Representations in World Models of Self-Supervised Sequence Models},
  author={Nanda, Neel and Lee, Andrew and Wattenberg, Martin},
  booktitle={Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP},
  pages={16--30},
  year={2023},
  url={https://arxiv.org/abs/2309.00941}
}

@article{csordas2024recurrent,
  title={Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations},
  author={Csord{\'a}s, R{\'o}bert and Potts, Christopher and Manning, Christopher D and Geiger, Atticus},
  journal={arXiv preprint arXiv:2408.10920},
  year={2024}
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{burns2022discovering,
  title={Discovering latent knowledge in language models without supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2212.03827},
  year={2022}
}

@inproceedings{
li2023inferencetime,
title={Inference-Time Intervention: Eliciting Truthful Answers from a Language Model},
author={Kenneth Li and Oam Patel and Fernanda Vi{\'e}gas and Hanspeter Pfister and Martin Wattenberg},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=aLLuYpn83y}
}

@inproceedings{rimsky-etal-2024-steering,
    title = "Steering Llama 2 via Contrastive Activation Addition",
    author = "Rimsky, Nina  and
      Gabrieli, Nick  and
      Schulz, Julian  and
      Tong, Meg  and
      Hubinger, Evan  and
      Turner, Alexander",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.828",
    doi = "10.18653/v1/2024.acl-long.828",
    pages = "15504--15522",
}

@article{park2024geometry,
  title={The Geometry of Categorical and Hierarchical Concepts in Large Language Models},
  author={Park, Kiho and Choe, Yo Joong and Jiang, Yibo and Veitch, Victor},
  journal={arXiv preprint arXiv:2406.01506},
  year={2024}
}

@article{todd2023function,
  title={Function vectors in large language models},
  author={Todd, Eric and Li, Millicent L and Sharma, Arnab Sen and Mueller, Aaron and Wallace, Byron C and Bau, David},
  journal={arXiv preprint arXiv:2310.15213},
  year={2023}
}

@inproceedings{hendel-etal-2023-context,
    title = "In-Context Learning Creates Task Vectors",
    author = "Hendel, Roee  and
      Geva, Mor  and
      Globerson, Amir",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.624",
    doi = "10.18653/v1/2023.findings-emnlp.624",
    pages = "9318--9333",
}

@article{spielman2019spectral,
  title={Spectral and algebraic graph theory},
  author={Spielman, Daniel},
  journal={Yale lecture notes, draft of December},
  volume={4},
  pages={47},
  year={2019}
}
@article{tutte1963draw,
  title={How to draw a graph},
  author={Tutte, William Thomas},
  journal={Proceedings of the London Mathematical Society},
  volume={3},
  number={1},
  pages={743--767},
  year={1963},
  publisher={Oxford University Press}
}

@article{fan1949theorem,
  title={On a theorem of Weyl concerning eigenvalues of linear transformations I},
  author={Fan, Ky},
  journal={Proceedings of the National Academy of Sciences},
  volume={35},
  number={11},
  pages={652--655},
  year={1949},
  publisher={National Acad Sciences}
}

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@inproceedings{lu-etal-2022-fantastically,
    title = "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity",
    author = "Lu, Yao  and
      Bartolo, Max  and
      Moore, Alastair  and
      Riedel, Sebastian  and
      Stenetorp, Pontus",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.556",
    doi = "10.18653/v1/2022.acl-long.556",
    pages = "8086--8098",
}

@article{li2023context,
  title={In-context learning with many demonstration examples},
  author={Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2302.04931},
  year={2023}
}


@article{olsson2022context,
  title={In-context learning and induction heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and others},
  journal={arXiv preprint arXiv:2209.11895},
  year={2022}
}

@article{chen2023sudden,
  title={Sudden drops in the loss: Syntax acquisition, phase transitions, and simplicity bias in MLMs},
  author={Chen, Angelica and Shwartz-Ziv, Ravid and Cho, Kyunghyun and Leavitt, Matthew L and Saphra, Naomi},
  journal={arXiv preprint arXiv:2309.07311},
  year={2023}
}

@article{lubana2024percolation,
  title={A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language},
  author={Lubana, Ekdeep Singh and Kawaguchi, Kyogo and Dick, Robert P and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2408.12578},
  year={2024}
}

@misc{o1,
  title={OpenAI o1: Learning to Reason with LLMs},
  url={https://openai.com/index/learning-to-reason-with-llms/},
  year={2024},
  author={OpenAI},
}

@article{yang2022transformers,
  title={Transformers from an optimization perspective},
  author={Yang, Yongyi and Wipf, David P and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36958--36971},
  year={2022}
}


@article{hazineh2023linear,
  title={Linear latent world models in simple transformers: A case study on Othello-GPT},
  author={Hazineh, Dean S and Zhang, Zechen and Chiu, Jeffery},
  journal={arXiv preprint arXiv:2310.07582},
  year={2023}
}



@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@Misc{accelerate,
  title =        {Accelerate: Training and inference at scale made simple, efficient and adaptable.},
  author =       {Sylvain Gugger and Lysandre Debut and Thomas Wolf and Philipp Schmid and Zachary Mueller and Sourab Mangrulkar and Marc Sun and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/accelerate}},
  year =         {2022}
}

@article{meng2022locating,
  title={Locating and editing factual associations in gpt},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@article{de2021editing,
  title={Editing factual knowledge in language models},
  author={De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
  journal={arXiv preprint arXiv:2104.08164},
  year={2021}
}

@misc{cohen2023evaluatingrippleeffectsknowledge,
      title={Evaluating the Ripple Effects of Knowledge Editing in Language Models}, 
      author={Roi Cohen and Eden Biran and Ori Yoran and Amir Globerson and Mor Geva},
      year={2023},
      eprint={2307.12976},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.12976}, 
}

@misc{qi2025incontexteditinglearningknowledge,
      title={In-Context Editing: Learning Knowledge from Self-Induced Distributions}, 
      author={Siyuan Qi and Bangcheng Yang and Kailin Jiang and Xiaobo Wang and Jiaqi Li and Yifan Zhong and Yaodong Yang and Zilong Zheng},
      year={2025},
      eprint={2406.11194},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11194}, 
}

@misc{kujanpää2024knowledgeinjectionpromptdistillation,
      title={Knowledge Injection via Prompt Distillation}, 
      author={Kalle Kujanpää and Harri Valpola and Alexander Ilin},
      year={2024},
      eprint={2412.14964},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.14964}, 
}

@misc{mitchell2022fastmodeleditingscale,
      title={Fast Model Editing at Scale}, 
      author={Eric Mitchell and Charles Lin and Antoine Bosselut and Chelsea Finn and Christopher D. Manning},
      year={2022},
      eprint={2110.11309},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.11309}, 
}

@misc{hase2024fundamentalproblemsmodelediting,
      title={Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?}, 
      author={Peter Hase and Thomas Hofweber and Xiang Zhou and Elias Stengel-Eskin and Mohit Bansal},
      year={2024},
      eprint={2406.19354},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19354}, 
}

@misc{zhang2024comprehensivestudyknowledgeediting,
      title={A Comprehensive Study of Knowledge Editing for Large Language Models}, 
      author={Ningyu Zhang and Yunzhi Yao and Bozhong Tian and Peng Wang and Shumin Deng and Mengru Wang and Zekun Xi and Shengyu Mao and Jintian Zhang and Yuansheng Ni and Siyuan Cheng and Ziwen Xu and Xin Xu and Jia-Chen Gu and Yong Jiang and Pengjun Xie and Fei Huang and Lei Liang and Zhiqiang Zhang and Xiaowei Zhu and Jun Zhou and Huajun Chen},
      year={2024},
      eprint={2401.01286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.01286}, 
}

@misc{huang2022incontextlearningdistillationtransferring,
      title={In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models}, 
      author={Yukun Huang and Yanda Chen and Zhou Yu and Kathleen McKeown},
      year={2022},
      eprint={2212.10670},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10670}, 
}

@misc{wang2024editingconceptualknowledgelarge,
      title={Editing Conceptual Knowledge for Large Language Models}, 
      author={Xiaohan Wang and Shengyu Mao and Ningyu Zhang and Shumin Deng and Yunzhi Yao and Yue Shen and Lei Liang and Jinjie Gu and Huajun Chen},
      year={2024},
      eprint={2403.06259},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.06259}, 
}

@misc{snell2022learningdistillingcontext,
      title={Learning by Distilling Context}, 
      author={Charlie Snell and Dan Klein and Ruiqi Zhong},
      year={2022},
      eprint={2209.15189},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.15189}, 
}

@article{yao2023editing,
  title={Editing large language models: Problems, methods, and opportunities},
  author={Yao, Yunzhi and Wang, Peng and Tian, Bozhong and Cheng, Siyuan and Li, Zhoubo and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13172},
  year={2023}
}

@article{wang2024knowledge,
  title={Knowledge mechanisms in large language models: A survey and perspective},
  author={Wang, Mengru and Yao, Yunzhi and Xu, Ziwen and Qiao, Shuofei and Deng, Shumin and Wang, Peng and Chen, Xiang and Gu, Jia-Chen and Jiang, Yong and Xie, Pengjun and others},
  journal={arXiv preprint arXiv:2407.15017},
  year={2024}
}

@inproceedings{levy-etal-2017-zero,
    title = "Zero-Shot Relation Extraction via Reading Comprehension",
    author = "Levy, Omer  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Zettlemoyer, Luke",
    editor = "Levy, Roger  and
      Specia, Lucia",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1034/",
    doi = "10.18653/v1/K17-1034",
    pages = "333--342",
    abstract = "We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task."
}

@article{onoe2023can,
  title={Can lms learn new entities from descriptions? challenges in propagating injected knowledge},
  author={Onoe, Yasumasa and Zhang, Michael JQ and Padmanabhan, Shankar and Durrett, Greg and Choi, Eunsol},
  journal={arXiv preprint arXiv:2305.01651},
  year={2023}
}

@article{DBLP:journals/corr/LebretGA16,
  author    = {R{\'{e}}mi Lebret and
               David Grangier and
               Michael Auli},
  title     = {Generating Text from Structured Data with Application to the Biography
               Domain},
  journal   = {CoRR},
  volume    = {abs/1603.07771},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.07771},
  archivePrefix = {arXiv},
  eprint    = {1603.07771},
  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LebretGA16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{burns2023weak,
  title={Weak-to-strong generalization: Eliciting strong capabilities with weak supervision},
  author={Burns, Collin and Izmailov, Pavel and Kirchner, Jan Hendrik and Baker, Bowen and Gao, Leo and Aschenbrenner, Leopold and Chen, Yining and Ecoffet, Adrien and Joglekar, Manas and Leike, Jan and others},
  journal={arXiv preprint arXiv:2312.09390},
  year={2023}
}

@article{zhong2023mquake,
  title={Mquake: Assessing knowledge editing in language models via multi-hop questions},
  author={Zhong, Zexuan and Wu, Zhengxuan and Manning, Christopher D and Potts, Christopher and Chen, Danqi},
  journal={arXiv preprint arXiv:2305.14795},
  year={2023}
}

@article{wilie2024belief,
  title={Belief Revision: The Adaptability of Large Language Models Reasoning},
  author={Wilie, Bryan and Cahyawijaya, Samuel and Ishii, Etsuko and He, Junxian and Fung, Pascale},
  journal={arXiv preprint arXiv:2406.19764},
  year={2024}
}

@article{zhu2024language,
  title={Language models represent beliefs of self and others},
  author={Zhu, Wentao and Zhang, Zhining and Wang, Yizhou},
  journal={arXiv preprint arXiv:2402.18496},
  year={2024}
}

@article{park2023linear,
  title={The linear representation hypothesis and the geometry of large language models},
  author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  journal={arXiv preprint arXiv:2311.03658},
  year={2023}
}
@article{scherrer2023evaluating,
  title={Evaluating the moral beliefs encoded in llms},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={51778--51809},
  year={2023}
}
@article{hase2021language,
  title={Do language models have beliefs? methods for detecting, updating, and visualizing model beliefs},
  author={Hase, Peter and Diab, Mona and Celikyilmaz, Asli and Li, Xian and Kozareva, Zornitsa and Stoyanov, Veselin and Bansal, Mohit and Iyer, Srinivasan},
  journal={arXiv preprint arXiv:2111.13654},
  year={2021}
}

@article{gu2023minillm,
  title={MiniLLM: Knowledge distillation of large language models},
  author={Gu, Yuxian and Dong, Li and Wei, Furu and Huang, Minlie},
  journal={arXiv preprint arXiv:2306.08543},
  year={2023}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{xu2024survey,
  title={A survey on knowledge distillation of large language models},
  author={Xu, Xiaohan and Li, Ming and Tao, Chongyang and Shen, Tao and Cheng, Reynold and Li, Jinyang and Xu, Can and Tao, Dacheng and Zhou, Tianyi},
  journal={arXiv preprint arXiv:2402.13116},
  year={2024}
}

@inproceedings{buciluǎ2006model,
  title={Model compression},
  author={Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={535--541},
  year={2006}
}

@article{ba2014deep,
  title={Do deep nets really need to be deep?},
  author={Ba, Jimmy and Caruana, Rich},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}




@inproceedings{agarwal2024policy,
  title={On-policy distillation of language models: Learning from self-generated mistakes},
  author={Agarwal, Rishabh and Vieillard, Nino and Zhou, Yongchao and Stanczyk, Piotr and Garea, Sabela Ramos and Geist, Matthieu and Bachem, Olivier},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@article{padmanabhan2023propagating,
  title={Propagating knowledge updates to lms through distillation},
  author={Padmanabhan, Shankar and Onoe, Yasumasa and Zhang, Michael and Durrett, Greg and Choi, Eunsol},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={47124--47142},
  year={2023}
}


@article{balaguer2024rag,
  title={RAG vs fine-tuning: Pipelines, tradeoffs, and a case study on agriculture},
  author={Balaguer, Angels and Benara, Vinamra and Cunha, Renato Luiz de Freitas and Hendry, Todd and Holstein, Daniel and Marsman, Jennifer and Mecklenburg, Nick and Malvar, Sara and Nunes, Leonardo O and Padilha, Rafael and others},
  journal={arXiv preprint arXiv:2401.08406},
  year={2024}
}

@article{pecher2024comparing,
  title={Comparing specialised small and general large language models on text classification: 100 labelled samples to achieve break-even performance},
  author={Pecher, Branislav and Srba, Ivan and Bielikova, Maria},
  journal={arXiv preprint arXiv:2402.12819},
  year={2024}
}

@article{sun2023pushing,
  title={Pushing the limits of chatgpt on nlp tasks},
  author={Sun, Xiaofei and Dong, Linfeng and Li, Xiaoya and Wan, Zhen and Wang, Shuhe and Zhang, Tianwei and Li, Jiwei and Cheng, Fei and Lyu, Lingjuan and Wu, Fei and others},
  journal={arXiv preprint arXiv:2306.09719},
  year={2023}
}

@article{mosbach2023few,
  title={Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation},
  author={Mosbach, Marius and Pimentel, Tiago and Ravfogel, Shauli and Klakow, Dietrich and Elazar, Yanai},
  journal={arXiv preprint arXiv:2305.16938},
  year={2023}
}

@article{ericsson1993role,
  title={The role of deliberate practice in the acquisition of expert performance.},
  author={Ericsson, K Anders and Krampe, Ralf T and Tesch-R{\"o}mer, Clemens},
  journal={Psychological review},
  volume={100},
  number={3},
  pages={363},
  year={1993},
  publisher={American Psychological Association}
}


@misc{guan2025deliberativealignmentreasoningenables,
      title={Deliberative Alignment: Reasoning Enables Safer Language Models}, 
      author={Melody Y. Guan and Manas Joglekar and Eric Wallace and Saachi Jain and Boaz Barak and Alec Helyar and Rachel Dias and Andrea Vallone and Hongyu Ren and Jason Wei and Hyung Won Chung and Sam Toyer and Johannes Heidecke and Alex Beutel and Amelia Glaese},
      year={2025},
      eprint={2412.16339},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.16339}, 
}

@misc{park2024iclrincontextlearningrepresentations,
      title={ICLR: In-Context Learning of Representations}, 
      author={Core Francisco Park and Andrew Lee and Ekdeep Singh Lubana and Yongyi Yang and Maya Okawa and Kento Nishi and Martin Wattenberg and Hidenori Tanaka},
      year={2024},
      eprint={2501.00070},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.00070}, 
}

@article{doimo2024representation,
  title={The representation landscape of few-shot learning and fine-tuning in large language models},
  author={Doimo, Diego and Serra, Alessandro and Ansuini, Alessio and Cazzaniga, Alberto},
  journal={arXiv preprint arXiv:2409.03662},
  year={2024}
}

@misc{lampinen2022languagemodelslearnexplanations,
      title={Can language models learn from explanations in context?}, 
      author={Andrew K. Lampinen and Ishita Dasgupta and Stephanie C. Y. Chan and Kory Matthewson and Michael Henry Tessler and Antonia Creswell and James L. McClelland and Jane X. Wang and Felix Hill},
      year={2022},
      eprint={2204.02329},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.02329}, 
}


@misc{geminiteam2024geminifamilyhighlycapable,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.11805}, 
}

@misc{geminiteam2024gemini15unlockingmultimodal,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.05530}, 
}

@misc{rein2023gpqagraduatelevelgoogleproofqa,
      title={GPQA: A Graduate-Level Google-Proof Q\&A Benchmark}, 
      author={David Rein and Betty Li Hou and Asa Cooper Stickland and Jackson Petty and Richard Yuanzhe Pang and Julien Dirani and Julian Michael and Samuel R. Bowman},
      year={2023},
      eprint={2311.12022},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.12022}, 
}

@misc{hendrycks2021measuringmathematicalproblemsolving,
      title={Measuring Mathematical Problem Solving With the MATH Dataset}, 
      author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2103.03874},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.03874}, 
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{pezeshkpour2023largelanguagemodelssensitivity,
      title={Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions}, 
      author={Pouya Pezeshkpour and Estevam Hruschka},
      year={2023},
      eprint={2308.11483},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.11483}, 
}


@misc{zheng2024largelanguagemodelsrobust,
      title={Large Language Models Are Not Robust Multiple Choice Selectors}, 
      author={Chujie Zheng and Hao Zhou and Fandong Meng and Jie Zhou and Minlie Huang},
      year={2024},
      eprint={2309.03882},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.03882}, 
}


@misc{openai2024openaio1card,
      title={OpenAI o1 System Card}, 
      author={OpenAI},
      year={2024},
      eprint={2412.16720},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.16720}, 
}

@article{feng2024extractive,
  title={Extractive Structures Learned in Pretraining Enable Generalization on Finetuned Facts},
  author={Feng, Jiahai and Russell, Stuart and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2412.04614},
  year={2024}
}

@article{o2014complementary,
author = {O’Reilly, Randall C. and Bhattacharyya, Rajan and Howard, Michael D. and Ketz, Nicholas},
title = {Complementary Learning Systems},
journal = {Cognitive Science},
volume = {38},
number = {6},
pages = {1229-1248},
keywords = {Hippocampus, Neocortex, Learning, Memory, Consolidation, Neural network models},
doi = {https://doi.org/10.1111/j.1551-6709.2011.01214.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1551-6709.2011.01214.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1551-6709.2011.01214.x},
abstract = {Abstract This paper reviews the fate of the central ideas behind the complementary learning systems (CLS) framework as originally articulated in McClelland, McNaughton, and O’Reilly (1995). This framework explains why the brain requires two differentially specialized learning and memory systems, and it nicely specifies their central properties (i.e., the hippocampus as a sparse, pattern-separated system for rapidly learning episodic memories, and the neocortex as a distributed, overlapping system for gradually integrating across episodes to extract latent semantic structure). We review the application of the CLS framework to a range of important topics, including the following: the basic neural processes of hippocampal memory encoding and recall, conjunctive encoding, human recognition memory, consolidation of initial hippocampal learning in cortex, dynamic modulation of encoding versus recall, and the synergistic interactions between hippocampus and neocortex. Overall, the CLS framework remains a vital theoretical force in the field, with the empirical data over the past 15 years generally confirming its key principles.},
year = {2014}
}

@article{sekeres2024update,
  title={To update or to create? The influence of novelty and prior knowledge on memory networks},
  author={Sekeres, Melanie J and Schomaker, Judith and Nadel, Lynn and Tse, Dorothy},
  journal={Philosophical Transactions B},
  volume={379},
  number={1906},
  pages={20230238},
  year={2024},
  publisher={The Royal Society}
}

@article{wamsley2011memory,
  title={Memory, sleep and dreaming: experiencing consolidation},
  author={Wamsley, Erin J and Stickgold, Robert},
  journal={Sleep medicine clinics},
  volume={6},
  number={1},
  pages={97},
  year={2011}
}

@article{diekelmann2010memory,
  title={The memory function of sleep},
  author={Diekelmann, Susanne and Born, Jan},
  journal={Nature reviews neuroscience},
  volume={11},
  number={2},
  pages={114--126},
  year={2010},
  publisher={Nature Publishing Group UK London}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@inproceedings{kandpal2023large,
  title={Large language models struggle to learn long-tail knowledge},
  author={Kandpal, Nikhil and Deng, Haikang and Roberts, Adam and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={15696--15707},
  year={2023},
  organization={PMLR}
}

@article{craik1972levels,
  title={Levels of processing: A framework for memory research},
  author={Craik, Fergus IM and Lockhart, Robert S},
  journal={Journal of verbal learning and verbal behavior},
  volume={11},
  number={6},
  pages={671--684},
  year={1972},
  publisher={Elsevier}
}

@article{chi1994eliciting,
  title={Eliciting self-explanations improves understanding},
  author={Chi, Michelene TH and De Leeuw, Nicholas and Chiu, Mei-Hung and LaVancher, Christian},
  journal={Cognitive science},
  volume={18},
  number={3},
  pages={439--477},
  year={1994},
  publisher={Elsevier}
}

@article{slamecka1978generation,
  title={The generation effect: Delineation of a phenomenon.},
  author={Slamecka, Norman J and Graf, Peter},
  journal={Journal of experimental Psychology: Human learning and Memory},
  volume={4},
  number={6},
  pages={592},
  year={1978},
  publisher={American Psychological Association}
}

@article{mcclelland1995there,
  title={Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.},
  author={McClelland, James L and McNaughton, Bruce L and O'Reilly, Randall C},
  journal={Psychological review},
  volume={102},
  number={3},
  pages={419},
  year={1995},
  publisher={American Psychological Association}
}

@article{wilson1994reactivation,
  title={Reactivation of hippocampal ensemble memories during sleep},
  author={Wilson, Matthew A and McNaughton, Bruce L},
  journal={Science},
  volume={265},
  number={5172},
  pages={676--679},
  year={1994},
  publisher={American Association for the Advancement of Science}
}

@article{tse2007schemas,
  title={Schemas and memory consolidation},
  author={Tse, Dorothy and Langston, Rosamund F and Kakeyama, Masaki and Bethus, Ingrid and Spooner, Patrick A and Wood, Emma R and Witter, Menno P and Morris, Richard GM},
  journal={Science},
  volume={316},
  number={5821},
  pages={76--82},
  year={2007},
  publisher={American Association for the Advancement of Science}
}

@article{van2012theoretical,
  title={Theoretical model: Schemas, coping styles, and modes},
  author={Van Genderen, Hannie and Rijkeboer, Marleen and Arntz, Arnoud},
  journal={The Wiley-Blackwell handbook of schema therapy: Theory, research, and practice},
  pages={27--40},
  year={2012},
  publisher={Wiley Online Library}
}

@article{wang2024self,
  title={Self-Updatable Large Language Models with Parameter Integration},
  author={Wang, Yu and Liu, Xinshuang and Chen, Xiusi and O'Brien, Sean and Wu, Junda and McAuley, Julian},
  journal={arXiv preprint arXiv:2410.00487},
  year={2024}
}
@article{kujanpaa2024knowledge,
  title={Knowledge injection via prompt distillation},
  author={Kujanp{\"a}{\"a}, Kalle and Valpola, Harri and Ilin, Alexander},
  journal={arXiv preprint arXiv:2412.14964},
  year={2024}
}

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
}

@article{hubel1962receptive,
  title={Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
  author={Hubel, David H and Wiesel, Torsten N},
  journal={The Journal of physiology},
  volume={160},
  number={1},
  pages={106},
  year={1962}
}


@article{rosenblatt1958perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}


@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{fukushima1980neocognitron,
  title={Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Fukushima, Kunihiko},
  journal={Biological cybernetics},
  volume={36},
  number={4},
  pages={193--202},
  year={1980},
  publisher={Springer}
}
