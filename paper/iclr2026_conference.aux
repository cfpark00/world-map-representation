\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{hubel1962receptive,rosenblatt1958perceptron,fukushima1980neocognitron,rumelhart1986learning}
\citation{bengio2014representationlearningreviewnew}
\citation{li2022emergent,gurnee2023language,nanda2023emergent}
\citation{huh2024platonicrepresentationhypothesis}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {paragraph}{This work.}{1}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Overview of the World-Data-Model framework.} \textbf  {Top:} The world consists of 5,075 real city coordinates; we test adaptation by adding 100 synthetic \texttt  {Atlantis} cities (App.\nobreakspace  {}\ref  {app:world}). \textbf  {Middle:} Seven geometric tasks generate training data from city coordinates (App.\nobreakspace  {}\ref  {app:data}). \textbf  {Bottom:} Training dynamics of one model, showing loss curves, linear probing accuracy for coordinate reconstruction, and visualizations of internal representations (PCA and linear probe projections) at different training stages. See App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_training} for all training curves.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fig1}{{1}{2}{\textbf {Overview of the World-Data-Model framework.} \textbf {Top:} The world consists of 5,075 real city coordinates; we test adaptation by adding 100 synthetic \texttt {Atlantis} cities (App.~\ref {app:world}). \textbf {Middle:} Seven geometric tasks generate training data from city coordinates (App.~\ref {app:data}). \textbf {Bottom:} Training dynamics of one model, showing loss curves, linear probing accuracy for coordinate reconstruction, and visualizations of internal representations (PCA and linear probe projections) at different training stages. See App.~Fig.~\ref {fig:app_training} for all training curves.\relax }{figure.caption.1}{}}
\citation{rosenblatt1958perceptron,rumelhart1986learning}
\citation{li2022emergent,gurnee2023language,nanda2023emergent,marks2024geometrytruthemergentlinear}
\citation{towardsmonosemanticity,templeton2024scaling}
\citation{huh2024platonicrepresentationhypothesis}
\citation{kumar2025questioningrepresentationaloptimismdeep}
\citation{krizhevsky2012imagenet,he2015deep}
\citation{devlin2018bert,radford2018improving}
\citation{berglund2024reversalcursellmstrained,lampinen2025generalizationlanguagemodelsincontext}
\citation{jain2023mechanistically,ward2025reasoningfinetuningrepurposeslatentrepresentations,yue2025doesreinforcementlearningreally,qin2025decomposingelementsproblemsolving}
\citation{kumar2022finetuningdistortpretrainedfeatures}
\citation{caruana1997multitask}
\citation{aghajanyan2021muppetmassivemultitaskrepresentations}
\citation{michaud2023quantization,zhang2025intelligenceedgechaos}
\citation{xie2021explanation,chan2022datadistributionalpropertiesdrive,reddy2023mechanisticbasisdatadependence,raventós2023pretrainingtaskdiversityemergence,park2024competition,wurgaft2025incontextlearningstrategiesemerge}
\citation{okawa2024compositional,park2024emergencehiddencapabilitiesexploring}
\citation{allen2023physics1,allen2023physics}
\citation{menon2025analyzinginabilitiessaesformal,hindupur2025projectingassumptionsdualitysparse}
\citation{jain2023mechanistically}
\citation{nishi2024representation}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}}
\newlabel{sec:related}{{2}{3}{Related Work}{section.2}{}}
\citation{nanda2023progressmeasuresgrokkingmechanistic}
\citation{achille2019criticallearningperiodsdeep}
\citation{dohare2024maintainingplasticitydeepcontinual}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Framework: Decoupling World, Data, and Model}{4}{section.3}}
\newlabel{sec:setup}{{3}{4}{Experimental Framework: Decoupling World, Data, and Model}{section.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Framework.}{4}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Instantiation.}{4}{section*.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}World Representations Converge Under Multi-Task Learning}{4}{section.4}}
\newlabel{sec:pretraining}{{4}{4}{World Representations Converge Under Multi-Task Learning}{section.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Result 1: World Representations Emerge through Autoregressive Training}{4}{section*.5}}
\citation{kornblithcka}
\citation{pezeshki2021gradient,shah2020pitfallssimplicitybiasneural,hoffmann2024eurekamomentstransformersmultisteptasks,bachmann2025pitfallsnexttokenprediction,gopalani2025happenslossplateauunderstanding}
\citation{huh2024platonicrepresentationhypothesis}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {World representation geometry depends on the data generation process.} (a) Different tasks create distinct geometries: \texttt  {distance} (thread-like), \texttt  {angle} (2D manifold), \texttt  {compass} (fragmented), \texttt  {inside} (diffuse). Row 1: PCA. Row 2: Linear probe projections. Row 3: Rotated views showing hidden structure. See App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_reprs} for more seeds. (b) CKA matrix at layer 5, estimated across 3 seeds. \texttt  {Crossing} (Cr) fails to train alone. See App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_cka_pt1} for SEM and layers 3, 4, 6.\relax }}{5}{figure.caption.7}}
\newlabel{fig:result1-1}{{2}{5}{\textbf {World representation geometry depends on the data generation process.} (a) Different tasks create distinct geometries: \texttt {distance} (thread-like), \texttt {angle} (2D manifold), \texttt {compass} (fragmented), \texttt {inside} (diffuse). Row 1: PCA. Row 2: Linear probe projections. Row 3: Rotated views showing hidden structure. See App.~Fig.~\ref {fig:app_reprs} for more seeds. (b) CKA matrix at layer 5, estimated across 3 seeds. \texttt {Crossing} (Cr) fails to train alone. See App.~Fig.~\ref {fig:app_cka_pt1} for SEM and layers 3, 4, 6.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Result 2: Data Generation Process Controls World Representation Geometry}{5}{figure.caption.7}}
\@writefile{toc}{\contentsline {paragraph}{Result 3: Multi-Task Learning Drives Representational Convergence}{5}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Multi-task pretraining drives representational convergence.} (a,b) Two-task training creates more regular structures than single-task models. (c) CKA matrix (7$\times $7) for two-task models shows higher alignment (see App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_cka_pt2} for SEM). (d) Average CKA increases with task count (1$\rightarrow $2$\rightarrow $3), saturating at $\sim $0.85 for layers 4-6 while layer 3 continues improving (see App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_cka_3seed} for SEM). \texttt  {Crossing}, which failed to learn in single-task training, is excluded; including it would only strengthen the convergence finding. 3D visualizations: \href  {https://osf.io/4huk3/?view_only=8ddee09b18ed43b0a302b96f6bfecd50}{link}.\relax }}{6}{figure.caption.9}}
\newlabel{fig:result1-2}{{3}{6}{\textbf {Multi-task pretraining drives representational convergence.} (a,b) Two-task training creates more regular structures than single-task models. (c) CKA matrix (7$\times $7) for two-task models shows higher alignment (see App.~Fig.~\ref {fig:app_cka_pt2} for SEM). (d) Average CKA increases with task count (1$\rightarrow $2$\rightarrow $3), saturating at $\sim $0.85 for layers 4-6 while layer 3 continues improving (see App.~Fig.~\ref {fig:app_cka_3seed} for SEM). \texttt {Crossing}, which failed to learn in single-task training, is excluded; including it would only strengthen the convergence finding. 3D visualizations: \href {https://osf.io/4huk3/?view_only=8ddee09b18ed43b0a302b96f6bfecd50}{link}.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {7-task model.} (a) PCA projection of layer 5 representations naturally reveals world map structure. (b) Training curves showing successful learning of all 7 tasks, including \texttt  {crossing} which failed in single-task training.\relax }}{6}{figure.caption.10}}
\newlabel{fig:7taskmodel}{{4}{6}{\textbf {7-task model.} (a) PCA projection of layer 5 representations naturally reveals world map structure. (b) Training curves showing successful learning of all 7 tasks, including \texttt {crossing} which failed in single-task training.\relax }{figure.caption.10}{}}
\citation{kumar2025questioningrepresentationaloptimismdeep}
\citation{kumar2022finetuningdistortpretrainedfeatures}
\@writefile{toc}{\contentsline {section}{\numberline {5}Divergent Tasks Harm Entity Integration via Fine-Tuning}{7}{section.5}}
\newlabel{sec:fine_tuning}{{5}{7}{Divergent Tasks Harm Entity Integration via Fine-Tuning}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Fine-tuning generalization and its correlation with representational similarity.} (a) Generalization matrix (averaged over 4 seeds; see App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_ft_vs_ni_4seed} for individual seeds): each row is a model that integrated \texttt  {Atlantis} via one task; columns show normalized improvement on \texttt  {Atlantis} queries for each task (see App.\nobreakspace  {}\ref  {app:eval} for metric details). (b) For each task pair (X, Y), we plot the single-task CKA between X and Y against the normalized improvement on task Y after fine-tuning on task X (see App.\nobreakspace  {}Fig.\nobreakspace  {}\ref  {fig:app_cka_vs_ni_annotated} for annotated version).\relax }}{7}{figure.caption.12}}
\newlabel{fig:result2-1}{{5}{7}{\textbf {Fine-tuning generalization and its correlation with representational similarity.} (a) Generalization matrix (averaged over 4 seeds; see App.~Fig.~\ref {fig:app_ft_vs_ni_4seed} for individual seeds): each row is a model that integrated \texttt {Atlantis} via one task; columns show normalized improvement on \texttt {Atlantis} queries for each task (see App.~\ref {app:eval} for metric details). (b) For each task pair (X, Y), we plot the single-task CKA between X and Y against the normalized improvement on task Y after fine-tuning on task X (see App.~Fig.~\ref {fig:app_cka_vs_ni_annotated} for annotated version).\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Result 1: Pretraining Phase Representational Alignment Predicts Fine-Tuning Generalization \textit  {Despite} Joint Pretraining}{7}{figure.caption.12}}
\citation{mccloskey1989catastrophic}
\@writefile{toc}{\contentsline {paragraph}{Result 2: Divergent Tasks Catastrophically Harm Generalization}{8}{section*.13}}
\@writefile{toc}{\contentsline {paragraph}{Result 3: Divergent Tasks Disrupt Representational Integration of New Entities}{8}{section*.14}}
\citation{brown2020language}
\citation{demircan2024sparseautoencodersrevealtemporal}
\citation{lampinen2025generalizationlanguagemodelsincontext,park2025textitnewnewssystem2finetuning}
\citation{chen2024generativeadaptercontextualizinglanguage,charakorn2025texttolorainstanttransformeradaption,zweiger2025selfadaptinglanguagemodels}
\citation{hochreiter1997long,schlag2021lineartransformerssecretlyfast,behrouz2024titanslearningmemorizetest,yang2025gateddeltanetworksimproving}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Divergent tasks harm multi-task fine-tuning and disrupt representational integration.} (a) Deviation from best-teacher expectation for 21 two-task models (rows) across 7 evaluation tasks (columns), computed in normalized improvement space (see App.\nobreakspace  {}\ref  {app:eval}); ``red horizontal bands'' show \texttt  {distance} task combinations degrade performance below single-task baselines. (b) Representation visualization and linear probe reconstruction of \texttt  {Atlantis}. (c) Histogram of deviation values: models including \texttt  {distance} vs. not. (d) Linear probe \texttt  {Atlantis} coordinate reconstruction error for models with \texttt  {distance}, without \texttt  {distance}, and baseline on pretraining cities; green vertical line indicates performance when \texttt  {Atlantis} is part of pretraining.\relax }}{9}{figure.caption.15}}
\newlabel{fig:result2-2}{{6}{9}{\textbf {Divergent tasks harm multi-task fine-tuning and disrupt representational integration.} (a) Deviation from best-teacher expectation for 21 two-task models (rows) across 7 evaluation tasks (columns), computed in normalized improvement space (see App.~\ref {app:eval}); ``red horizontal bands'' show \texttt {distance} task combinations degrade performance below single-task baselines. (b) Representation visualization and linear probe reconstruction of \texttt {Atlantis}. (c) Histogram of deviation values: models including \texttt {distance} vs. not. (d) Linear probe \texttt {Atlantis} coordinate reconstruction error for models with \texttt {distance}, without \texttt {distance}, and baseline on pretraining cities; green vertical line indicates performance when \texttt {Atlantis} is part of pretraining.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{9}{section.6}}
\newlabel{sec:discussion}{{6}{9}{Discussion}{section.6}{}}
\citation{rosenblatt1958perceptron,rumelhart1986learning}
\citation{park2024iclrincontextlearningrepresentations}
\citation{shai2025transformersrepresentbeliefstate}
\citation{bigelow2025beliefdynamicsrevealdual,lubana2025priorstimemissinginductive}
\citation{wang2025simplemechanisticexplanationsoutofcontext}
\citation{casademunt2025steeringoutofdistributiongeneralizationconcept,minder2025overcomingsparsityartifactscrosscoders}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{10}{section.7}}
\bibdata{iclr2026_conference}
\bibcite{achille2019criticallearningperiodsdeep}{{1}{2019}{{Achille et~al.}}{{Achille, Rovere, and Soatto}}}
\bibcite{aghajanyan2021muppetmassivemultitaskrepresentations}{{2}{2021}{{Aghajanyan et~al.}}{{Aghajanyan, Gupta, Shrivastava, Chen, Zettlemoyer, and Gupta}}}
\bibcite{allen2023physics}{{3}{2023{a}}{{Allen-Zhu \& Li}}{{Allen-Zhu and Li}}}
\bibcite{allen2023physics1}{{4}{2023{b}}{{Allen-Zhu \& Li}}{{Allen-Zhu and Li}}}
\bibcite{towardsmonosemanticity}{{5}{2023}{{Anthropic AI}}{{}}}
\bibcite{arditi2024refusal}{{6}{2024}{{Arditi et~al.}}{{Arditi, Obeso, Syed, Paleka, Panickssery, Gurnee, and Nanda}}}
\bibcite{bachmann2025pitfallsnexttokenprediction}{{7}{2025}{{Bachmann \& Nagarajan}}{{Bachmann and Nagarajan}}}
\bibcite{behrouz2024titanslearningmemorizetest}{{8}{2024}{{Behrouz et~al.}}{{Behrouz, Zhong, and Mirrokni}}}
\bibcite{bengio2014representationlearningreviewnew}{{9}{2014}{{Bengio et~al.}}{{Bengio, Courville, and Vincent}}}
\bibcite{berglund2024reversalcursellmstrained}{{10}{2024}{{Berglund et~al.}}{{Berglund, Tong, Kaufmann, Balesni, Stickland, Korbak, and Evans}}}
\bibcite{betley2025emergentmisalignmentnarrowfinetuning}{{11}{2025}{{Betley et~al.}}{{Betley, Tan, Warncke, Sztyber-Betley, Bao, Soto, Labenz, and Evans}}}
\bibcite{bigelow2025beliefdynamicsrevealdual}{{12}{2025}{{Bigelow et~al.}}{{Bigelow, Wurgaft, Wang, Goodman, Ullman, Tanaka, and Lubana}}}
\bibcite{bronstein2021geometricdeeplearninggrids}{{13}{2021}{{Bronstein et~al.}}{{Bronstein, Bruna, Cohen, and Veličković}}}
\bibcite{brown2020language}{{14}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.}}}
\bibcite{caruana1997multitask}{{15}{1997}{{Caruana}}{{}}}
\bibcite{casademunt2025steeringoutofdistributiongeneralizationconcept}{{16}{2025}{{Casademunt et~al.}}{{Casademunt, Juang, Karvonen, Marks, Rajamanoharan, and Nanda}}}
\bibcite{chan2022datadistributionalpropertiesdrive}{{17}{2022}{{Chan et~al.}}{{Chan, Santoro, Lampinen, Wang, Singh, Richemond, McClelland, and Hill}}}
\bibcite{charakorn2025texttolorainstanttransformeradaption}{{18}{2025}{{Charakorn et~al.}}{{Charakorn, Cetin, Tang, and Lange}}}
\bibcite{chen2024generativeadaptercontextualizinglanguage}{{19}{2024}{{Chen et~al.}}{{Chen, Fang, Xia, Liu, Durme, Zettlemoyer, Gao, and Cheng}}}
\bibcite{cohen2016groupequivariantconvolutionalnetworks}{{20}{2016}{{Cohen \& Welling}}{{Cohen and Welling}}}
\bibcite{csordas2024recurrent}{{21}{2024}{{Csord{\'a}s et~al.}}{{Csord{\'a}s, Potts, Manning, and Geiger}}}
\bibcite{demircan2024sparseautoencodersrevealtemporal}{{22}{2024}{{Demircan et~al.}}{{Demircan, Saanum, Jagadish, Binz, and Schulz}}}
\bibcite{devlin2018bert}{{23}{2018}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\bibcite{dohare2024maintainingplasticitydeepcontinual}{{24}{2024}{{Dohare et~al.}}{{Dohare, Hernandez-Garcia, Rahman, Mahmood, and Sutton}}}
\bibcite{engels2024languagemodelfeatureslinear}{{25}{2024}{{Engels et~al.}}{{Engels, Liao, Michaud, Gurnee, and Tegmark}}}
\bibcite{fu2025hiddenplainsightvlms}{{26}{2025}{{Fu et~al.}}{{Fu, Bonnen, Guillory, and Darrell}}}
\bibcite{fukushima1980neocognitron}{{27}{1980}{{Fukushima}}{{}}}
\bibcite{ge2025evolutionconceptslanguagemodel}{{28}{2025}{{Ge et~al.}}{{Ge, Shu, Wu, Zhou, He, and Qiu}}}
\bibcite{gopalani2025happenslossplateauunderstanding}{{29}{2025}{{Gopalani \& Hu}}{{Gopalani and Hu}}}
\bibcite{gurnee2023language}{{30}{2023}{{Gurnee \& Tegmark}}{{Gurnee and Tegmark}}}
\bibcite{he2015deep}{{31}{2015}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{higgins2016beta}{{32}{2017}{{Higgins et~al.}}{{Higgins, Matthey, Pal, Burgess, Glorot, Botvinick, Mohamed, and Lerchner}}}
\bibcite{hindupur2025projectingassumptionsdualitysparse}{{33}{2025}{{Hindupur et~al.}}{{Hindupur, Lubana, Fel, and Ba}}}
\bibcite{hochreiter1997long}{{34}{1997}{{Hochreiter \& Schmidhuber}}{{Hochreiter and Schmidhuber}}}
\bibcite{hoffmann2024eurekamomentstransformersmultisteptasks}{{35}{2024}{{Hoffmann et~al.}}{{Hoffmann, Schrodi, Bratulić, Behrmann, Fischer, and Brox}}}
\bibcite{hu2021loralowrankadaptationlarge}{{36}{2021}{{Hu et~al.}}{{Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen}}}
\bibcite{hubel1962receptive}{{37}{1962}{{Hubel \& Wiesel}}{{Hubel and Wiesel}}}
\bibcite{huh2024platonicrepresentationhypothesis}{{38}{2024}{{Huh et~al.}}{{Huh, Cheung, Wang, and Isola}}}
\bibcite{ilharco2023editingmodelstaskarithmetic}{{39}{2023}{{Ilharco et~al.}}{{Ilharco, Ribeiro, Wortsman, Gururangan, Schmidt, Hajishirzi, and Farhadi}}}
\bibcite{jain2023mechanistically}{{40}{2023}{{Jain et~al.}}{{Jain, Kirk, Lubana, Dick, Tanaka, Grefenstette, Rockt{\"a}schel, and Krueger}}}
\bibcite{kim2025taskdiversityshortensicl}{{41}{2025}{{Kim et~al.}}{{Kim, Kwon, Choi, Park, Cho, Lee, and Ryu}}}
\bibcite{kornblithcka}{{42}{2019}{{Kornblith et~al.}}{{Kornblith, Norouzi, Lee, and Hinton}}}
\bibcite{krizhevsky2012imagenet}{{43}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{kumar2025questioningrepresentationaloptimismdeep}{{44}{2025}{{Kumar et~al.}}{{Kumar, Clune, Lehman, and Stanley}}}
\bibcite{kumar2022finetuningdistortpretrainedfeatures}{{45}{2022}{{Kumar et~al.}}{{Kumar, Raghunathan, Jones, Ma, and Liang}}}
\bibcite{lampinen2025generalizationlanguagemodelsincontext}{{46}{2025}{{Lampinen et~al.}}{{Lampinen, Chaudhry, Chan, Wild, Wan, Ku, Bornschein, Pascanu, Shanahan, and McClelland}}}
\bibcite{lee2024mechanistic}{{47}{2024}{{Lee et~al.}}{{Lee, Bai, Pres, Wattenberg, Kummerfeld, and Mihalcea}}}
\bibcite{lee2025geometryselfverificationtaskspecificreasoning}{{48}{2025}{{Lee et~al.}}{{Lee, Sun, Wendler, Viégas, and Wattenberg}}}
\bibcite{lester2021powerscaleparameterefficientprompt}{{49}{2021}{{Lester et~al.}}{{Lester, Al-Rfou, and Constant}}}
\bibcite{li2022emergent}{{50}{2022}{{Li et~al.}}{{Li, Hopkins, Bau, Vi{\'e}gas, Pfister, and Wattenberg}}}
\bibcite{li2025tracing}{{51}{2025}{{Li et~al.}}{{Li, Agrawal, Ghosh, Teru, Lajoie, and Richards}}}
\bibcite{loshchilov2019decoupled}{{52}{2019}{{Loshchilov \& Hutter}}{{Loshchilov and Hutter}}}
\bibcite{lubana2025priorstimemissinginductive}{{53}{2025}{{Lubana et~al.}}{{Lubana, Rager, Hindupur, Costa, Tuckute, Patel, Murthy, Fel, Wurgaft, Bigelow, Lin, Ba, Wattenberg, Viegas, Weber, and Mueller}}}
\bibcite{malladi2024finetuninglanguagemodelsjust}{{54}{2024}{{Malladi et~al.}}{{Malladi, Gao, Nichani, Damian, Lee, Chen, and Arora}}}
\bibcite{marks2024geometrytruthemergentlinear}{{55}{2024}{{Marks \& Tegmark}}{{Marks and Tegmark}}}
\bibcite{mccloskey1989catastrophic}{{56}{1989}{{McCloskey \& Cohen}}{{McCloskey and Cohen}}}
\bibcite{menon2025analyzinginabilitiessaesformal}{{57}{2025}{{Menon et~al.}}{{Menon, Shrivastava, Krueger, and Lubana}}}
\bibcite{michaud2023quantization}{{58}{2023}{{Michaud et~al.}}{{Michaud, Liu, Girit, and Tegmark}}}
\bibcite{minder2025overcomingsparsityartifactscrosscoders}{{59}{2025}{{Minder et~al.}}{{Minder, Dumas, Juang, Chugtai, and Nanda}}}
\bibcite{mircea2025trainingdynamicsunderlyinglanguage}{{60}{2025}{{Mircea et~al.}}{{Mircea, Chakraborty, Chitsazan, Naphade, Sahu, Rish, and Lobacheva}}}
\bibcite{nanda2023progressmeasuresgrokkingmechanistic}{{61}{2023{a}}{{Nanda et~al.}}{{Nanda, Chan, Lieberum, Smith, and Steinhardt}}}
\bibcite{nanda2023emergent}{{62}{2023{b}}{{Nanda et~al.}}{{Nanda, Lee, and Wattenberg}}}
\bibcite{nishi2024representation}{{63}{2024}{{Nishi et~al.}}{{Nishi, Okawa, Ramesh, Khona, Lubana, and Tanaka}}}
\bibcite{okawa2024compositional}{{64}{2024}{{Okawa et~al.}}{{Okawa, Lubana, Dick, and Tanaka}}}
\bibcite{olah2017feature}{{65}{2017}{{Olah et~al.}}{{Olah, Mordvintsev, and Schubert}}}
\bibcite{geonames_all_cities_1000}{{66}{2025}{{OpenDataSoft / GeoNames}}{{}}}
\bibcite{park2024iclrincontextlearningrepresentations}{{67}{2024{a}}{{Park et~al.}}{{Park, Lee, Lubana, Yang, Okawa, Nishi, Wattenberg, and Tanaka}}}
\bibcite{park2024competition}{{68}{2024{b}}{{Park et~al.}}{{Park, Lubana, Pres, and Tanaka}}}
\bibcite{park2024emergencehiddencapabilitiesexploring}{{69}{2024{c}}{{Park et~al.}}{{Park, Okawa, Lee, Lubana, and Tanaka}}}
\bibcite{park2025textitnewnewssystem2finetuning}{{70}{2025}{{Park et~al.}}{{Park, Zhang, and Tanaka}}}
\bibcite{pearce2025tree}{{71}{2025}{{Pearce et~al.}}{{Pearce, Simon, Byun, and Balsam}}}
\bibcite{pezeshki2021gradient}{{72}{2021}{{Pezeshki et~al.}}{{Pezeshki, Kaba, Bengio, Courville, Precup, and Lajoie}}}
\bibcite{qin2025decomposingelementsproblemsolving}{{73}{2025}{{Qin et~al.}}{{Qin, Park, Kwun, Walsman, Malach, Anand, Tanaka, and Alvarez-Melis}}}
\bibcite{radford2018improving}{{74}{2018}{{Radford et~al.}}{{Radford, Narasimhan, Salimans, Sutskever, et~al.}}}
\bibcite{raventós2023pretrainingtaskdiversityemergence}{{75}{2023}{{Raventós et~al.}}{{Raventós, Paul, Chen, and Ganguli}}}
\bibcite{reddy2023mechanisticbasisdatadependence}{{76}{2023}{{Reddy}}{{}}}
\bibcite{rosenblatt1958perceptron}{{77}{1958}{{Rosenblatt}}{{}}}
\bibcite{rumelhart1986learning}{{78}{1986}{{Rumelhart et~al.}}{{Rumelhart, Hinton, and Williams}}}
\bibcite{schlag2021lineartransformerssecretlyfast}{{79}{2021}{{Schlag et~al.}}{{Schlag, Irie, and Schmidhuber}}}
\bibcite{shah2020pitfallssimplicitybiasneural}{{80}{2020}{{Shah et~al.}}{{Shah, Tamuly, Raghunathan, Jain, and Netrapalli}}}
\bibcite{shai2025transformersrepresentbeliefstate}{{81}{2025}{{Shai et~al.}}{{Shai, Marzen, Teixeira, Oldenziel, and Riechers}}}
\bibcite{singh2024needsrightinductionhead}{{82}{2024}{{Singh et~al.}}{{Singh, Moskovitz, Hill, Chan, and Saxe}}}
\bibcite{templeton2024scaling}{{83}{2024}{{Templeton et~al.}}{{Templeton, Conerly, Marcus, Lindsey, Bricken, Chen, Pearce, Citro, Ameisen, Jones, Cunningham, Turner, McDougall, MacDiarmid, Freeman, Sumers, Rees, Batson, Jermyn, Carter, Olah, and Henighan}}}
\bibcite{treutlein2024connectingdotsllmsinfer}{{84}{2024}{{Treutlein et~al.}}{{Treutlein, Choi, Betley, Marks, Anil, Grosse, and Evans}}}
\bibcite{vafa2025foundationmodelfoundusing}{{85}{2025}{{Vafa et~al.}}{{Vafa, Chang, Rambachan, and Mullainathan}}}
\bibcite{wang2025simplemechanisticexplanationsoutofcontext}{{86}{2025}{{Wang et~al.}}{{Wang, Engels, Clive-Griffin, Rajamanoharan, and Nanda}}}
\bibcite{ward2025reasoningfinetuningrepurposeslatentrepresentations}{{87}{2025}{{Ward et~al.}}{{Ward, Lin, Venhoff, and Nanda}}}
\bibcite{weiler2021generale2equivariantsteerablecnns}{{88}{2021}{{Weiler \& Cesa}}{{Weiler and Cesa}}}
\bibcite{wu2024reftrepresentationfinetuninglanguage}{{89}{2024}{{Wu et~al.}}{{Wu, Arora, Wang, Geiger, Jurafsky, Manning, and Potts}}}
\bibcite{wurgaft2025incontextlearningstrategiesemerge}{{90}{2025}{{Wurgaft et~al.}}{{Wurgaft, Lubana, Park, Tanaka, Reddy, and Goodman}}}
\bibcite{xie2021explanation}{{91}{2021}{{Xie et~al.}}{{Xie, Raghunathan, Liang, and Ma}}}
\bibcite{yang2024qwen2}{{92}{2024}{{Yang et~al.}}{{Yang, Yang, Zhang, Hui, Zheng, Yu, Li, Liu, Huang, Wei, et~al.}}}
\bibcite{yang2025gateddeltanetworksimproving}{{93}{2025}{{Yang et~al.}}{{Yang, Kautz, and Hatamizadeh}}}
\bibcite{yue2025doesreinforcementlearningreally}{{94}{2025}{{Yue et~al.}}{{Yue, Chen, Lu, Zhao, Wang, Yue, Song, and Huang}}}
\bibcite{zhang2025intelligenceedgechaos}{{95}{2025}{{Zhang et~al.}}{{Zhang, Patel, Rizvi, Liu, He, Karbasi, Zappala, and van Dijk}}}
\bibcite{zhao2025echochamberrlposttraining}{{96}{2025}{{Zhao et~al.}}{{Zhao, Meterez, Kakade, Pehlevan, Jelassi, and Malach}}}
\bibcite{zweiger2025selfadaptinglanguagemodels}{{97}{2025}{{Zweiger et~al.}}{{Zweiger, Pari, Guo, Akyürek, Kim, and Agrawal}}}
\bibstyle{iclr2026_conference}
\citation{geonames_all_cities_1000}
\citation{engels2024languagemodelfeatureslinear,csordas2024recurrent}
\citation{bronstein2021geometricdeeplearninggrids}
\@writefile{toc}{\contentsline {section}{\numberline {A}3D Visualizations}{17}{appendix.A}}
\newlabel{app:vis}{{A}{17}{3D Visualizations}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Experimental Details}{17}{appendix.B}}
\newlabel{app:experimental_details}{{B}{17}{Experimental Details}{appendix.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}World}{17}{subsection.B.1}}
\newlabel{app:world}{{B.1}{17}{World}{subsection.B.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Geographic distribution of cities used in our experiments.} 5,075 real-world cities plus 100 synthetic \texttt  {Atlantis} cities (5,175 total). Cities span all continents and provide a fixed, measurable world structure. Coordinates use an equirectangular projection: $x = 10 \times \text  {longitude}$, $y = 10 \times \text  {latitude}$ (in degrees). The \texttt  {Atlantis} region (Atlantic Ocean) is used for out-of-distribution testing.\relax }}{17}{figure.caption.19}}
\newlabel{fig:cities_map}{{7}{17}{\textbf {Geographic distribution of cities used in our experiments.} 5,075 real-world cities plus 100 synthetic \texttt {Atlantis} cities (5,175 total). Cities span all continents and provide a fixed, measurable world structure. Coordinates use an equirectangular projection: $x = 10 \times \text {longitude}$, $y = 10 \times \text {latitude}$ (in degrees). The \texttt {Atlantis} region (Atlantic Ocean) is used for out-of-distribution testing.\relax }{figure.caption.19}{}}
\citation{berglund2024reversalcursellmstrained}
\citation{bachmann2025pitfallsnexttokenprediction}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Data Generation Process}{18}{subsection.B.2}}
\newlabel{app:data}{{B.2}{18}{Data Generation Process}{subsection.B.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Tasks}{18}{section*.20}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of 7 geometric tasks. Numerical outputs are integers; ``scaled coords'' refers to the $\times 10$ coordinate system (Sec.\nobreakspace  {}\ref  {app:world}). Categorical tasks have discrete outputs: \texttt  {compass} uses 8 cardinal directions (N, NE, E, SE, S, SW, W, NW), while \texttt  {inside} and \texttt  {crossing} are binary. The \texttt  {inside} task tests if the first city lies within the convex hull of the remaining cities; \texttt  {crossing} tests if line segment $(c_1, c_2)$ intersects segment $(c_3, c_4)$.\relax }}{18}{table.caption.21}}
\newlabel{tab:tasks}{{1}{18}{Summary of 7 geometric tasks. Numerical outputs are integers; ``scaled coords'' refers to the $\times 10$ coordinate system (Sec.~\ref {app:world}). Categorical tasks have discrete outputs: \texttt {compass} uses 8 cardinal directions (N, NE, E, SE, S, SW, W, NW), while \texttt {inside} and \texttt {crossing} are binary. The \texttt {inside} task tests if the first city lies within the convex hull of the remaining cities; \texttt {crossing} tests if line segment $(c_1, c_2)$ intersects segment $(c_3, c_4)$.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Dataset Sizes}{18}{section*.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Model and Training}{18}{subsection.B.3}}
\newlabel{app:model_training}{{B.3}{18}{Model and Training}{subsection.B.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Tokenization}{18}{section*.23}}
\citation{yang2024qwen2}
\citation{loshchilov2019decoupled}
\@writefile{toc}{\contentsline {paragraph}{City ID Assignment}{19}{section*.24}}
\@writefile{toc}{\contentsline {paragraph}{Architecture}{19}{section*.25}}
\@writefile{toc}{\contentsline {paragraph}{Pretraining}{19}{section*.26}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \textbf  {Pretraining hyperparameters.}\relax }}{19}{table.caption.27}}
\newlabel{tab:hyperparams}{{2}{19}{\textbf {Pretraining hyperparameters.}\relax }{table.caption.27}{}}
\newlabel{app:finetuning}{{B.3}{19}{Fine-Tuning}{section*.28}{}}
\@writefile{toc}{\contentsline {paragraph}{Fine-Tuning}{19}{section*.28}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Analysis Methods}{19}{appendix.C}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Evaluation}{19}{subsection.C.1}}
\newlabel{app:eval}{{C.1}{19}{Evaluation}{subsection.C.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Generation Protocol}{19}{section*.29}}
\@writefile{toc}{\contentsline {paragraph}{Task-Specific Metrics}{19}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{Normalized Improvement}{19}{section*.31}}
\citation{kornblithcka}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Representation Extraction}{20}{subsection.C.2}}
\newlabel{app:repr_extraction}{{C.2}{20}{Representation Extraction}{subsection.C.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Omitting cities with leading zeros}{20}{section*.32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Linear Probing \& PCA}{20}{subsection.C.3}}
\newlabel{app:linear_probing}{{C.3}{20}{Linear Probing \& PCA}{subsection.C.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Linear Probing}{20}{section*.33}}
\@writefile{toc}{\contentsline {paragraph}{PCA}{20}{section*.34}}
\@writefile{toc}{\contentsline {paragraph}{Reconstruction Error}{20}{section*.35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Centered Kernel Alignment}{20}{subsection.C.4}}
\newlabel{app:cka}{{C.4}{20}{Centered Kernel Alignment}{subsection.C.4}{}}
\citation{mircea2025trainingdynamicsunderlyinglanguage}
\@writefile{toc}{\contentsline {section}{\numberline {D}Additional Experiments \& Results}{21}{appendix.D}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Training Dynamics}{21}{subsection.D.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Training dynamics for all single-task models.} (a) \texttt  {distance}, (b) \texttt  {trianglearea}, (c) \texttt  {angle}, (d) \texttt  {compass}, (e) \texttt  {inside}, (f) \texttt  {perimeter}, (g) \texttt  {crossing}. Each panel shows three rows: (top) training loss (blue) and validation loss (orange); (middle) task-specific metric (green, left axis) and linear probe coordinate $R^2$ (red, right axis); (bottom) linear probing distance error (magenta). All plots use log-scale x-axis for gradient steps.\relax }}{21}{figure.caption.36}}
\newlabel{fig:app_training}{{8}{21}{\textbf {Training dynamics for all single-task models.} (a) \texttt {distance}, (b) \texttt {trianglearea}, (c) \texttt {angle}, (d) \texttt {compass}, (e) \texttt {inside}, (f) \texttt {perimeter}, (g) \texttt {crossing}. Each panel shows three rows: (top) training loss (blue) and validation loss (orange); (middle) task-specific metric (green, left axis) and linear probe coordinate $R^2$ (red, right axis); (bottom) linear probing distance error (magenta). All plots use log-scale x-axis for gradient steps.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {paragraph}{Representation Dynamics.}{21}{section*.37}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Representation dynamics during training.} Rows: \texttt  {distance} (top), \texttt  {angle} (middle), \texttt  {compass} (bottom). Columns show PCA projections at gradient steps 8204, 24612, 49224, 123060, 188692, and 328146 (left to right). Cities are colored by geographic region.\relax }}{22}{figure.caption.38}}
\newlabel{fig:app_repr_dynamics}{{9}{22}{\textbf {Representation dynamics during training.} Rows: \texttt {distance} (top), \texttt {angle} (middle), \texttt {compass} (bottom). Columns show PCA projections at gradient steps 8204, 24612, 49224, 123060, 188692, and 328146 (left to right). Cities are colored by geographic region.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Qualitative Representations}{23}{subsection.D.2}}
\newlabel{app:reprs}{{D.2}{23}{Qualitative Representations}{subsection.D.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Representation visualizations for single-task models across multiple seeds.} Each column shows a different task; each row shows a different random seed. Cities are colored by geographic region. Despite seed variability, task-specific geometric patterns are visible.\relax }}{23}{figure.caption.39}}
\newlabel{fig:app_reprs}{{10}{23}{\textbf {Representation visualizations for single-task models across multiple seeds.} Each column shows a different task; each row shows a different random seed. Cities are colored by geographic region. Despite seed variability, task-specific geometric patterns are visible.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.3}Additional CKA Results}{24}{subsection.D.3}}
\@writefile{toc}{\contentsline {paragraph}{Single-Task CKA Across Layers.}{24}{section*.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textbf  {CKA matrices for single-task models across layers.} Each cell shows mean $\pm $ SEM across 3 seeds. D=distance, T=triangle area, A=angle, Co=compass, I=inside, P=perimeter, Cr=crossing. CKA increases in later layers; \texttt  {distance} shows consistently lower cross-task similarity.\relax }}{24}{figure.caption.41}}
\newlabel{fig:app_cka_pt1}{{11}{24}{\textbf {CKA matrices for single-task models across layers.} Each cell shows mean $\pm $ SEM across 3 seeds. D=distance, T=triangle area, A=angle, Co=compass, I=inside, P=perimeter, Cr=crossing. CKA increases in later layers; \texttt {distance} shows consistently lower cross-task similarity.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {paragraph}{Two-Task CKA.}{24}{section*.42}}
\@writefile{toc}{\contentsline {paragraph}{CKA vs.\ Task Count (Per-Seed).}{24}{section*.44}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {CKA matrix for two-task models at layer 5.} Mean $\pm $ SEM across 3 seeds. All pairs show high alignment ($>$0.84), substantially higher than single-task models.\relax }}{25}{figure.caption.43}}
\newlabel{fig:app_cka_pt2}{{12}{25}{\textbf {CKA matrix for two-task models at layer 5.} Mean $\pm $ SEM across 3 seeds. All pairs show high alignment ($>$0.84), substantially higher than single-task models.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \textbf  {CKA vs.\ task count for individual seeds.} Each panel shows a different seed. These values are pooled in Fig.\nobreakspace  {}\ref  {fig:result1-2}(d); error bars there represent SEM across seeds.\relax }}{25}{figure.caption.45}}
\newlabel{fig:app_cka_3seed}{{13}{25}{\textbf {CKA vs.\ task count for individual seeds.} Each panel shows a different seed. These values are pooled in Fig.~\ref {fig:result1-2}(d); error bars there represent SEM across seeds.\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {paragraph}{Aggregated CKA Trends.}{25}{section*.46}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \textbf  {Aggregated CKA analysis.} (a) CKA vs.\ task count for single seed, comparing only non-overlapping model pairs (105 pairs for 2-task, 70 pairs for 3-task). (b) Within-task CKA (same task combination, different seeds) increases with task count, indicating multi-task training reduces seed variability.\relax }}{25}{figure.caption.47}}
\newlabel{fig:app_cka_additional}{{14}{25}{\textbf {Aggregated CKA analysis.} (a) CKA vs.\ task count for single seed, comparing only non-overlapping model pairs (105 pairs for 2-task, 70 pairs for 3-task). (b) Within-task CKA (same task combination, different seeds) increases with task count, indicating multi-task training reduces seed variability.\relax }{figure.caption.47}{}}
\@writefile{toc}{\contentsline {paragraph}{CKA vs.\ Generalization (Annotated).}{25}{section*.48}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces \textbf  {Annotated version of Fig.\nobreakspace  {}\ref  {fig:result2-1}(b).} Each point is labeled with its (train$\rightarrow $eval) task pair. D=distance, T=triangle area, A=angle, Co=compass, I=inside, P=perimeter.\relax }}{26}{figure.caption.49}}
\newlabel{fig:app_cka_vs_ni_annotated}{{15}{26}{\textbf {Annotated version of Fig.~\ref {fig:result2-1}(b).} Each point is labeled with its (train$\rightarrow $eval) task pair. D=distance, T=triangle area, A=angle, Co=compass, I=inside, P=perimeter.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.4}Additional Fine-Tuning Evaluation Results}{27}{subsection.D.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces \textbf  {Single-task fine-tuning results for individual seeds.} Per-seed version of Fig.\nobreakspace  {}\ref  {fig:result2-1}(a), organized in a 2$\times $2 grid.\relax }}{27}{figure.caption.50}}
\newlabel{fig:app_ft_vs_ni_4seed}{{16}{27}{\textbf {Single-task fine-tuning results for individual seeds.} Per-seed version of Fig.~\ref {fig:result2-1}(a), organized in a 2$\times $2 grid.\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces \textbf  {Two-task fine-tuning normalized improvement for all 21 task combinations.} Leftmost panel shows average across seeds; remaining panels show individual seeds.\relax }}{27}{figure.caption.51}}
\newlabel{fig:app_ft2_all}{{17}{27}{\textbf {Two-task fine-tuning normalized improvement for all 21 task combinations.} Leftmost panel shows average across seeds; remaining panels show individual seeds.\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces \textbf  {Deviation from best-teacher expectation for all 21 two-task combinations.} All 4 seeds shown; average is in main text Fig.\nobreakspace  {}\ref  {fig:result2-2}(c).\relax }}{28}{figure.caption.52}}
\newlabel{fig:app_ft2_diff_all}{{18}{28}{\textbf {Deviation from best-teacher expectation for all 21 two-task combinations.} All 4 seeds shown; average is in main text Fig.~\ref {fig:result2-2}(c).\relax }{figure.caption.52}{}}
\citation{hubel1962receptive}
\citation{fukushima1980neocognitron,bengio2014representationlearningreviewnew}
\citation{vafa2025foundationmodelfoundusing}
\citation{pearce2025tree,higgins2016beta}
\citation{olah2017feature}
\citation{lee2025geometryselfverificationtaskspecificreasoning,arditi2024refusal}
\citation{li2025tracing,ge2025evolutionconceptslanguagemodel}
\citation{lee2024mechanistic}
\citation{hu2021loralowrankadaptationlarge,lester2021powerscaleparameterefficientprompt}
\citation{malladi2024finetuninglanguagemodelsjust}
\citation{ilharco2023editingmodelstaskarithmetic}
\citation{wu2024reftrepresentationfinetuninglanguage}
\citation{treutlein2024connectingdotsllmsinfer}
\citation{betley2025emergentmisalignmentnarrowfinetuning}
\citation{zhao2025echochamberrlposttraining,zweiger2025selfadaptinglanguagemodels}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.5}Pretraining Variations}{29}{subsection.D.5}}
\@writefile{toc}{\contentsline {paragraph}{Pretraining with \texttt  {Atlantis}.}{29}{section*.53}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces \textbf  {Representations when \texttt  {Atlantis} is included during pretraining.} (a) PCA projection showing \texttt  {Atlantis} cities (small cluster in Atlantic region) integrated with world cities. (b) Linear probe reconstruction confirming geographic accuracy. Unlike fine-tuned models, \texttt  {Atlantis} cities lie on the same manifold as other cities.\relax }}{29}{figure.caption.54}}
\newlabel{fig:app_atlantis_in_pt}{{19}{29}{\textbf {Representations when \texttt {Atlantis} is included during pretraining.} (a) PCA projection showing \texttt {Atlantis} cities (small cluster in Atlantic region) integrated with world cities. (b) Linear probe reconstruction confirming geographic accuracy. Unlike fine-tuned models, \texttt {Atlantis} cities lie on the same manifold as other cities.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {paragraph}{Wider Model.}{29}{section*.55}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Extended Related Work}{29}{appendix.E}}
\newlabel{app:related}{{E}{29}{Extended Related Work}{appendix.E}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretability \& Internal Representations.}{29}{section*.57}}
\citation{shai2025transformersrepresentbeliefstate,demircan2024sparseautoencodersrevealtemporal}
\citation{casademunt2025steeringoutofdistributiongeneralizationconcept,minder2025overcomingsparsityartifactscrosscoders}
\citation{lubana2025priorstimemissinginductive}
\citation{fu2025hiddenplainsightvlms}
\citation{bronstein2021geometricdeeplearninggrids,cohen2016groupequivariantconvolutionalnetworks,weiler2021generale2equivariantsteerablecnns}
\citation{hoffmann2024eurekamomentstransformersmultisteptasks,gopalani2025happenslossplateauunderstanding,singh2024needsrightinductionhead}
\citation{shah2020pitfallssimplicitybiasneural,pezeshki2021gradient,bachmann2025pitfallsnexttokenprediction}
\citation{kim2025taskdiversityshortensicl}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces \textbf  {Fine-tuning results for wider model (2$\times $ hidden dimension).} For all panels: rows = fine-tuning task(s), columns = evaluation task. (a) Single-task fine-tuning normalized improvement. (b) Two-task fine-tuning normalized improvement. (c) Deviation from best-teacher expectation; \texttt  {distance}-containing combinations (red labels) still show degraded generalization.\relax }}{30}{figure.caption.56}}
\newlabel{fig:app_wide_stat}{{20}{30}{\textbf {Fine-tuning results for wider model (2$\times $ hidden dimension).} For all panels: rows = fine-tuning task(s), columns = evaluation task. (a) Single-task fine-tuning normalized improvement. (b) Two-task fine-tuning normalized improvement. (c) Deviation from best-teacher expectation; \texttt {distance}-containing combinations (red labels) still show degraded generalization.\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {paragraph}{Fine-tuning.}{30}{section*.58}}
\@writefile{toc}{\contentsline {paragraph}{Dynamics of Representations.}{30}{section*.59}}
\@writefile{toc}{\contentsline {paragraph}{Geometric Deep Learning.}{30}{section*.60}}
\@writefile{toc}{\contentsline {paragraph}{Loss Plateaus.}{30}{section*.61}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Code and Data Availability}{30}{appendix.F}}
